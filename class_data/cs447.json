{
    "class": "YourClassName",
    "lectures": [
        {
            "lecture": 11,
            "content": "Multiplication by repeated addition\n3 \u00d7 6 =\n1 2 3\n18\nhow many additions would it take to calculate\n2 x 500,000,000?\n4 5 6\n7 8 9 10 11 12\n13 14 15 16 17 18\nBack to grade school\n\u25cf remember your multiplication tables?\n\u25cf binary is so much easier\n\u25cf if we list 0 too, the product logic looks awfully familiar\u2026\n4\n\u2715 1 2 3 4 5 6 7 8 9\n1 1 2 3 4 5 6 7 8 9\n2 2 4 6 8 10 12 14 16 18\n3 3 6 9 12 15 18 21 24 27\n4 4 8 12 16 20 24 28 32 36\n5 5 10 15 20 25 30 35 40 45\n6 6 12 18 24 30 36 42 48 54\n7 7 14 21 28 35 42 49 56 63\n8 8 16 24 32 40 48 56 64 72\n9 9 18 27 36 45 54 63 72 81\n\u2715 1\n1 1\nA B P\n0 0 0\n0 1 0\n1 0 0\n1 1 1\n\u25cf you know how to multiply, riiiight?\n5\nJust like you remember\n5\n\u00d7 6\n0101 =\n\u00d7 0110 =\n 0000\n 0101\n0101\n0000___\n0011110\n30\n0\n 00\n 000\nthese are partial\nproducts. how\nmany additions\nare we doing?\nwait, what operation\nare we doing here...?\nMultiplicand\nMultiplier\n\u25cf what are we actually doing with this technique?\n\u25cf remember how positional numbers are really polynomials?\n6\nWait, why does this work?\n78\u00d754 = 70\u00d750 + 70\u00d74 + 8\u00d750 + 8\u00d74\nFOIL\u2026\nwe're eliminating many addition\nsteps by grouping them together.\nwe group them together by\npowers of the base.\n= 78\u00d750 + 78\u00d74\nHow many bits?\n\u25cf when we added two n-digit/bit numbers, how\nmany digits/bits was the sum?\n\u25cf how about for multiplication?\n\u25cf when you multiply two n-digit/bit numbers,\nthe product will be at most 2n digits/bits\n\u25cf so if we multiply two 32-bit numbers\u2026\no we could get a 64-bit result! AAAA!\no if we just ignored those extra 32 bits, or\ncrashed, we'd be losing a lot of info.\no so we have to store it.\n7\n99\n\u00d7 99\n9801 9999\n\u00d7 9999\n99980001\n1111\n\u00d7 1111\n11100001\n\u25cf MIPS has two more 32-bit registers, HI and LO. if you do this:\nmult t0, a0\n\u25cf then HI = upper 32 bits of the product and LO = lower 32 bits\n\u25cf to actually get the product, we use these:\nmfhi t0 # move From HI (t0 = HI)\nmflo t1 # move From LO (t1 = LO)\n\u25cf the mul pseudo-op does a mult followed by an mflo\n\u25cf MIPS does this for 2 reasons:\no multiplication can take longer than addition\no we'd otherwise have to change two different registers at once\n\u25cf if you wanted to check for 32-bit multiplication overflow, how could you do\nit?\n8\nHow (and why) MIPS does it\nDetecting 32-bit overflow with signed numbers\n\u25cf Result is positive and HI is zero \u00e8 No overflow!\n\u25cf Result is negative and HI is 0xFFFFFFFF AND MSB of LO is 1 \u00e8 No overflow!\n\u25cf Result is negative and HI is 0xFFFFFFFF AND MSB of LO is 0 \u00e8 Overflow!\n9\n00000000\u202600000000 ANYTHING!\nHI LO\n11111111\u202611111111 1\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\nHI LO\n11111111\u202611111111 0\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\nHI LO\nSigned multiplication\n10\nA B P\n3 5 15\n3 -5 -15\n-3 5 -15\n-3 -5 15\n11\nGrade school (but like, 6th, instead of 3rd)\nA B S\n+ + +\n+ - -\n- + -\n- - +\n\u25cf if you multiply two signed numbers, what's the rule?\nProduct Sign\nif the signs of the\noperands differ, the\noutput is negative.\n\u25cf we already have an algorithm to multiply unsigned numbers\n\u25cf multiplying signed numbers is exactly the same (except for the signs)\n\u25cf so why not use what we already made?\nlong prod = unsigned_mult(abs(A), abs(B));\nif(sgn(A) == sgn(B))\nreturn prod;\nelse\nreturn \u2013prod;\n12\nDon't repeat yourself\nDivision\nLike multiplication, except\u2026 not really\n13\nIf multiplication is repeated addition\u2026\n\u25cf \u2026is division repeated subtraction?\no yes. it is.\n\u25cf in A \u00f7 B, the quotient (answer) is \"how many times can you\nsubtract B from A until you can't anymore?\"\n14\n20 \u00f7 3 =\n1\n4\n2\n5\n3\n6\n6 R 2\nwhat about\nthese lil guys?\nhow many subtractions would it take to calculate\n1,000,000,000 \u00f7 2?\nThat's not what you learned in school, was it\n\u25cf You learned something a tiiiiiny bit more complicated\n15\n7 7 4209\n0 0 5 4 R 5 1 4\u00f777?\n42\u00f777?\n420\u00f777!- 385 =77\u00d75\n3 5 9\n- 308\n5 1\n=77\u00d74\nFinally!!\nuhh\u2026how many times?\nlike, 5-ish?\nguess and check\noh, that's like 77\u00d74\nWhat's going on?\n\u25cf division is multiplication backwards. it's like ctrl+z.\n16\n77\n\u00d7\n+R51\nwe're finding the partial products\nthat add up to a total product\ndivision goes left-to-right because we find the\npartial products from biggest to smallest\nand to make it even more interesting,\nthere might be a remainder\nand then there's division by 0.\nmultiplication is multiplying polynomials.\ndivision is factoring polynomials.\n3850\n308\n4158\n54\n4209\nAnother way of looking at it (animated)\n\u25cf let's say we want to do\u2026\n17\nfirst we ask how\nmany 400s fit\n400\nthen how many 40s\n1\n7\nthen how many 4s 4\n40 40 40\n40\n40\n40\n40\n4\n4\n4\n4 so we're saving time\nby doing groups of\nsubtractions from\nbiggest to smallest\n(calculating random number)\u2026 696\u00f74\nThanks, tiny multiplication table. Thable.\n\u25cf at least multiplication in binary is easy, which simplifies division\n18\n1100 1001001\n1100\u22641? 1100\u226410?\n1100\u2264100?\n- 1100\n110 0\n- 1100\n0\n1100\u22641001?\n1100\u226410010!\n0 0 0 0 1 1 R 1\n1\n0\n1100\u22641100!\n1100\u22641?\nin binary, each step becomes a\nyes-no choice: does the divisor fit\ninto the remainder?\nDivisor? Dividend? Remainder?\n19\n1100 1001001\nthe dividend is\nthe number that is\nbeing divided\nthe divisor\ndivides the\ndividend\nthe remainder is the\nnumber we're trying to\nfit the divisor into\nit starts off as the\ndividend\u2026\n- 1100\n110 0\nbut really, when we\nsubtract something, we\nare making the\nremainder smaller.\n1 this is the new\nremainder.\nFinding partial products, biggest to smallest (animated)\n20\n1100 1001001\nessentially we're starting with the divisor shifted\nall the way left, and sliding it right\n1100 000000\n0 0 0 0 1 1 0R 1\n11001\nHow does MIPS do it\n\u25cf MIPS uses HI and LO for division as well. If you do this:\ndiv t0, a0 # Divide signed\ndivu t0, a0 # Divide unsigned\n\u25cf then HI = remainder of the product and LO = quotient\n\u25cf to actually get the quotient and remainder, we use these:\nmfhi t0 # move From HI (t0 = HI)\nmflo t1 # move From LO (t1 = LO)\n\u25cf the div pseudo-op does a real div followed by an mflo\n21 CS447\nA few more odds and ends\n22\nDivide-and-conquer\u2026 in parallel\n\u25cf an n\u00d7n digit multiplication can be broken into n, n\u00d71 digit ones\n\u25cf the partial products can be summed in any order(thanks, commutativity)\n23\n1011\u00d70101 =\n1011\u00d71\n+ 1011\u00d70\n+1011\u00d7100\n+ 1011\u00d70\n+\n+\n+\nall operations in the same\ncolumn can be done in parallel.\nnow our multiplication takes\nonly 3 steps instead of 4.\nbut this is a O(log(n))\nalgorithm! so for 32 bits\u2026\nit takes 6 steps instead of 32!\nBut division\u2026\n\u25cf if we try to do something similar, well\u2026\n24\n1011\u00f7101 =\n1011\u00f7101000\n1011\u00f710100\n1011\u00f71010\n1011\u00f7101\n= 0\n= 0\n= 1 R 1\n= 1 R 110??\nwhat's the difference between\naddition and subtraction?\nsubtraction is not commutative.\nwe cannot know the\nanswer to this step\u2026 \u2026until we know the answer\nto the previous one.\nyou can do the steps in any\norder\u2026 but you can't do\nthem at the same time.\nDivision is fundamentally slower\n\u25cf each step depends on the previous one.\n\u25cf we cannot split it up into subproblems like with multiplication.\n\u25cf the only way to make division faster is to guess.\no SRT Division is a way of predicting quotient bits based on the next few bits\nof the dividend and divisor\no but it can make mistakes and they have to be corrected\no the original Pentium CPU in 1994 messed this up\n\u00a7 and Intel pretended everything was OK\n\u00a7 and people got mad\n\u00a7 and they had to recall millions of them\n\u00a7 and Intel lost half a billion dollars\n\u2013 lol\n25\nDoing modulo with AND\n\u25cf in decimal, dividing by powers of 10 is trivial.\n26\n53884\u00f7 1000 = 53 R 884 1000 = 53 R 884\n\u25cf in binary, we can divide by powers of 2 easily with shifting\n\u25cf and we can get the remainder by masking!\n10010110 10010110 \u00f7 1000 = 10010 R 110 1000 = 10010 R 110\n10010110 >> 11 = 10010\n10010110 & 0111 = 110\nmore generally: a AND (2n-1) = a % 2n\nmore generally: a AND ((1<<n)-1) = a % 2n\nSigned division\n27\nAll roads lead to Rome\u2026 er, the Dividend\n\u25cf how did we extend our multiplication algorithm to signed numbers?\n\u25cf but how exactly do the rules work when you have two results?\n28\nDividend = (Divisor \u00d7 Quotient) + Remainder\nthe four values are related as:\nIf you do\u2026 Java says\u2026 Python says\u2026\n7 / 2 3 R 1 3 R 1\n7 / -2 -3 R 1 -4 R -1\n-7 / 2 -3 R -1 -4 R 1\n-7 / -2 3 R -1 3 R -1\ncheck out https://en.wikipedia.org/wiki/Modulo_operation for this travesty\nmathematicians would\nexpect the remainder\nto always be positive,\nso the last row would\nbe 4 R 1!\nIn Java -7/2 = -(7/2)\nIn Python -7/2 \u2260 -(7/2)\nWhaaaaaaaaaaaaaaaat\n\u25cf no, really, it's not well-defined. there's no \"right\" answer.\n\u25cf watch out for this.\no I think I ran into it once because I was doing maths with angles in the\nrange [-pi, pi)\no most of the time, when you're dealing with modulo, you're dealing with\npositive values\no Most languages I had used did (-7 / 2) as -(7 / 2)\n\u00a7 this is \"truncated division\" (rounds towards 0)\no but Python is gaining popularity and can sometimes be confusing\n\u00a7 it uses \"flooring division\" (rounds towards -\u221e)\n\u25cf so which does arithmetic right shift do?\no it does flooring division. "
        },
        {
            "lecture": 10,
            "content": "Fractional Binary\n3\nFractional numbers\n\u25cf Up to this point we have been working with integer numbers.\no Unsigned and signed!\n\u25cf However, Real world numbers are\u2026 Real numbers. Like so:\n\u25cf That create new challenges!\no Let\u2019s start by taking a look at them.\n4\n2 0 2 4\n2 0 2 4.320\nJust a fraction of a number\n\u25cf The numbers we use are written positionally: the position of a digit within the\nnumber has a meaning.\n\u25cf What about when the numbers go over the decimal point?\n5\n2 0 2 4\n1000s 100s 10s 1s\n100 101 102 103\n10ths\n10-1\n100ths\n10-2\n1000ths\n10-3\n. 3 2 0\n? ??\nA fraction of a bit?\n\u25cf Binary is the same!\n\u25cf Just replace 10s with 2s.\n6\n23 22 21 20\n0 1 1 0\n8s 4s 2s 1s\n2-1 2-2 2-3 2-4\n.1 1 0 1\n2ths? 4ths 8ths 16ths\nTo convert into decimal, just add stuff\n7\n23 22 21 20\n0 1 1 0\n2-1 2-2 2-3 2-4\n.1 1 0 1\n0 \u00d7 8 +\n1 \u00d7 4 +\n1 \u00d7 2 +\n0 \u00d7 1 +\n1 \u00d7 .5 +\n1 \u00d7 .25 +\n0 \u00d7 .125 +\n1 \u00d7 .0625\n=\n= 6.812510\nFrom decimal to binary? Tricky?\n8\n6.8125 10\n0.812510\nx 2\n1.6250\n0.625010\nx 2\n1.2500\n0.250010\nx 2\n0.5000\n0.500010\nx 2\n1.0000\n6\u00f7210 = 3R0\n3\u00f7210 = 1R1\n1 1 0.1101\nMSB\nLSB\nSo, it\u2019s easy right? Well\u2026\n9\nWhat about: 0.\n1 10 0.\n110\nx 2\n0.2\n0.210\nx 2\n0.4\n0.410\nx 2\n0.8\n0.810\nx 2\n1.6\n0\n.\n0\n0\n0\n1\nSo, it\u2019s easy right? Well\u2026\u2026\n10\nWhat about: 0.\n1 10 0.610\nx 2\n1.2\n0.210\nx 2\n0.4\n0.410\nx 2\n0.8\n0.810\nx 2\n1.6\n0\n.\n0\n0\n0\n1\n0.\n110\nx 2\n0.2\n0.210\nx 2\n0.4\n0.410\nx 2\n0.8\n0.810\nx 2\n1.6\n1\n0\n0\n1\nSo, it\u2019s easy right? Well\u2026\u2026\u2026\n11\nWhat about: 0.\n1 10 0.610\nx 2\n1.2\n0.210\nx 2\n0.4\n0.410\nx 2\n0.8\n0.810\nx 2\n1.6\n0\n.\n0\n0\n0\n1\n0.\n110\nx 2\n0.2\n0.210\nx 2\n0.4\n0.410\nx 2\n0.8\n0.810\nx 2\n1.6\n1\n0\n0\n1\n1\n0\n0\n1\n0.610\nx 2\n1.2\n0.210\nx 2\n0.4\n0.410\nx 2\n0.8\n0.810\nx 2\n.\n.\n. 1.6\nHow much is it worth?\n12\n\u2022Well, it depends on where you stop!\n0.00012 0.0625\n0.000110012 0.0976\u2026\n0.0001100110012 0.0998\u2026\n=\n=\n=\nLimited space!\n\u25cf How much should we store?\no We have 32-bit registers, so 32-bits?\n\u00a7 Let\u2019s say we do!\n\u25cf How many bits are used to store the integer part?\n\u25cf How many bits are used to store the fractional part?\n\u25cf What are the tradeoffs?\n13\nA rising tide\n\u25cf Maybe half-and-half? 16.16 number looks like this:\n14\n0011 0000 0101 1010.1000 0000 1111 1111\n0011.0000 0101 1010 1000 0000 1111 1111\n0011 0000 0101 1010 1000 0000.1111 1111\nbinary point\nthe largest (signed) value we\ncan represent is +32767.999\nthe smallest fraction we can\nrepresent is 1/65536\nWhat if we place the binary point to the left\u2026\n\u2026we can get much higher accuracy near 0\u2026\n\u2026then we trade off accuracy for range further away from 0.\n\u2026but if we place the binary point to the right\u2026\nMind the point\n\u25cf In this representation we assume that the lowest n digits are the decimal places.\n15\n$12.34\n+$10.81\n$23.15\n1234\n+1081\n2315\nthis is called fixed-point\nrepresentation\nAnd it\u2019s a bitfield :D\nhttps://www.youtube.com/watch?v=GwmrIcn9Hwg\nfp_mult:\nmult a0, a1\nmflo t0\nsrl t0, t0, N_BITS_FRAC\nmfhi t1\nsll t1, t1, N_BITS_INT\nor v0, t0, t1\njr ra\nfp_add:\nadd v0, a0, a1\njr ra\nMove the point\n\u25cf What if we could float the point around?\no Enter scientific notation: The number -0.0039 can be represented:\n\u25cf These are both representing the same number, but we need to move the decimal\npoint according to the power of ten represented.\n\u25cf The bottom example is in normalized scientific notation.\no There is only one non-zero digit to the left of the point\n\u25cf Because the decimal point can be moved, we call this representation\n16\n-3.9 \u00d7 10-3\n-0.39 \u00d7 10-2\nFloating point\nFloating-point number\nrepresentation\n17\nThis could be a whole unit itself...\n\u25cf floating-point arithmetic is COMPLEX STUFF\n\u25cf However...\no it's good to have an understanding of why limitations exist\no it's good to have an appreciation of how complex this is... and how much better\nthings are now than they were in the 1970s and 1980s\no It\u2019s good to know things do not behave as expected when using float and double!\n18\nBinary numbers using IEEE 754\n\u25cf est'd 1985, updated as recently as 2008\n\u25cf standard for floating-point representation and arithmetic that virtually every CPU\nnow uses\n\u25cf floating-point representation is based around scientific notation\n19\n1348 =\n-0.0039 =\n-1440000 =\n+1.348 \u00d7 10+3\n-3.9 \u00d7 10-3\n-1.44 \u00d7 10+6\nsign significand exponent\nBinary Scientific Notation\n\u25cf scientific notation works equally well in any other base!\no (below uses base-10 exponents for clarity)\n20\n+1001 0101 =\n-0.001 010 =\n-1001 0000 0000 0000 =\n+1.001 0101 \u00d7 2+7\n-1.010 \u00d7 2-3\n-1.001 \u00d7 2+15\nwhat do you notice about the digit\nbefore the binary point using\nnormalized representation?\n(-1)s x 1.f \u00d7 2exp s \u2013 sign\nf \u2013 fraction\n1.f \u2013 significand\nexp \u2013 exponent\nIEEE 754 Single-precision\n\u25cf Known as float in C/C++/Java etc., 32-bit float format\n\u25cf 1 bit for sign, 8 bits for the exponent, 23 bits for the fraction\n21\nillustration from user Stannered on Wikimedia Commons\n\u25cf Tradeoff:\no More accuracy \u00e8 More fraction bits\no More range \u00e8 More exponent bits\n\u25cf Every design has tradeoffs \u00af\\_(\u30c4)_/\u00af\nIEEE 754 Single-precision\n\u25cf Known as float in C/C++/Java etc., 32-bit float format\n\u25cf 1 bit for sign, 8 bits for the exponent, 23 bits for the fraction\n22\nillustration from user Stannered on Wikimedia Commons\n\u25cf The fraction field only stores the digits after the binary point\n\u25cf The 1 before the binary point is implicit!\no This is called normalized representation\no In effect this gives us a 24-bit significand\n\u25cf The significand of floating-point numbers is in sign-magnitude!\no Do you remember the downside(s)?\nThe exponent field\n\u25cf the exponent field is 8 bits, and can hold positive or negative exponents, but... it\ndoesn't use S-M, 1's, or 2's complement.\n\u25cf it uses something called biased notation.\no biased representation = exponent + bias constant\no single-precision floats use a bias constant of 127\n23\n-127 + 127 =>\n-10 + 127 =>\n34 + 127 =>\n0\n117\n161\n\u25cf the exponent can range from -126 to +127 (1 to 254 biased)\no 0 and 255 are reserved!\n\u25cf why'd they do this?\no You can sort floats with integer comparisons!\nexp + 127 => Biased\nBinary Scientific Notation (revisited)\n\u25cf Our previous numbers are actually\n24\n(-1)0 x 1.001 0101 \u00d7 2134-127\n+1.001 0101 \u00d7 2+7\ns E f\n0 10000110 00101010000000000\u2026000\nbias = 127\nsign = 0 (positive number!)\nBiased exponent = exp + 127 = 7 + 127 = 134 = 10000110\nfraction = 0010101 (ignore the \u201c1.\u201d)\nBinary Scientific Notation (revisited)\n\u25cf Our previous numbers are actually\n25\n(-1)1 x 1.010 \u00d7 2124-127\n-1.010 \u00d7 2-3 =\ns E f\n1 01111100 01000000000000000\u2026000\nbias = 127\nsign = 1 (negative number!)\nBiased exponent = exp + 127 = -3 + 127 = 124 = 01111100\nfraction = 010 (ignore the \u201c1.\u201d)\nBinary Scientific Notation (revisited)\n\u25cf Our previous numbers are actually\n26\n-1.001 \u00d7 2+15=\ns E f\n? ? ?\nbias = 127\nsign = ?\nBiased exponent = ?\nfraction = ?\nCheck it on C++ (there are online tools for this!)\n#include <iostream>\n#include<bitset>\nint main() {\n// This is the number from the previous slide\nfloat x {-0b1001000000000000};\n// C++ does not shift floats :(\n// This is C++-whispering: it allows me to shift the bits :) int num {*(int*)&x};\n// Extract the fields!\nstd::bitset <1> sign = (num >> 31) & 0x1 ;\nstd::bitset <8> biased_exp = (num >> 23) & 0xFF;\nstd::bitset <23> frac = (num >> 0) & 0x7FFFFF;\n// Now let\u2019s print\nstd::cout << \"sign: \" << sign << std::endl;\nstd::cout << \"biased exponent: \" << biased_exp << std::endl;\nstd::cout << \"frac: \" << frac << std::endl;\nreturn 0;\n}\nTry it in: https://repl.it/languages/cpp 27\nEncoding a number as a float\nYou have an number, like\n-12.5937510\n1. Convert it to binary.\nInteger part: 1100\n2\nFractional part: 0.10011\n2\n2. Write it in scientific notation:\n1100.10011\n2 x 2\n0\n3. Normalize it:\n1.10010011\n2 x 2\n3\n28\n0.5937510\nx 2 1.18750\n0.1875010\nx 2 0.37500\n0.3750\n010\nx 2 0.75000\n0.750\n0\n010\nx 2 1.50000\nMSB\nLSB\n0.500\n0\n010\nx 2 1.00000\nEncoding a number as a float\nYou have an number, like -12.5937510\n1. Convert it to binary.\nInteger part: 11002\nFractional part: 0.100112\n2. Write it in scientific notation:\n1100.100112 x 20\n3. Normalize it:\n1.100100112 x 23\n4. Calculate biased exponent\n+3 + 127 = 13010 = 100000102\n29\ns exponent fraction\n1 10000010 10010011000000000\u2026000\n0xC1498000 \nAdding floating point numbers\n\u25cf Step 1 \u2013 Make both exponents the same\n\u25cf Step 2 \u2013 Add the significands\n\u25cf Step 3 \u2013 Normalize the result\n30\n1.11 \u00d7 20 + 1.00 \u00d7 2-2\n1.11 \u00d7 20 + 0.01 \u00d7 20\n1.11 \u00d7 20 + 0.01 \u00d7 20 = 10.00 \u00d7 20\n10.00 \u00d7 20 = 1.000 \u00d7 21\nMultiply floating point numbers\n\u25cf Step 1 \u2013 Add the exponents\n\u25cf Step 2 \u2013 Multiply the significands\n\u25cf Step 3 \u2013 Normalize the result\n31\n1.11 \u00d7 20 x 1.01 \u00d7 2-2\n0 + (-2) = [0+127]+[-2+127] =\n[127] + [125] \u2013 127 = [125] = -2\n1.11 x 1.01 = 10.0011\n10.0011 \u00d7 2-2 = 1.00011 \u00d7 2-1\nDivide floating point numbers\n\u25cf Step 1 \u2013 Subtract the exponents\n\u25cf Step 2 \u2013 Divide the significands\n\u25cf Step 3 \u2013 Normalize the result\n32\n1.001 \u00d7 20 / 1.1 \u00d7 2-2\n0 - (-2) = [0+127]-[-2+127] =\n[127] - [125] + 127 = [129] = 2\n1.001 / 1.1 = 0.11\n0.11 \u00d7 22 = 1.1 \u00d7 21\nOther formats\n\u25cf the most common other format is double-precision (C/C++/Java double), which uses\nan 11-bit exponent and 52-bit fraction\n33 both illustrations from user Codekaizen on Wikimedia Commons\n\u25cf GPUs have driven the creation of a half-precision 16-bit floatingpoint format. it's adorable\n1023 bias\n15 bias\nSpecial cases\nSingle precision Double precision Meaning\nExponent Fraction Exponent Fraction\n0 0 0 0 0\n0 !=0 0 !=0 Number is denormalized\n255 0 2047 0 Infinity (sign-bit defines + or -)\n255 !=0 2047 !=0 NaN (Not a Number)\n34\n\u25cf IEEE 754 can represent data outside of the norm.\no Zero! How do you do that with normalized numbers?\no +/- Infinity\no NaN (Not a number). E.g. when you divide zero by zero.\no Other denormalized number: Squeeze the most out of our bits!\n\u00a7 E.g.: 0.00000000000000000000001 x 2-127\nCheck out this cool thing in MARS\n\u25cf go to Tools > Floating Point Representation\n\u25cf Try it out!"
        },
        {
            "lecture": 12,
            "content": "What's electricity?\n(EE-ish section)\n2\n3\nIn your orbit\np+\nehere's a proton. it has\na positive charge\nhere's an electron. it has\na negative charge\nit kinda goes\naround\nthe proton\nin an orbit*\n*it actually doesn\u2019t\u2026 it\u2019s way more complex than that!\nWaves, teleportation and other black magic!\nprotons sit still while electrons can move around\n4\nOpposites attract\u2026\np+ ep+ eopposite charges\nattract\ntwo of the same\ncharge repel here's electricity.\nhere it is\nbut protons are\nkinda stuck, so\u2026\n5\nLots of fish electrons in the sea\nhere's a solid piece of metal\nthe atoms are in a fixed structure\nbut some of the electrons are free to move around\nright now, the charges are\nbalanced: same number of\npositive and negative\nlet's knock it out of whack\n6\nTwo moles is company, three's a crowd\nlet's shove more electrons in\npacking more\nelectrons in leads\nto two things:\n1. this metal is now\nnegatively charged\n2. the electrons are\nnow closer together\nmeaning they're less\nhappy\naaa\nnoo\n7\nCarousel of unhappiness\nand then give them a\n(difficult) way out\nand then have something which will\nsqueeze them back together again\nwell now you have electricity\nwire\nif we shove some down a wire\nwire\nwe'd like to get off\nmister bones wild ride\n8\nWatch em go\nvoltage measures\nelectron unhappiness\ncurrent measures how\nmany electrons per second\nare moving past a point\nlow\nhigh\nlow\nand that's electricity high\nLogic Basics\n9\n\u25cf Why is a vacuum tube called like that?\n\u25cf They are also called thermionic valves (or simply valves)\n10\nValves (or tubes) \u2013 more fun?\nhttps://en.wikipedia.org/wiki/Vacuum_tube\nValves (or tubes) \u2013 more fun?\n\u25cf Why is a vacuum tube called like that?\n\u25cf They are also called thermionic valves (or simply valves)\n11\nJoin us!\nJoin us!\nYou shall\nnot pass!\nJoin us!\n\u25cf a transistor is like a little valve\n12\nTransistors\nMOSFET BJT\nThere are multiple\ntypes of transistors\ncommon\noutput\ninput\noutput\ncommon\ninput\noutput\ncommon\ninput\nCan be used many\ndifferent ways!\nFuture\n\u25cf Memristor?\no Well, it\u2019s been a while :)\n\u25cf Light switches?\no https://spectrum.ieee.org/optical-switch-1000x-faster-transistors\no Still switches!\no No clue about the physics behind this :)\n13\n\u25cf The ones we\u2019ll focus on MOSFET transistors\no Metal-Oxide Semiconductor Field-Effect Transistor\no Commonly used just as switches (digital electronics)\n14\nTransistors\nD\nS\nG\n9V\nD\nS\nG\n0V\nThe positive\nterminal (e.g. 9V)\nThe negative/ground\nterminal (0V) \n\u25cf Used as an electrically controlled switch\no The input is connected to G (Gate)\n\u00a7 controls the switch state\no The output is D (drain) is connected to S (source)\n\u25cf The voltages represent bits! (maybe 9V = 1, 0V = 0)\n15\nTransistors\nInput Output\nD\nS\nG\n\u25cf MOSFETs come in two varieties:\n16\nTransistors\nD\nS\nG\n\u201cN\u201d Type\nWork when connected to 0\nG=1 G=0\nON OFF\nS\nD\nG\n\u201cP\u201d Type\nWork when connected to 1\nThis means\ninverted\nG=0 G=1\nON OFF\n17\nTransistors \u2013 Overly simplified\n01\nD\nS\nG\n01\nS\nD\nG\n\u201cN\u201d Type \u201cP\u201d Type\nThe current\nmust flow!!\n18\nTransistors\nNow just put 3 billion\nof them together! who\nsaid EE was hard?\n\u25cf We can combine transistors in interesting ways to make gates\n\u25cf A gate implements one of the basic boolean logic functions\n\u25cf Let's start with the simplest: the NOT gate\n19\nGates\nthis little bubble\nmeans \"invert\"\nA Q\nA is the input Q is the output\n\u25cf if we want to, say, NOT a 32-bit value, we can draw it like:\n20\nTime to bundle up\n32 32\n\u25cf it's a lot nicer than drawing 32 wires with 32 NOT gates\n\u25cf Logisim calls these wire bundles\no it doesn't draw the slashes and numbers though\u2026\n21\nNOT with MOSFETs\nA Q\n\u201cN\u201d Type\n\u201cP\u201d Type\nA Q A Q\n0 1\n1 0\nA=0\n1\nA=1\n0\n22\nNAND with MOSFETs\nA\nQ\nB\nA B Q\n0 0 1\n0 1 1\n1 0 1\n1 1 0\nA\nA\nB\nQ\nB\n23\nAND with MOSFETs\nA\nQ\nB\nA B Q\n0 0 0\n0 1 0\n1 0 0\n1 1 1\nA\nA\nB\nB\nQ\n24\nNOR with MOSFETs\nA B Q\n0 0 1\n0 1 0\n1 0 0\n1 1 0\nA\nA B\nQ\nB\nA Q\nB\n25\nOR with MOSFETs\nA B Q\n0 0 0\n0 1 1\n1 0 1\n1 1 1\nA\nA B\nB\nA Q\nB\nQ\n\u25cf we know about AND and OR, but what's XOR?\n26\nAND, OR, and\u2026 XOR?\nA\nQ\nB\nAND gate\nA\nQ\nB\nOR gate\nA\nQ\nB\nXOR gate\nA B Q\n0 0 0\n0 1 1\n1 0 1\n1 1 0\nA B Q\n0 0 0\n0 1 1\n1 0 1\n1 1 1\neXclusive OR\nmeans \"one or\nthe other, but\nNOT BOTH.\"\nA B Q\n0 0 0\n0 1 0\n1 0 0\n1 1 1\nAB A+B A\u2295B\n\u25cf If you have more than 2 inputs\u2026\nyou can just concatenate:\n27\nAND (multiple inputs)\nA\nQ\u2019\nB\nAND gate\nQ\u2019\nQ\nC\nAND gate\nA B C Q\n0 0 0 0\n1 0 0 0\n0 1 0 0\n1 1 0 0\n0 0 1 0\n1 0 1 0\n0 1 1 0\n1 1 1 1\nAND and/or OR \u25cf Combining logic is just a matter of\ncombining logic gates:\n\u25cf Look at the truth entries on the truth\n-table\no when Q is \u201c1\u201d\n\u25cf AND each entry variable \u25cf Then, OR each entry:\nABC + ABC\n\u25cf In English:\n28\nA\nB\nC\nQ\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n1\n1\n1\n0\n0\n0\n0\n1\n0\n1\n0\n1\n0\n0\n1\n1\n1\n1\n1\n1\n0\nIt\u2019s true when\n\u201cA is false\u201d and \u201cB is true\u201d and \u201cC is false\u201d\nOR\n\u201cA is false\u201d and \u201cB is true\u201d and \u201cC is true\u201d\nABC + ABC\n29\nAND and/or OR BA\nQ\nC\nA\nB\nC\nQ\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n1\n1\n1\n0\n0\n0\n0\n1\n0\n1\n0\n1\n0\n0\n1\n1\n1\n1\n1\n1\n0\n\u25cf if you stick a NOT gate after an AND gate, you get a NAND gate\n30\nIf you give an electrical engineer a NAND gate\u2026\n\u25cf this kind of gate has a cool property: it's universal\no in other words, you can build an entire computer with NANDs\n\u25cf but this isn't how real circuits are designed, at least anymore\n\u25cf digital logic courses use them cause NAND gate chips are cheap\n\u25cf but in Logisim, we have infinite gates for free :D\n\u25cf use the kind of gate you need for the situation at hand"
        },
        {
            "lecture": 13,
            "content": "Can I add with transistors?\n3\nSolving a problem\n\u25cf Let\u2019s say we want to create a circuit to add two bits.\no How do we do that?\n\u25cf In 3 very simple steps:\no Create a truth table that accurately represents the problem\no Interpret the truth table into a logic function\no Translate the function into a circuit\n4\nThe Tables of Truth\n\u25cf let's try to come up with a truth table for adding two bits\n\u25cf each column will hold 1 bit\n5\nA B C\n0\n0\n1\n1\n0\n1\n0\n1\n0\n0\n0\n1\nS\n0\n1\n1\n0\nlet's name the\ninputs A and B\nlet's name the\noutputs C and S,\nfor Carry and Sum\nfor the input values,\nwe count up in\nbinary\nnow let's fill in the\noutput values\ngreat! But\nthis is wrong.\nhey, this C column\nlooks familiar\u2026 so\ndoes the S column\nHalf-truth tables \u25cf what we just made was a half\n-adder\n\u25cf it has a carry output but not a carry input o (which might be useful for the lowest bit) \u25cf to make a full adder, we need 3 input bits\n6\nA\nB\nC\no\n0011\n0101\n0001\nS0110\n0011\n0101\nC\ni\n00001111\n01\n10\n1\n0\n1\n1\n00111 11\n0\n1011 0\n010\n+0010 1\n111\n1110 0\n001AB\nC\no\nSC\ni\nThe logic of it all \u25cf it looks a little messy, but it kinda makes\nsense if you think of it like this: o it counts how many input bits are \"1\" o Co and S are a 2-bit number!\n\u25cf if we look at the outputs in isolation: o S is 1 if we have an odd number of \"1s\" o Co is 1 if we have 2 or 3 \"1s\" \u25cf it's a little weird, but we can build this out of\nAND, OR, and XOR gates\n7\nA\nB\nC\no\n0011\n0101\n0001\nS0110\n0011\n0101\nC\ni\n00001111\n01\n10\n1\n0\n1\n1\nB Ci Co\n0\n0\n1\n1\n0\n1\n0\n1\n0\n0\n0\n1\nS\n0\n1\n1\n0\n0\n0\n1\n1\n0\n1\n0\n1\nA\n0\n0\n0\n0\n1\n1\n1\n1\n0\n1\n1\n0\n1 0\n1 1\nLet\u2019s build the adder Co circuit\n8\n\ufffd!\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd!\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd = \ufffd!\ufffd\ufffd\ufffd\ufffd + \ufffd\ufffd!\ufffd\ufffd\ufffd + \ufffd\ufffd\ufffd\ufffd\ufffd + \ufffd\ufffd\ufffd\ufffd\ufffd\nSweeping that under the rug\u2026\n\u25cf in programming, we use functions to be able to reuse code\n\u25cf in hardware, we can group gates into a component\n\u25cf here's the symbol for a one-bit full adder\n9\nB + A\nCi\nCo\nS\nthe inputs are\nlike arguments\nthe outputs are like\nreturn values\nnow we don't have to care how\nit adds, just that it does\nAdding longer numbers\n10\nWhere do the carries go?\n\u25cf when you add one place, you might get a carry out\n\u25cf that becomes the carry in for the next higher place\n11\n1 0 1 1 0 0 1 0\n+0 0 1 0 1 1 1 1\nBit\nBucket..?\nRipple Carry Adder\n\u25cf if we want to add two three-bit numbers, we'll\nneed three one-bit adders\n\u25cf we chain the carries from each place to the next\nhigher place, like we do on paper\n\u25cf we have to split the numbers up like so:\n12\nB +\n0\nA0 S0\nB +\n1\nA1 S1\nB +\n2\nA2 S2\nA2 A1 A0\nB2 B1 B0\nS2 S1 S0\n+\nFlip side\n\u25cf We could come up with a separate subtraction circuit, but\u2026\n\u25cf Since algebra tells us that x - y = x + (-y)\no Negation meaning flip the bits and add 1\n\u25cf Flipping the bits uses NOT gates\n\u25cf How do we add 1 without any extra circuitry?\no we use a full adder for the LSB, and when\nwe're subtracting, set the \"carry in\" to 1\n13\n~B +\n0\nA0 S0\n~B +\n1\nA1 S1\n1\nWhat makes a good word size?\n\u25cf can you think of an example of\u2026\no 100 of something?\no a million of something? One thousand million?\no One billion? more?\n\u25cf 28 = 256, 216 \u2245 65,000, 232 \u2245 4000 million, 264 \u2245 lots-of-a-lot\n\u25cf for a given word size, all the circuitry has to be built to support it\no 64 1-bit adders\no 128 wires going in\no 64 wires coming out\n14\nGate Delay\n\u25cf electrical signals can't move infinitely fast\n\u25cf transistors can't turn on and off infinitely fast\n\u25cf since each digit must wait for the next smaller digit to\ncompute its carry\u2026\no ripple carry is linear in the number of digits\n\u25cf this is a diagram of how the outputs of a 16-bit ripple\ncarry adder change over time\no it's measured in picoseconds! so ~100ps total\n\u25cf but if we went to 32 bits, it'd take 200ps\no and 64 bits, 400ps...\n\u25cf there are more efficient ways of adding\n15 (courtesy of Kate Temkin)\nWhat about overflow? \u25cf For unsigned addition, it's easy o For an n-bit adder: \u00a7 just look at the Co of the MSB \u00a7 if it's 1, it's an overflow. o what about subtraction? \u25cf For signed, is a bit strange o Compare the last 2 carry bits o If they are different \u00a7 Then there is overflow\n16\nB\n+\n0 A0\nS\n0\nB\n+\n1\nA\n1\nS\n1\nB\n+\n2 A2\nS\n2\nOVF\nBut why?\n\u25cf When does signed addition overflow?\no If:\n\u00a7 Both addends have the same sign\n\u00a7 The result has a different sign\n\u25cf How can we detect that?\no Looking at the last bit!\n\u25cf Where is the overflow?\n17\nOn the last bit, the carry-in and carryout have different bit values.\nA B Co\n0\n0\n1\n1\n0\n1\n0\n1\n0\n0\n0\nS\n0\n1\n1\n0\n0\n0\n1\n1\n0\n1\n0\n1\nCi\n0\n0\n0\n1\n1\n1\n1\n1\n0\n1 0\n1 1\nThe last bit:\n0 1\n1 0 There is overflow in signed addition if:\nMuxes and demuxes, encoders and\ndecoders\n18\nHardware that makes decisions\n\u25cf a multiplexer (mux) outputs one of its inputs based on a select.\n19\nQ\nA\nB\nS\nThis is the select input.\nQ\nA\nB\nS=0\nA\nQ\nB\nS=1\nMultiplexer truth table\n\u25cf let's make a truth table for a two-input 1-bit multiplexer.\n20\nS A B Q\n0 0 0\n0 0 1\n0 1 0\n0 1 1\n1 0 0\n1 0 1\n1 1 0\n1 1 1\n0\n0\n1\n1\n0\n1\n0\n1\nQ\nA\nB\nS=0\nA\nQ\nB\nS=1\nDoing everything and throwing most of it away\n\u25cf I want a circuit that does this:\nif(select == 1)\noutput = A \u2013 B\nelse\noutput = A + B\n\u25cf let's see what that looks like\n\u25cf a mux is like a hardware if-else statement\n\u25cf but unlike in software\u2026\no the \"condition\" comes at the \"end\" (the output)\no instead of doing one or the other, we do both, choose the one that we care\nabout, and ignore the rest!\n21\nAmusing muxes\n\u25cf Let\u2019s go to Logisim!\n22\nWhat's that enable input?\n\u25cf if you don't understand tristate buses or high\nimpedance states, do not turn on the enable input.\n\u25cf if you ever see blue wires, you are in weird,\nconfusing territory.\n\u25cf if you know this stuff, fine, but otherwise\u2026\n23\nDemultipliexers\n\u25cf a demux does the opposite: it sends its input to one of its outputs\n\u25cf the rest of the outputs are 0s\n24\nIn\nS\nIn\nS=0\nIn\nS=1\nLooking in a mirror\n\u25cf it can be confusing if all you see is this:\n25\nwhich is which???\nLogisim distinguishes these with names\nI\u2019ll do it with arrows\nEncoders\n\u25cf They encode 2n inputs into n outputs. Specifically\u2026\n\u25cf you give it several 1-bit inputs, and it tells you which one is 1.\n26\nEnc\n1\n0\n0\n0\n0\n0\n0\n1\n2\n3\n0\n1\nEnc\n1\n0\n0\n0\n1\n0\n0\n1\n2\n3\n0\n1\nEnc\n1\n0\n0\n0\n0\n1\n0\n1\n2\n3\n0\n1\nEnc\n1\n0\n0\n0\n1\n1\n0\n1\n2\n3\n0\n1\nI1 I2 I3\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\nOut\n00\n01\n10\n11\nI0\n1\n0\n0\n0\nEncoder issues\n\u25cf That table seems VERY incomplete!!!\no What about the other entries???\n27\nThe output is not valid!\nEnc\n0\n0\n0\n0\n???\n???\n0\n1\n2\n3\n0\n1\nvalid 0\nI0 I1 I2 I3 Out Valid\n0 0 0 0 ?? 0\n0 1 1 0 ?? 0\n1 1 1 0 ?? 0\n1 1 1 1 ?? 0\n\u2026 \u2026 \u2026 \u2026 \u2026 \u2026\nEnter: Priority Encoders\n\u25cf In a priority encoder \u2026 you give it several 1-bit inputs, and it tells you the highest\ninput with a 1.\n28\nPri\n1\n0\n0\n0\n0\n0\n0\n1\n2\n3\n0\n1\nPri\n1\n1\n0\n0\n1\n0\n0\n1\n2\n3\n0\n1\nPri\n1\n1\n0\n0\n0\n1\n0\n1\n2\n3\n0\n1\nPri\n1\n1\n0\n0\n1\n1\n0\n1\n2\n3\n0\n1\nI1 I2 I3\n0\n1\nX\nX\n0\n0\n1\nX\n0\n0\n0\n1\nOut\n00\n01\n10\n11\nI0\n1\nX\nX\nX\nWhat are\nthese?\nidc\n\u25cf we don't even care about the that input\n\u25cf we can put X in the inputs we don't care about\n\u25cf we call these don't cares\no yep, really\n\u25cf what these mean is:\no when we make this into a boolean function, we can ignore those inputs\n\u00a7 we won't even need to write em\n29\nI1 I2 I3\n0\n1\nX\nX\n0\n0\n1\nX\n0\n0\n0\n1\nOut\n00\n01\n10\n11\nI0\n1\nX\nX\nX\nStill\u2026\n\u25cf All zeros is still an invalid input :(\n30\nif none of the inputs is 1,\nthen logisim gives you X\u2026\nThese are not don\u2019t cares :\u2019)\nPri\n0\n0\n0\n0\nX\nX\n0\n1\n2\n3\n0\n1\nvalid 0\nDecoders\n\u25cf a decoder is like a 1-bit demux whose input is always 1\n\u25cf It does pretty much the opposite of an encoder J\n31\nS\n1\nS\nexactly one output is 1,\nand the rest are 0s\nUses for encoders, decoders and demuxes\n\u25cf uhhhhhhhhhhh\no Ummmmmmmmm\u2026 for now \u2026\n\u00a7 unless you're using tristate (blue) wires, they're not too useful\u2026\n\u25cf most of the time, you don't have to \"direct\" a signal to a location\no instead, you hook up the inputs to everything that needs them\n\u25cf we'll use them more when we get to sequential logic\n32\nCombinational vs Sequential\n\u25cf combinational logic: the outputs of a circuit depend entirely on their current inputs\no AND, OR, NOT, XOR gates\no adders\no muxes, demuxes, encoders, and decoders\n\u25cf sequential logic is coming up soon\no the outputs can depend on the current and previous inputs\no it remembers\n\u25cf logic minimization techniques only work on combinational logic!\no \u2026or combinational pieces of a larger sequential circuit"
        },
        {
            "lecture": 17,
            "content": "Assemblers and Compilers\nHow the machine-code sausage is made\n3\nWhat is machine code?\n4\n\u25cf text is human-oriented and informationally\u2026 sparse.\n\u25cf instead, we encode each instruction as a bitfield.\no this encoding is specified by the ISA.\n5\nSomething denser\n31 26 25 21 20 16 15 0\nopcode rs rt immediate\n31 26 25 21 20 16 15 11 10 6 5 0\nopcode rs rt rd shamt funct\n31 26 25 0\nopcode target\nR\nI\nJ\nthe opcode (and funct) field\nidentifies which instruction it is.\nadd rd,rs,rt\nbeq rs,rt,offset\njal target\nMIPS has three\ninstruction formats.\nsll rd,rs,shamt\n\u25cf well this is mostly next lecture, but\u2026\n6\nHow does it\u2026 do the thing?\n31 26 25 21 20 16 15 11 10 6 5 0\n000000 01001 01010 01000 00000 100000\nadd t0, t1, t2\nRegister File\nWE w r1 r2\nALU\ngets encoded as\u2026 \"add\" 1\nthe fields are used\nas the control\nsignals to the CPU's\ncomponents.\nHow It's Made\n7\n8\nSo we know the assembler\nli s0, 0\ntop:\n move a0, s0\n jal print_int\n addi s0, s0, 1\n blt s0, 5, top\n li v0, 10\n syscall\nprint_int:\n li v0, 1\n syscall\n jr ra\nAddress Instruction\n0x00400000 0x24100000\n0x00400004 0x00102021\n0x00400008 0x0C100008\n0x0040000C 0x22100001\n0x00400010 0x2A010005\n0x00400014 0x1420FFFB\n0x00400018 0x2402000A\n0x0040001C 0x0000000C\n0x00400020 0x24020001\n0x00400024 0x0000000C\n0x00400028 0x03E00008\nassembler!\nbut, there's clearly\na little more\ngoing on under\nthe hood\u2026\n\u25cf An assembler is a pretty simple program\n\u25cf See an instruction, output its encoding\n9\nHow it works\naddi s0, s0, 1\nthis is an I-type instruction\nthe opcode field is 8\ns0 is register 16\nthe encoding of 1 is 0x0001\nopcode rs rt imm\n8 16 16 1\nsplut 0x22100001\nBut what about\nlabels and the\ndata segment\n10\nHow it actually works (animated)\n.text .data\n0: DEADBEEF\n4: 00000005\n8: 12345678\n0: 24100000\n4: 00102021\n8: 0c000000\nLabels\nx: .data:0\ny: .data:4\nz: .data:8\ntop: .text:4\nFixups\n8: print_int\n.data\nx: .word 0xDEADBEEF\ny: .word 5\nz: .word 0x12345678\n.text\n li s0, 0\ntop:\n move a0, s0\n jal print_int\n addi s0, s0, 1\n blt s0, 5, top\n li v0, 10\n syscall\nprint_int:\n li v0, 1\n syscall\n jr ra\n10: 2A010005\n14: 1420FFFB\n18: 2402000A\n1C: 0000000C\n20: 24020001\n24: 0000000C\n28: 03E00008\nprint_int:\n .text:20\npseudo-op!\nthen, run through the fixups!\n8: 0c000008\nC: 22100001\nYum yum\n\u25cf if a label doesn't exist, it's an error.\n\u25cf now we have machine code!\n\u25cf it's packaged up into a casing: an object file\n\u25cf then the object files are linked\n\u25cf and then you get an executable program\no this is CS0449 stuff!\n11\n\u25cf ahahaha oh they're a lot more complicated\n12\nWhat about compilers?\nint main(int argc, char** argv) {\n if(argc < 2)\n fatal(\"gimme arguments\");\n else {\n ...\n }\n}\nlexing!\nparsing!\nKEYWORD(\"int\"),\nID(\"main\"),\nLPAREN,\nKEYWORD(\"int\"),...\nTokens\nAST (Abstract Syntax Tree)\nFunction\n ret_type: int\n name: \"main\"\n args: [\n {type: int, name: \"argc\"},\n {type: ptr(ptr(char)),\n name: \"argv\"}\n ]\nif\n<\nargc 2 call\nfatal \"gimme arguments\"\n\u2026\nintermediate\nrepresentation\ntranslation!\nsemantic\nanalysis!\nmysterious\nbullshit\n\u25cf all that really matters:\n13\nIt's just a grinder.\n/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\\n/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\\n/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\\n/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\\n/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\\n/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\\n/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\\n/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\\n/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\\n/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\\n/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\\nhello.c\ncompiler!!!\nbloop\nplop\ncode goes in, sausage object\nfiles come out\nsome compilers output\nassembly and rely on an\nassembler to produce\nmachine code\nthese days, it's common\nfor the compiler itself to\nproduce machine code,\nor some kind of\nplatform-independent\nassembly code\nJumps and Branches\n14\n\u25cf the control flow instructions are divided into two groups.\n15\nMaybe you never noticed\u2026\njumps make execution go\nto one specific place\nbranches make execution\ngo to one of two places\nj end bne s1, t0, top\nbut.. why?\nwell, notice the operands of each.\n\u25cf Each jump or branch has a target: where it goes to\n\u25cf We'd like to be able to encode any target address\u2026\n\u25cf But we have a fixed number of bits to encode our instructions.\n16\nA matter of practicality\nthink about the cases\nwhere jumps are used.\nnow think about the cases\nwhere branches are used.\nsome_function()\nreturn;\nwhile(true) {}\nif(...) {}\nwhile(...) {}\nfor(...) {}\nhow far away is a branch\ntarget likely to be?\nhow far away is a jump\ntarget likely to be?\n\u25cf we say that jumps are absolute and branches are relative.\n17\nAbsolute versus Relative\ntop:\n move a0, s0\n jal print_int\n add s0, s0, 1\n blt s0, 5, top\n ...\njumps just set the\nPC to a new value.\nbranches either add an offset\nto the PC or do nothing.\nPC = 0x800400B0\nPC += (-16)\njumps need a long address, but branches only need a\nsmall offset. so we can fit them into J and I instructions!\n\u25cf every MIPS instruction is 4 bytes\n\u25cf what's memory alignment again?\n18\nMore bang for your buck\nAddress in hex and in binary\n0x78000000 0111 1000 0000 0000 0000 0000 0000 0000\n0x78000004 0111 1000 0000 0000 0000 0000 0000 0100\n0x78000008 0111 1000 0000 0000 0000 0000 0000 1000\n0x7800000C 0111 1000 0000 0000 0000 0000 0000 1100\nwhat do you notice about these low 2 bits?\nin binary, multiples of 4 always end in 00\nsince every instruction's address ends in 00, do we need to store it?\nInstruction Fetching\nWhat do we do next, boss?\n19\n\u25cf what order do these instructions run?\n20\nRemember this?\nli s0, 0\n top:\n move a0, s0\n jal print_int\n addi s0, s0, 1\n blt s0, 5, top\n li v0, 10\n syscall\nprint_int:\n li v0, 1\n syscall\n jr ra\nmost instructions\nchange the PC to the\nnext address\ncontrol flow\ninstructions can\nchange the PC\nto a constant\u2026\n\u2026or the value from a register\u2026\n\u2026or one of two choices,\nconditionally\nForwarrrrrrrrd MARCH\n\u25cf moving ahead by 1 instruction each cycle is easy enough\n21\n+\n00100004\nsize of one instruction PC\nhow big are instructions in MIPS?\nArbitrary locatiooooon MARCH\n\u25cf jumps (j, jal, jr) put a constant value into the PC\no we call this the jump target.\n\u25cf well now we have two choices of where to go. how do we choose?\n22\n+\n00100004\nPC\njump target\n4\nPC Source\nPC Source (PCSrc for short) is a control signal.\nmany control signals are just MUX selectors\nMIPS jump targets\n\u25cf in MIPS, j and jal use the J-type instruction format:\n23\n31 26 25 0\nopcode target\nthis is 26 bits\u2026\n\u2026but the PC is 32 bits.\nWHAT DO??\n00100004\n\u25cf we don't need to store the lower 2 bits because of alignment.\n\u25cf most programs are nowhere near big enough to need 32-bit addrs.\n\u25cf so in MIPS, jumps only change the lower 28 bits of the PC.\n24\nDo we really need a full 32-bit address (no)\n78000008\nPC\n31 26 25 0\n000010 0x243C007\nhere's a j.\n<< 2\n0x90F001C\nput that into the\nlow 28 bits of the PC\n790F001C\nLet\u2019s visualize it\n25\n0040 0000 main: li s0, 0\n0040 0004 _loop_cmp: li t0, 10\n0040 0008 beq s0, t0, _loop_end\n0040 000C li v0, 1\n0040 0010 move a0, s0\n0040 0014 syscall\n0040 0018 addi s0, s0, 1\n0040 001C j _loop_cmp\n0040 0020 _loop_end: li v0, 10\n0040 0024 syscall\n31 26 25 0\n000010 opcode target\n0040 0004\n0000 0000 0100 0000 0000 0000 0000 0100\n00000100000000000000000001\nLet\u2019s visualize it\n26\n0040 0000 main: li s0, 0\n0040 0004 _loop_cmp: li t0, 10\n.... .... ...\n0040 001C j _loop_cmp\n0040 0020 _loop_end: li v0, 10\n0040 0024 syscall\n31 26 25 0\n000010 00000100000000000000000001\nPC\n0000 0000 0100 0000 0000 0000 0001 1100 0000 0000 0100 0000 0000 0000 0000 0100 0x 0040 001C 0x 0040 0004\nDo we really need a full 32-bit address (no) (cntd.)\n\u25cf If a jump instruction is in address\n\u25cf It can reach from address:\n\u25cf To address:\n27\n31 26 25 0\n000010 0x0000000\n<< 2 0x0000000\nYXXXXXXX\nYFFFFFFC\nY0000000\n31 26 25 0\n000010 0x3FFFFFF\n<< 2 0xFFFFFFC\nwhat does this mean if the thing\nyou're jumping to starts with a\ndifferent nibble? >>\n\u25cf What if we want to jump too far?\n\u25cf There is one instruction that can jump into a 32-bit address\no What is that?\n\u00a7 How big is register ra?\n28\nIf jumping REALLY far, far away\u2026\njr ra\nj a_label_far_far_away\nbeq t0, zero, a_label_far_far_away\n29\nIf jumping REALLY far, far away\u2026\nla t0, a_label_far_far_away\n jr t0\nj a_label_far_far_away\nbeq t0, zero, a_label_far_far_away\nbne t0, zero, _skip_jump\n la t0, a_label_far_far_away\n jr t0\n_skip_jump:\n30\nIf jumping REALLY far, far away\u2026\nla t0, a_label_far_far_away\n jalr t0\njal a_label_far_far_away\n\u25cf think about a number line.\n31\nRelative branches\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17\nyou\nare\nhere\nif you want to get here, what\ndo you have to add to 10?\nhow about here?\nwhat's the pattern? destination - source\n\u25cf In MIPS the PC points to the next instruction to run.\n\u25cf let's say we're running the beq here. it's at address 00\u2026\n32\nMIPS branch offsets\n00: beq a0, 10, else\n 04: li v0, 0\n 08: b end\nelse: 0C: li v0, 1\nend: 10: ...\n\u2026but the PC is here. PC\nwe want to get to address 0C.\nhow do we get there?\nPC += 8\nthe branch offset for this beq is:\ntarget \u2013 (branch address + 4) = 12 \u2013 (0 + 4) = 8\n\u25cf Since the branch's immediate is only 16 bits\u2026\n33\nEncoding it\n31 26 25 21 20 16 15 0\n4 4 1 0x0002\n0x0008 >> 2\nif the branch offset is negative like 0xFFFFFFE8, no big deal \u2013\nchop off the top 16 bits. 0xFFE8 is still a negative number.\nThe number stored is the number of instructions\n\u25cf To go to else, from the updated value of PC: Jump 2 instructions down\n34\n31 26 25 21 20 16 15 0\n4 4 1 0x0002\n0x0008 >> 2\n00: beq a0, 10, else\n 04: li v0, 0\n 08: b end\nelse: 0C: li v0, 1\nend: 10: ...\nthe branch offset for this beq PC\nis:\ntarget \u2013 (branch address + 4)\n=\n12 \u2013 (0 + 4) = 8"
        },
        {
            "lecture": 16,
            "content": "The Register File\nand Building an ALU\nOriginal slides by: Jarrett Billingsley\nModified with bits from: Bruce\nChilders, David Wilkinson\n#10\nThe Register File\n2\nAbstracting out the flip-flops.\nControl Registers\nDatapath\nProcessor\nMemory\nRemember this?\nUnresolved questions:\n\u25cf What's the control?\n\u25cf What's the datapath?\n\u25cf How does it know what\ninstruction to get next?\n\u25cf How does it know what\nregisters to access?\n\u25cf How does it know to add,\nsubtract, etc.?\n3\nProgram\ninstruction 3 5\n+\n8 A B\nC\nZooming in\n\u25cf There are a few major parts of any CPU:\n4\nControl\nRegisters Datapath\nt0 s4\nat\nfp\nsp eax?\n+ - \u00d7 \u00f7\n\u2295\u222b &\nregisters hold the\nvalues being computed\nthe datapath computes\nnew values\n\u2603\nif(add)\n do this\nelse if...\nvalues move\nbetween them\nthe control tells\neverything else what\nto do, and when\ncontrol signals!\n...oh yeah, memory too\nA bit less abstract\n\u25cf The registers are grouped together into the register file\n\u25cf The ALU (arithmetic and logic unit) is the main part of the datapath\n\u25cf The control is doing its thing, somehow\u2026? (we\u2019ll see)\n5\nControl\nRegister\nFile\nALU\nwe can get the values of two\nregisters at once\nIt doesn't have to be this way\n6\nCISC CPUs usually have small\nsets of registers, and many have\nspecial purposes or behaviors\nRISC CPUs usually have 32* mostlyinterchangeable registers: MIPS,\nRISC, SPARC, ARMv8, RISC-V\u2026\n8086\nax\nbx\ncx\ndx\nsi\ndi\nsp\nbp\n6502\nA\nX\nY\nz80\na f\nb c\nd e\nh l\nix\niy\nsp\nPDP8\nAC\n*or 32 at a time\nr0 r1 r2 r3 r4 r5 r6 r7\nr8 r9 r10 r11 r12 r13 r14 r15\nr16 r17 r18 r19 r20 r21 r22 r23\nr24 r25 r26 r27 r28 r29 r30 r31\nwhy is this? well, what do you\nremember about the differences\nbetween RISC and CISC?\n32/64\nbits\n16 bits\n8 bits\n12 bits\nTug-of-war\n\u25cf Register file design is constrained by many competing factors\n7\ncompilers love lots of\nidentical registers!\nmore registers means\nmore silicon\u2026\nhumans like intuitive\nassembly language!\nISA says instructions\nhave 2 operands\nand 1 destination\nwith lots of registers,\nfunction calls are faster!\n\u2026except for this one\ninstruction that has\n2 destinations. multi-issue CPU: need to\nread 4 regs and write 2\n\u2026but context switches\nare slower.\n\u2026but there are diminishing returns.\nfast L1 cache? not as\nmany regs needed\nD\nD Q D QQ\nA word of advice\n\u25cf You will see many imperfect designs in your life\n\u25cf But in problem-solving, perfection isn't always the goal\no everyone has to work within the constraints they're given\n\u25cf and if everyone does something the same way\u2026\no there are probably problems/constraints you don't know about\no don't waste your time reinventing the wheel.\n\u00a7 find out why it's done that way first.\n\u25cf When it comes to register files, 32 registers is just a nice number\no not too many, not too few, a nice middle-ground\n\u25cf also don't be a judgmental ass about someone else's design because one, it's shitty, and two, they know more about why\nit was designed that way, so you're just being presumptuous\n8\nSoooo registers\u2026 How do we create a register?\n\u25cf If we create a 32-bit register out of D Flip-Flops:\n9\nD Q\nD Flip-Flop\nD Q\nD Flip-Flop\nD Q\nD Flip-Flop\nD Q\nD Flip-Flop\n3rd bit 2nd bit 1st bit 0th bit\nWe abstract\naway to this:\nThankfully, so\ndoes Logisim!\nD Q\nRegister\n32 32\nRegister File\nCombined into\u2026\n\u25cf Then, we can combine many of those together:\n10\nD Q\nRegister\n32 32\nD Q\nRegister\n32 32\nD Q\nRegister\n32 32\n\u2026\nThe MIPS register file\n\u25cf In the instruction add t0, t1, t2, how many registers are read?\no how many are written?\no how many different registers are accessed?\n11\nRegister\nFile\nthere's one input or\nwrite port\nthere are two output\nor read ports\neach port can read a\ndifferent register it needs a clock signal.\nwhat other control\nsignals does it need?\nhow about a\nwrite enable?\nand inputs to select\nthe registers?\nWE rd rs rt\nReading from one register\n\u25cf You have two registers, and you want to choose one to read\n12\n83\nD Q\nWE\n29\nD Q\nWE\nA\nB\nwhat kind of component chooses?\n0\n83\n1\n29\nreading from a register is\ntechnically combinational\na read port is made of a\nselect signal, a MUX, and a\ndata output\nWE = 1\nWE = 1\nWriting\n\u25cf For the write port, we only want to write to one register at a time\n\u25cf We'll have a select signal again\u2026\n13\n83\nD Q\nWE\n29\nD Q\nWE\nA\nB\nwhen should we write to A?\nwhen should we write to B?\nselect = 0\nselect = 1\nDo we ALWAYS write to a\nregister?\nHow about in\nbeq A, 3, top?\nClose the door\n\u25cf when a register's write enable is 0, what happens to the data?\n\u25cf so we can hook up the data input to all registers at once.\n14\n83\nD Q\nWE\n29\nD Q\nWE\nA\nB\nonly the register with\nWE=1 will store the data\nData\nChekhov's Gun\n\u25cf there's a component we haven't seen in a while which only sends an input value to\none of its outputs (demux)\n15\n83\nD Q\nWE\n29\nD Q\nWE\nA\n01 B\na write port is made of a select signal, a data\ninput, a write enable, and some kinda logic to\nsend the write enable to one register\nWE\nWE\nWE0\n0\nThe Register File\n\u25cf And then, we can abstract our subcircuit to the following:\no This presumes we have 32 registers which are 32-bits in size\no (like MIPS!)\n16\nRegister File\n32\nWriteData\n32\nReadData1\n32\nReadData2\nWriteEnable\n5\nReadRegister1\n5\nReadRegister2\n5\nClock\nWriteRegister\nDiving in\n\u25cf We have a complete register file!\n\u25cf Now\u2026 let\u2019s look more closely at building an ALU.\n17\nControl\nRegister\nFile\nALU\nBuilding Out a Basic ALU\n18\nDoing the stuff.\nStarting small, the one-bit adder\n\u25cf Who remembers how to use an adder to subtract?\n19\n+ Result\nA\nB\nCarry in\nCarry out\nStarting small, the one-bit adder\n\u25cf Here is a simple ALU. It can Add A and B together.\no There are a few control signals leading into it and several outputs.\no Consider how this ALU subcircuit, as it is, can perform \u201cA \u2013 B\u201d\n20\n0\n1\n+ Result\nA\nB\nCarry in\nBinvert\nCarry out\nThis is a\nMUX\nA basic 1-bit ALU \u2013 Addition\n21\n0\n1\n+\nResult\nA\nB\nBinvert Carry in\nCarry out\n0 0\nPut it in a\nbox\nA basic 1-bit ALU \u2013 Subtraction\n22\n0\n1\n+\nResult\nA\nB\nBinvert Carry in\nCarry out\n1 1\n2s Complement\n1- Invert 2-Add one\nA basic 1-bit ALU \u2013 Expanding the adder\nALU \u2013 Arithmetic and Logic Unit\n\u25cf This ALU can perform the\narithmetic operations add,\nand subtract.\n\u25cf And the logic operations\nAND, OR, and NOT\n\u25cf Operation is selected by\nthe signal Operation:\n(2-bits)\n00 \u2013 AND; 01 \u2013 OR;\n10 \u2013 ADD; 11 \u2013 SLT\n23\n0\n1\n+\n0\n1\n2\n3\n2\nResult\nB\nLess\nBinvert Carry in Operation\nCarry out\nA\nA basic 1-bit ALU \u2013 Addition\n24\n0\n1\n+\n0\n1\n2\n3\n2\nResult\nA\nB\nLess\nBinvert Carry in Operation\nCarry out\n0 0 10\nThe other\noutputs are\nbeing\ncalculated.\nBut not\npropagated\nA basic 1-bit ALU \u2013 Subtraction\n25\n0\n1\n+\n0\n1\n2\n3\n2\nResult\nBinvert Carry in Operation\nCarry out\n1 1 10\nA\nB\nLess\nA basic 1-bit ALU \u2013 AND\n26\n0\n1\n+\n0\n1\n2\n3\n2\nResult\nBinvert Carry in Operation\nCarry out\n0 00\nA\nB\nLess\nX\nA basic 1-bit ALU \u2013 OR\n27\n0\n1\n+\n0\n1\n2\n3\n2\nResult\nBinvert Carry in Operation\nCarry out\n0 01\nA\nB\nLess\nX\nA basic 1-bit ALU \u2013 NAND and NOR?\nRemember Boolean algebra?\n28\n\ufffd \ufffd \ufffd\ufffd\n0 0 1\n0 1 1\n1 0 1\n1 1 0\n\ufffd \ufffd \ufffd + \ufffd\n1 1 1\n1 0 1\n0 1 1\n0 0 0\n\ufffd\ufffd = \ufffd + \ufffd\n\ufffd \ufffd \ufffd + \ufffd\n0 0 1\n0 1 0\n1 0 0\n1 1 0\n\ufffd \ufffd \ufffd. \ufffd\n1 1 1\n1 0 0\n0 1 0\n0 0 0\n\ufffd + \ufffd = \ufffd. \ufffd\nA basic 1-bit ALU \u2013 NAND\n29\n0\n1\n+\n0\n1\n2\n3\n2\nResult\nBinvert Carry in Operation\nCarry out\n1 01\n0\n1\nAinvert\n1\nA\nB\nLess\nWe need to\nadd another\ninverter and\nmutex\nX\nA basic 1-bit ALU \u2013 NOR\n30\n0\n1\n+\n0\n1\n2\n3\n2\nResult\nBinvert Carry in Operation\nCarry out\n1 00\n0\n1\nAinvert\n1\nA\nB\nLess\nX\nA basic 1-bit ALU, with overflow detection\n\u25cf This ALU can detect overflow\n\u25cf Also allows to perform the SLT operation!\n\u25cf Remember the slt instruction?\nblt t0, t1, label\no It\u2019s equivalent to\nslt at, t0, t1\nbne at, zero, label\n\u25cf SLT \u2013 Set if Less Then\no \u201cSet\u201d = 1 if a<b\no \u201cSet\u201d = 0 if a>=b\n31\n0\n1\n+\n0\n1\n2\n3\n2\nResult\nB\nLess\nOperation\nCarry in\nBinvert\nCarry out\nSet\nOverflow\nA\n0\n1\nAinvert\nA basic 1-bit ALU, with overflow detection\n\u25cf This ALU can detect overflow\n\u25cf Also allows to perform the SLT operation!\n\u25cf Remember the slt instruction?\nblt t0, t1, label\no It\u2019s equivalent to\nslt at, t0, t1\nbne at, zero, label\n\u25cf SLT \u2013 Set if Less Then\no \u201cSet\u201d = 1 if a<b\no \u201cSet\u201d = 0 if a>=b\n\u25cf What is the propagation delay?\n32\n0\n1\n+\n0\n1\n2\n3\n2\nResult\nB\nLess\nOperation\nCarry in\nBinvert\nCarry out\nSet\nOverflow\nA\n0\n1\nAinvert\nAssume: Not: 2ns, Mux: 6ns,\nAdder: 10ns, AND/OR/XOR: 4ns (26ns)\nBuilding it up!\n\u25cf Combine multiple 1-bit ALUs\n\u25cf We can combine the Binvert and\nCarry in signals\no They are used simultaneously\nfor subtractions\no Otherwise, we don\u2019t care about\nthe Carry in\n33\n2 Ainvert Bnegate Operation\nALU 0\nALU 1\nALU 2\nCarry out\nCarry out\nCarry out\nA0\nA1\nA2\nA31\nCarry in\nCarry in\nCarry in\nCarry in\nB0\nB1\nB2\nB31\n0\n0\n0\nLess\nLess\nLess\nLess\nALU 31 Set\nCarry out\nOverflow\nResult31\nResult2\nResult1\nResult0\n0 1 10\n1\n0\n0\n0\n1\nCarry in can be\nconnected to\nBinvert\nImplementing SLT \u25cf SLT uses subtraction\nslt at, t0, t1\nt0<t1: t0\n-t1<0\no Set is 1\n\u25cf Note how Set is connected to\nALU0\u2019s Less input\n\u25cf Could we use Result31 instead? o No, note how the output is 0,\nnot\n1\n34\n2 Ainvert Bnegate Operation\nALU 0\nALU 1\nALU 2\nCarry out\nCarry out\nCarry out\nA\n0\nA\n1\nA\n2\nA31\nCarry in\nCarry in\nCarry in\nCarry in\nB\n0\nB\n1\nB\n2\nB31 000\nLess\nLess\nLess\nLess\nALU 31 Set\nCarry out\nOverflow\nResult31\nResult\n2\nResult\n1\nResult\n0\n0\n1 11\n1000\n1\nA 32-bit ALU\n35\n2 Ainvert Bnegate Operation\nALU 0\nALU 1\nALU 2\nCarry out\nCarry out\nCarry out\nA0\nA1\nA2\nA31\nCarry in\nCarry in\nCarry in\nCarry in\nB0\nB1\nB2\nB31\n0\n0\n0\nLess\nLess\nLess\nLess\nALU 31 Set\nCarry out\nOverflow\nResult31\nResult2\nResult1\nResult0\nZero\nAs we saw when we\ntalked about overflow.\nIt can be detected in\nthe MSB\nE.g. beq, bne\nZero detection is so\ncommon that is usually\nsupported by ALUs\n32\n32\n32\nALU operation\nA\nB\n4\nResult\nZero\nOverflow\nALU\nA basic 32\n-bit ALU?\n\u25cf ALUs are many times in the\nreal world built as multiple 1-bit ALUs. o Called bit-slicing\n\u25cf However, we can happily\nlive in our ideal world for a\nbit longer!\n\u25cf We can build it much like\nthe 1\n-bit model, but just tell\nLogisim to make the\ncomponents\u2019 \u201cData Size\u201d\n32\n-bits.\no i.e., for your project.\n\u25cf Whew!\n36\n01\n+\n0123\n2\nResult\nBnegate Operation\nCarry out\n1 00\n01\nAinvert 1\nAB\n<\nOverflow\nZooming Out Again\n\u25cf Now, how to we wire up the Register File with the ALU??\no How do we know which registers to use?\no How do we pull in instructions?\n\u25cf Tune in next time for\u2026\no Control and Datapath"
        },
        {
            "lecture": 14,
            "content": "How ICs are made in 3 slides\n(another For Fun\u2122 section)\n3\nHow ICs (integrated circuits) are made\n\u25cf silicon is purified and grown into a\nmonolithic crystal (extremely expensive)\n\u25cf this is sliced thinly to make wafers\no gooey caramel is put between them to make stroopwafel\n\u25cf a series of complicated photochemical\nprocesses do things like:\no change its electrical properties\no make wires to connect things\no make inert insulating layers\n4\nHow ICs (integrated circuits) are made\n\u25cf many ICs are printed on one wafer\n\u25cf the wafers are diced (chopped up)\n\u25cf the ICs are tested\n\u25cf the ICs are mounted in a package ->\n\u25cf they're tested again\n\u25cf then they're ready to sell\n5\nManufacturing yield\n\u25cf ICs are tiny and complex\n\u25cf silicon crystals can have defects\n\u25cf a tiny speck of dust during production can ruin an entire chip\n\u25cf the yield is the percentage of usable chips\no bigger chips have smaller yields: more opportunities for mistakes!\n\u25cf the size of the silicon is the biggest factor in the price of an IC\no huge ICs (several cm on each side!), such as very high-resolution camera\nsensors, can cost tens of thousands of dollars!\n\u25cf manufacturers can also bin resulting chips\no bug-free ones can be sold as Core i7s for lotsa money\no slightly malformed ones can be sold as Core i5s and i3s\no the ones they sweep off the floor are the Celerons\n6\nLogic Minimization\n7\nSilicon is expensive, rocks are slow\n\u25cf Logic minimization means using the smallest number of gates/transistors\npossible to implement a boolean function\no a boolean function is anything we've talked about\no it has boolean inputs, and boolean outputs\n\u00a7 Less inputs can also improve speed\n\u25cf Fewer transistors means:\no smaller area:\n\u00a7 cheaper chips!\n\u00a7 more stuff on one chip!\n\u00a7 smaller chance of manufacturing defects!\no less gate delay:\n\u00a7 faster circuits!\n8\nBoolean algebra\n\u25cf Idempotent\no \ufffd. \ufffd = \ufffd + \ufffd = \ufffd\n\u25cf Commutative\no \ufffd. \ufffd = \ufffd. \ufffd\no \ufffd + \ufffd = \ufffd + \ufffd\n\u25cf Associative\no \ufffd. \ufffd. \ufffd = \ufffd. \ufffd . \ufffd\no \ufffd + \ufffd + \ufffd = \ufffd + \ufffd + \ufffd\n\u25cf Distributive\no \ufffd. \ufffd + \ufffd = \ufffd. \ufffd + \ufffd. \ufffd\no \ufffd + \ufffd. \ufffd = \ufffd + \ufffd . (\ufffd + \ufffd)\n9\n\u25cf De Morgan\u2019s laws\no \ufffd. \ufffd = \ufffd) + \ufffd)\no \ufffd + \ufffd = \ufffd). \ufffd)\n\u25cf Other\no \ufffd + \ufffd. \ufffd = \ufffd\no \ufffd. \ufffd + \ufffd = \ufffd\no \ufffd)) = \ufffd\no \ufffd + \ufffd) = 1\no \ufffd. \ufffd) = 0\nMinimizing Booleans\n\u25cf How do we minimize Boolean functions?\no Logical adjacency!\n\u25cf If in two Boolean terms being ORed only one of the variables changes then it\ncan be removed\no \ufffd = \ufffd\ufffd$ + \ufffd\ufffd = \ufffd \ufffd$ + \ufffd = \ufffd\no \ufffd = \ufffd\ufffd$\ufffd + \ufffd\ufffd$\ufffd$ = \ufffd\ufffd$ \ufffd + \ufffd$ = \ufffd\ufffd$\n\u25cf To minimize a Boolean expression\no Find the terms where only one variable changes\no Eliminate that variable\n10\nA first try\n\u25cf The truth table for a two-input 1-bit\nmultiplexer.\n11\nS A B Q\n0 0 0\n0 0 1\n0 1 0\n0 1 1\n1 0 0\n1 0 1\n1 1 0\n1 1 1\n0\n0\n1\n1\n0\n1\n0\n1\nQ\nA\nB\nS=0\nA\nQ\nB\nS=1\nS Q\n0 A\n0 A\n0 A\n0 A\n1 B\n1 B\n1 B\n1 B\nA first try\n\u25cf The truth table for a two-input 1-bit multiplexer.\n12\nS A B Q\n0 0 0\n0 0 1\n0 1 0\n0 1 1\n1 0 0\n1 0 1\n1 1 0\n1 1 1\n0\n0\n1\n1\n0\n1\n0\n1\n\ufffd!\ufffd\ufffd$\n\ufffd!\ufffd\ufffd\n\ufffd\ufffd$\ufffd\n\ufffd\ufffd\ufffd\n\ufffd = \ufffd!\ufffd\ufffd$ + \ufffd!\ufffd\ufffd + \ufffd\ufffd$\ufffd + \ufffd\ufffd\ufffd\n\ufffd = \ufffd!\ufffd + \ufffd!\ufffd + \ufffd\ufffd + \ufffd\ufffd\nWell\u2026 I guess we don\u2019t need\nthose variables\nAre there any adjacencies?\n\ufffd = \ufffd!\ufffd + \ufffd\ufffd\nThis seems easy\u2026\nIt makes sense, right? \u25cf We know that if S=0 then the output is A \u25cf We know that if S=1 then the output is B o We don\u2019t care about one of the variables \u25cf So, let\u2019s solve this truth table\n1. find all rows with an output of 1\n2. for each one, write an AND of all the inputs,\nwith NOTs on the 0s\n3. eliminate duplicate terms\n4. OR the remaining terms together \ufffd = \ufffd+\ufffd + \ufffd\ufffd\n\u25cf Getting the sum\n-of\n-products\no an OR of multiple ANDed terms\n13\nS\nA\nB\nQ\n0\n0\nX\n0\n0\n0\nX\n0\n0\n1\nX\n1\n0\n1\nX\n1\n1\nX\n0\n0\n1\nX\n1\n1\n1\nX\n0\n0\n1\nX\n1\n1\n\ufffd!\n\ufffd\n\ufffd!\n\ufffd\n\ufffd\ufffd\n\ufffd\ufffd\nTurning that expression into gates\n\u25cf making \ufffd = \ufffd)\ufffd + \ufffd\ufffd into gates is pretty straightforward:\n14\nA\nS\nB\nQ\nMinimization using Boolean\nAlgebra\n15\nWhat if the function is more complex?\n\u25cf if we use that method on the Cout of a full adder:\n16\nA B Cin Cout\n0 0 0 0\n0 0 1 0\n0 1 0 0\n0 1 1 1\n1 0 0 0\n1 0 1 1\n1 1 0 1\n1 1 1 1\n\ufffd$\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd$\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd = \ufffd$\ufffd\ufffd\ufffd\ufffd + \ufffd\ufffd$\ufffd\ufffd\ufffd + \ufffd\ufffd\ufffd\ufffd\ufffd + \ufffd\ufffd\ufffd\ufffd\ufffd\n\u25cf It feels too complex, somehow\n\u25cf each NOT gate uses 2 transistors\n\u25cf each AND/OR gate uses 6\n\u25cf this will use 72 transistors\no just for the carry\no of one one-bit addition\nMinimizing equations \u2013WHYYYYY!!\n\ufffd\ufffd\ufffd + \ufffd\ufffd\ufffd + \ufffd\ufffd\ufffd + \ufffd\ufffd\ufffd\nUsing distributivity\ufffd\ufffd\ufffd + \ufffd\ufffd\ufffd = \ufffd\ufffd \ufffd + \ufffd :\n\ufffd\ufffd \ufffd + \ufffd + \ufffd\ufffd\ufffd + \ufffd\ufffd\ufffd\nAdjacency #1 tackled:\n\ufffd\ufffd + \ufffd\ufffd\ufffd + \ufffd\ufffd\ufffd\nWhat about now? Two variables change L\n17\n72 transistors\nMinimizing equations \u2013WHYYYYY!!\n\ufffd\ufffd\ufffd + \ufffd\ufffd\ufffd + \ufffd\ufffd\ufffd + \ufffd\ufffd\ufffd\nAdding (ORing) the same term multiple times is ok:\n\ufffd\ufffd + \ufffd\ufffd\ufffd + \ufffd\ufffd\ufffd + \ufffd\ufffd\ufffd + \ufffd\ufffd\ufffd\nNote the two adjacencies :D\n\ufffd\ufffd + \ufffd\ufffd \ufffd + \ufffd + \ufffd\ufffd \ufffd + \ufffd\nAdjacency #2 and #3 tackled:\n\ufffd\ufffd + \ufffd\ufffd + \ufffd\ufffd\n18\n30 transistors\nIt\u2019s hard!\nIf only we had a better tool to help us\n19\nKarnaugh Maps\n20\nGray Code \u25cf Gray code is a way of encoding binary where\nonly one bit changes on each step\n\u25cf How can we construct it? \u25cf Let\u2019s revisit our binary number table: o Start by creating the first two 1-bit entries o Mirror them and complete the next column o Repeat! \u25cf See how only one bit changes from the\nlast to the first number!\n\u25cf We\u2019ll only be using 2\n-bit code.\n21\n0110\n0011\n00001111\n1100\n0110\n1 0\n1 1\nKarnaugh Maps (K-maps) \u2013 Setting up\n\u25cf Karnaugh Maps are a tool for minimizing boolean functions\n\u25cf It helps us finding adjacencies\no let's start with a function that has two inputs\n22\nA B Q\n0 0 1\n0 1 0\n1 0 1\n1 1 1\nTruth Table\n\ufffd! \ufffd\n\ufffd!\n\ufffd\nK-map\n0\n1. Karnaugh maps are\nrepresented as a table\n2. write input values in Gray\ncode along axes.\no (there's only one input on\neach side here, it's easy)\n3. Fill in cells from truth table. 1\n0 1\nKarnaugh Maps (K-maps) \u2013 Finding rects\n23\n1 0\n1 1\n\ufffd! \ufffd\n\ufffd!\n\ufffd\nK-map 3. find rectangles of 1s with these rules:\no width and height can only be 1, 2, or 4\n\u00a7 NEVER 3\no overlapping is totally fine! it's good!\no use the biggest rectangles possible\no use the fewest rectangles possible\n1 0\n1 1\n\ufffd! \ufffd\n\ufffd!\n\ufffd\nKarnaugh Maps (K-maps) \u2013 Interpreting rects\n24\nK-map 4. for each rectangle, look at the values of\nthe variables along the axes. some\nvariables change, and others don't.\no which variable changes in the red\nrectangle? which doesn't?\no what about the blue rectangle?\n5. each rectangle is an AND minterm\no write the variables that stay the same\nfor that rect (keeping the NOT bars)\no ignore the variables that change\n6. OR all the terms together\n7. WHEW!\n\ufffd = \ufffd + \ufffd$\nRed: \ufffd$ Blue: \ufffd\nI'd like to place an order for the carry-out bit\n\u25cf With more than 2 variables, put two along one axis (GRAY CODE!)\n25\n0 0 1 0\n0 1 1 1\n\ufffd!\ufffd! \ufffd!\ufffd \ufffd\ufffd \ufffd\ufffd!\n\ufffd$\n\ufffd\n00\n0\n\ufffd\ufffd\n= \ufffd\ufffd + \ufffd\ufffd + \ufffd\ufffd\nRed: \ufffd\ufffd\nGreen: \ufffd\ufffd\nBlue: \ufffd\ufffd\n01 11 10\ntry to make the rectangles as big as\npossible. overlap is goooood. C A B Co\n0 0 0 0\n0 0 1 0\n0 1 0 0\n0 1 1 1\n1 0 0 0\n1 0 1 1\n1 1 0 1\n1 1 1 1\n1\nI'd like to place an order for the carry-out bit\n\u25cf With more than 2 variables, put two along one axis (GRAY CODE!)\n26\n0 0 1 0\n0 1 1 1\n\ufffd!\ufffd! \ufffd!\ufffd \ufffd\ufffd \ufffd\ufffd!\n\ufffd$\n\ufffd\n00\n0\n01 11 10\ntry to make the rectangles as big as\npossible. overlap is goooood. C A B Co\n0 0 0 0\n0 0 1 0\n0 1 0 0\n0 1 1 1\n1 0 0 0\n1 0 1 1\n1 1 0 1\n1 1 1 1\n1\nDid you notice this? \ufffd\ufffd\ufffd\nThis is the term we needed to add multiple times :D\nJust like a 2D RPG world map\u2026\n\u25cf rectangles on K-maps can wrap around (left-right AND top-bottom!)\n27\n1 1 0 1\n1 0 0 1\n\ufffd!\ufffd! \ufffd!\ufffd \ufffd\ufffd \ufffd\ufffd!\n\ufffd$\n\ufffd\nRed: \ufffd$\n\ufffd = \ufffd! + \ufffd!\ufffd$\nthis is really a 2x2 rectangle.\nit's just\u2026 doing its best.\nBlue: \ufffd$\ufffd!\n00\n0\n01 11 10\n1\nOkay, maybe it's not perfect.\n\u25cf let's try the Sum output of a full adder\n28\n0 1 0 1\n1 0 1 0\n\ufffd!\ufffd! \ufffd!\ufffd \ufffd\ufffd \ufffd\ufffd!\n\ufffd!\ufffd\n\ufffd\ufffd\n\ufffd\ufffd\ufffd = \ufffd!\ufffd!\ufffd + \ufffd!\ufffd\ufffd! + \ufffd\ufffd\ufffd + \ufffd\ufffd!\ufffd!\nRed: \ufffd$\ufffd$\ufffd\nGreen: \ufffd$\ufffd\ufffd$\nBlue: \ufffd\ufffd\ufffd\ufffd\nPurple: \ufffd\ufffd$\ufffd$\na 1x1 rectangle\nbecomes a term that\nuses all the variables\nwait, can\u2019t we do that as:\n\ufffd\ufffd\ufffd = \ufffd\u2a01\ufffd\u2a01\ufffd (that's xor!)\n00\n0\n01 11 10\n1\nTradeoffs, tradeoffs\n\u25cf there are extensions to K-maps to detect XORs\n\u25cf but\u2026\no XOR gates are slower than AND/OR gates\no if area is a concern, an XOR make sense\no if speed is a concern, AND/OR gates make sense\n\u25cf what do real hardware designers do?\no they use programs to do this stuff for them lol\no things like GALs, CPLDs, and FPGAs are reconfigurable hardware which\nusually use \"sum-of-products\" to do logic, so ANDs and ORs are all you've\ngot\n29\nSome more examples\n\u25cf Can you solve this?\n30\n0 0 0 0\n0 0 0 0\n0 1 1 0\n0 1 1 0\n\ufffd!\ufffd! \ufffd!\ufffd \ufffd\ufffd \ufffd\ufffd!\n\ufffd!\ufffd!\n\ufffd!\ufffd\n\ufffd\ufffd\n\ufffd\ufffd!\n00\n00\n01 11 10\n01\n11\n10\n\u25cf In AB: A is both {0,1}\n\u25cf In CD: D is both {0,1}\n\u25cf Eliminate both A,D\n\u25cf We get\n\ufffd\ufffd\nSome more examples\n\u25cf Can you solve this?\n31\n0 0 0 0\n1 1 1 1\n1 1 1 1\n0 0 0 0\n\ufffd!\ufffd! \ufffd!\ufffd \ufffd\ufffd \ufffd\ufffd!\n\ufffd!\ufffd!\n\ufffd!\ufffd\n\ufffd\ufffd\n\ufffd\ufffd!\n00\n00\n01 11 10\n01\n11\n10\n\u25cf In AB: Both have {0,1}\n\u25cf In CD: C is both {0,1}\n\u25cf Eliminate both A, B, C\n\u25cf We get\n\ufffd\nSome more examples\n\u25cf Can you solve this?\n32\n1 0 0 1\n0 0 0 0\n0 0 0 0\n1 0 0 1\n\ufffd!\ufffd! \ufffd!\ufffd \ufffd\ufffd \ufffd\ufffd!\n\ufffd!\ufffd!\n\ufffd!\ufffd\n\ufffd\ufffd\n\ufffd\ufffd!\n00\n00\n01 11 10\n01\n11\n10\n\u25cf In AB: A has both {0,1}\n\u25cf In CD: C is both {0,1}\n\u25cf Eliminate both A, C\n\u25cf We get\nB$ \ufffd$\nthis is still a 2x2 rectangle!\n7 segment LED display\n\u25cf This is a 7 segment LED display\no It displays numbers\no It has 8 LEDs (one for the decimal point)\n\u25cf Problem\no Given a 4-bit number, draw the\ncorresponding numeral.\no E.g. 0000 is \u201c0\u201d; 1001 is \u201c9\u201d.\no Ignore the dot\n\u25cf Solution\no Create a Boolean function for each\nsegment.\n33\nd1\nd2\nd0\nd3\nd4\nd5\nd6\nd7\n7 segment LED display\n34\nd1\nd2\nd0\nd3\nd4\nd5\nd6\nd7 Hex Digit LED\n7 segments, 1 decimal point\nTurn each segment on/off\n State: 0=OFF, 1=ON\n\u201cDraw\u201d numbers 0 to 9\nNumber 0\n01110111\nd0 d7\n7 segment LED display\n35\nd1\nd2\nd0\nd3\nd4\nd5\nd6\nd7 Hex Digit LED\n7 segments, 1 decimal point\nTurn each segment on/off\n State: 0=OFF, 1=ON\n\u201cDraw\u201d numbers 0 to 9\nNumber 1\n00101000\nd7 d0\n7 segment LED display\n36\nd1\nd2\nd0\nd3\nd4\nd5\nd6\nd7 Hex Digit LED\n7 segments, 1 decimal point\nTurn each segment on/off\n State: 0=OFF, 1=ON\n\u201cDraw\u201d numbers 0 to 9\nNumber 2\n11001101\nd7 d0\n7 segment LED display\n37\nd1\nd2\nd0\nd3\nd4\nd5\nd6\nd7 Hex Digit LED\n7 segments, 1 decimal point\nTurn each segment on/off\n State: 0=OFF, 1=ON\n\u201cDraw\u201d numbers 0 to 9\nNumber 3\n01101101\nd7 d0\n7 segment LED display\n38\nd1\nd2\nd0\nd3\nd4\nd5\nd6\nd7 Hex Digit LED\n7 segments, 1 decimal point\nTurn each segment on/off\n State: 0=OFF, 1=ON\n\u201cDraw\u201d numbers 0 to 9\nNumber 4\n00101011\nd7 d0\n7 segment LED display\n39\nd1\nd2\nd0\nd3\nd4\nd5\nd6\nd7 Hex Digit LED\n7 segments, 1 decimal point\nTurn each segment on/off\n State: 0=OFF, 1=ON\n\u201cDraw\u201d numbers 0 to 9\nNumber 5\n01100111\nd7 d0\n7 segment LED display\n40\nd1\nd2\nd0\nd3\nd4\nd5\nd6\nd7 Hex Digit LED\n7 segments, 1 decimal point\nTurn each segment on/off\n State: 0=OFF, 1=ON\n\u201cDraw\u201d numbers 0 to 9\nNumber 6\n11100111\nd7 d0\n7 segment LED display\n41\nd1\nd2\nd0\nd3\nd4\nd5\nd6\nd7 Hex Digit LED\n7 segments, 1 decimal point\nTurn each segment on/off\n State: 0=OFF, 1=ON\n\u201cDraw\u201d numbers 0 to 9\nNumber 7\n00101100\nd7 d0\n7 segment LED display\n42\nd1\nd2\nd0\nd3\nd4\nd5\nd6\nd7 Hex Digit LED\n7 segments, 1 decimal point\nTurn each segment on/off\n State: 0=OFF, 1=ON\n\u201cDraw\u201d numbers 0 to 9\nNumber 8\n11101111\nd7 d0\n7 segment LED display\n43\nd1\nd2\nd0\nd3\nd4\nd5\nd6\nd7 Hex Digit LED\n7 segments, 1 decimal point\nTurn each segment on/off\n State: 0=OFF, 1=ON\n\u201cDraw\u201d numbers 0 to 9\nNumber 9\n01101111\nd7 d0\n7 segment LED display\nHow to approach this?\n\u25cf Create a truth table\no Inputs are i0 to i3 (4 bits)\no Outputs are numbered d0, to d7, corresponding to segments\n\u25cf Minimize the circuit using a K-map\no Create the table\no Follow the rules!\n\u25cf Draw the numerals by setting d0 to d7 to 1s or 0s\no Build the circuit!\n44\n45\n7 segment LED display\ni3 i2 i1 i0 d0 d1 d2 d3 d4 d5 d6 d7\n0 0 0 0 0 1 1 1 0 1 1 1\n0 0 0 1 0 0 0 1 0 1 0 0\n0 0 1 0 1 0 1 1 0 0 1 1\n0 0 1 1 1 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026\n0 1 0 0 1 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026\n0 1 0 1 1 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026\n0 1 1 0 1 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026\n0 1 1 1 0 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026\n1 0 0 0 1 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026\n1 0 0 1 1 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026\n1 0 1 0 X X X X X X X X\n\u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026\n46\n7 segment LED display\ni3 i2 i1 i0 d0 d1 d2 d3 d4 d5 d6 d7\n0 0 0 0 0 1 1 1 0 1 1 1\n0 0 0 1 0 0 0 1 0 1 0 0\n0 0 1 0 1 0 1 1 0 0 1 1\n0 0 1 1 1 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026\n0 1 0 0 1 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026\n0 1 0 1 1 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026\n0 1 1 0 1 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026\n0 1 1 1 0 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026\n1 0 0 0 1 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026\n1 0 0 1 1 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026\n1 0 1 0 X X X X X X X X\n\u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026\nIt can only\ndisplay\nnumbers up\nto 9!\nSo we \u201cdon\u2019t\ncare\u201d about\nthe outputs\nfor larger\nnumbers\n\u25cf Now use a K\n-map for each output\nfunction d0\n-d7\n- Let\u2019s start with d0\n47\n7 segment LED display 0 0 1\n1\n1\n1\n0\n1\nX\nX\nX\nX\n1\n1\nX\nX\n\ufffd!\ufffd\n\ufffd!\ufffd\n\ufffd!\ufffd\n\ufffd\n\ufffd\n\ufffd\n\ufffd\n\ufffd\n\ufffd\n\ufffd\n\ufffd\n\ufffd!\ufffd\n\ufffd!\ufffd\n\ufffd!\ufffd\n\ufffd!\ufffd\n\ufffd\n\ufffd\n\ufffd\n\ufffd\n\ufffd\n\ufffd\n\ufffd\n\ufffd\n\ufffd!\ufffd\n00\n00\n01 11 10\n01\n11\n10\ni3 i2 i1 i0 d0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 0 0 0 1 1 0 0 1 1 1 0 1 0 X \u2026 \u2026 \u2026 \u2026 \u2026\n\u25cf Now use a K-map for each output function d0-d7\n\u25cf Let\u2019s start with d0\n48\n7 segment LED display\n0 0 1 1\n1 1 0 1\nX X X X\n1 1 X X\n\ufffd\n!\n\ufffd\ufffd\n!\n\ufffd \ufffd\n!\n\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\n!\n\ufffd\n\ufffd\n!\n\ufffd\ufffd\n!\n\ufffd\n\ufffd\n!\n\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\n!\n\ufffd\n00\n00\n01 11 10\n01\n11\n10\nOutput\n\u201cdon\u2019t cares\u201d\ncan be\nwhatever we\nneed them to\nbe J\n\u25cf Four minterms:\no \ufffd\ufffd\no \ufffd\ufffd\ufffd\ufffd\no \ufffd\ufffd\ufffd\ufffd\no \ufffd\ufffd\ufffd\ufffd\n49\n7 segment LED display\n0 0 1 1\n1 1 0 1\nX X X X\n1 1 X X\n\ufffd\n!\n\ufffd\ufffd\n!\n\ufffd \ufffd\n!\n\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\n!\n\ufffd\n\ufffd\n!\n\ufffd\ufffd\n!\n\ufffd\n\ufffd\n!\n\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\n\ufffd\ufffd\ufffd\n!\n\ufffd\n00\n00\n01 11 10\n01\n11\n10\n\ufffd\ufffd = \ufffd\ufffd + \ufffd\ufffd\ufffd\ufffd + \ufffd\ufffd\ufffd\ufffd + \ufffd\ufffd\ufffd\ufffd\nOn the lab\n\u25cf You will be making a circuit in Logisim using the 7 segment LED display\no Find it in input/output\n\u25cf Connect the logic you just solved into d0 (top-left pin) and test it\n\u25cf Solve for the remaining segments"
        },
        {
            "lecture": 15,
            "content": "The Latch\n3\nWhat the heck\n\u25cf Time to blow your mind.\n\u25cf Let\u2019s look at this circuit.\no Yes, you can do this.\n4\nR\nS\nQ\nQ\nWhat the actual heck\n\u25cf What is this in combinational logic??\no Q = R + (S + (R + (S + (R + (\u2026 oh gosh. Hmm\n\u25cf This makes no sense (from a combinational point of view)\n5\nR\nS\nQ\nQ\nS/R Latch\n\u25cf The feedback behavior allows it to \u201cstore\u201d a value.\no \u201c1\u201d on S will set Q to \u201c1\u201d, and \u201c1\u201d or R will reset Q to \u201c0\u201d\no It becomes stable at that value, hence, it is an S/R Latch.\no It\u2019s really heckin\u2019 neat.\n6\nR\nS\nQ\nQ\n(reset)\n(set)\n0\n1\nS/R Latch (animated)\n\u25cf Currently, the value is \u201c0\u201d, and we can change it to \u201c1\u201d by sending a \u201c1\u201d on S\n7\nR\nS\nQ\nQ\n1 (reset)\n(set) 0\n0\n1\n0\nStable Feedback\n1\n0\nNOR\nS/R Latch (animated)\n\u25cf Currently, the value is \u201c1\u201d, and we can maintain it by having R and S be \u201c0\u201d\n\u25cf If the value was \u201c0\u201d, this would also maintain that value.\n\u25cf This is the \u201clatch\u201d operation. This is how an S/R Latch can \u201cstore\u201d a value.\n8\nR\nS\nQ\nQ\n0 (reset)\n(set) 1\n1\nStable Feedback\n0\n0\n1\n0\nNOR\nS/R Latch (animated)\n\u25cf Currently, the value is \u201c1\u201d, and we can change it to \u201c0\u201d by sending a \u201c1\u201d on R\no And having S be \u201c0\u201d\n9\n1\n0\nR\nS\nQ\nQ\n0 (reset)\n(set)\n1\n1\n0\n0\n1\nStable Feedback\nNOR\n0\n1\n10\n01\nS/R Latch (animated)\n\u25cf Hmm, let\u2019s set R and S to \u201c1\u201d at the same time.\n\u25cf And then let\u2019s set them both to \u201c0\u201d afterward. (That should be stable\u2026 right?)\n\u25cf Oh no. Oscillation. Q is\u2026 both\u2026 0 and 1\u2026 ??? Kinda???\n10\nR\nS\nQ\nQ\n(reset)\n(set)\n1\n0\nStable Feedback\n(but illogical)\nNOR\n10\n0\n10\n01\n0\n0\n0\n0\nS/R Latch: The Whole Truth table\n\u25cf The state of this logic depends on the prior state.\no Q here is the current value of Q\no Qnext will be the new value.\n\u25cf This is an example of sequential logic.\no On your own: You can build it out of NANDs\nas well. Try to come up with that.\n11\nR\nS\nQ\nQ\n(reset)\n(set)\n0\n0\n1\noh no\n1\n0\n1\naaaa\nLet\u2019s look at some circuits\n\u25cf sr_latch.circ\n\u25cf Factorio latch\n0eNrtV8GOmzAQ/ZVqzlCB2ZANUvsFPbXHqkIOTJKRjEHGREUR/14bWjYb1iyhP\nWylPYTI2J558948AxfYiwYrRVJDcgHKSllD8v0CNR0lF/aebiuEBEhjAR5IXthRjhnlqP\nysLPYkuS4VdB6QzPEnJGH3wwOUmjThEK0ftKlsij0qs2CMY/NpLvV1IA+qsjZ7S2n\nTm3h+5EFr/kKTwmzQqhTpHk/8TGa1WXIgoVE5cJ9J6cbcGVMOK3yFOfTxGlt6eA\n1+SCMxsxhqGyu0l6NClNflUA4JM2tJZQ3pfmh3d503qZjNMTctOPi4eSo5JzVAGb\nK9QMDvmKmZy2kEfSBV63QxIUN5Q+29JpAEdlBUXPUwE/hkNpWNrpp1Yas27el\nOD6osUpImDiQHLmrsHJRbkW4Ij24J955Nx8+nmW3FF4W73RhNhfSALQPB5kG\n4miJa2RTsTTXF5xVNMZrvn7TE1IPeYrO6NWbzGm8coj481VpwIXzBi2oqZjh/ov1J\nPGq3QjouW30ieXxNPTPd1GhSidKeoVo1uJx6FwubEU2BOTWFj8JEU5T5VSnQyQ\ndbfQ7cyvPgABav81z4brl7zLFb6sjdXzjy9gTfzoNgjo7Y3tmqbGyIhVzF81yFgQPY4\n6q3JPYGX5J2y56Hu3XeZO/vSPMd57ZfPO+ox1k7xsv8FQZ3PBHZ//5A3PYsGL777\n6Xk6vPKA8H3aIDCV//bhy9cZydz72w82ZezjYJwE8X213W/ABNorVw=\n12\nLet\u2019s look at some circuits\n\u25cf Factorio power latch\n0eNrtWM2OmzAQfpVqzlBh8o+0K/XeQ+9VhRyYbCwZGxmTNop4gL5Hn6xPUh\nu6bBrCbyMlhz2EyMb+5ht/M2ObE2x5jqliQkNwAhZJkUHw9QQZexGU2z59TBEC\nYBoTcEDQxLZijFiMyo1ksmWCaqmgcICJGH9AQIpvDqDQTDOs0MrGMRR5skVlBt\nQ41p6mQp8DOZDKzMyVwpo3eO7MgaP9MybMBK0kD7e4pwdmRpshO8Y1qh\nbeB6Z0bnpqk9UI9xOUaLl1nHjeOfnKjMDIcsgsFrEPhfG5M8y0DLGIqShnumzauU\nXhNPz1u9at6S75uKgcJoZJzFRFpIS55v5fzNC8i1lNecdUpsOxy1GpAcFmY1tJSlXJ\nMYBnM0PmOs1HYL4oRFHhpsewXOtwp2QSMmFwINhRnmHxH6vt/PN61RTDAd\n9iVUS60fwLtPkwaWcTpfUfR9rfP39NENfqcztp/W5p+7T0L7W8LtZ8lFjeHdLwLGVe\n9fIu5Hp6gExcdMu1bsjhDNTN6TZTR0E/p0usZTfHtvxeTAsZ/6FC5vnu+d2spi0RM\nR8j+XxY2i9r3xKMWZ64yA1lxSI3lRybKvpvaT/NvcvY27QQW03bPO53LCDeTfaOW\n5ejvt3DG3cyWI+Dawu79aTSQd4rx5jUImRoZVmNBhpeeUgPWFuIbN7WLqGcu5\nwmaVs98lpuP6926lCYEAlUHPWeiZe+YDCv8wyNKS7tfUurHIcruWxZBJtPU8qg/z\nhl8P5pMvLysxoWn4RMqmH++4G5b0tpq1LrMVVofU1Fg1x+qwnOPu04wOkWje\nPwRX5H9eEz1dHe9B5QZaVEq5lHFrOl/RXFHz5GPCg=\n13\nThe Clock\n14\nKeeping Everything In Order\nPropagation Delay (Basics)\n\u25cf Ok. Q at t=0 is different than at t=1.\n\u25cf How long does it take for a change to occur?\no (How much time is really between t=0 and t=1)\n\u25cf This is bounded by propagation delay.\n15\nR\nS\nQ\nQ\n(reset)\n(set)\nPropagation Delay\n\u25cf Propagation delay is the time it takes for a signal to pass from the inputs\nto the outputs\n\u25cf During that delay, the outputs are invalid (they can fluctuate)\n\u25cf After that delay, the outputs are valid\n\u25cf If you try to use the output while it's invalid, things break\no stuff like 2 + 2 = 17??\n16\nThe Critical Path\n\u25cf The critical path is the path through a circuit that has the longest series of\nsequential operations\n\u25cf The longest propagation delay\no they depend on each other and can't be done in parallel!\n17\nRS\nQ\n0\nQ\n0\nS/R Latch (animated)\n18\n01\n10\n10\n1\n0\n1\ntime\nQ\n1\n0\n0\n1\nQS\nPropagation Delay (Basics)\n\u25cf If we have a component after this S/R latch that reacts to the data on Q\u2026 we\nneed it to synchronize.\no We need it to wait until the Q value is updated.\n\u25cf One method: something that periodically and predictably updates in an\ninterval that\u2019s a little longer than the propagation delay.\n19\nR\nS\nQ\nQ\n(reset)\n(set)\nTick Tock\n\u25cf Sequential logic is based on time, and time is continuous\n\u25cf Trying to build sequential circuits without anything to keep\ntrack of time is\u2026 possible, but very very difficult\n\u25cf This is why we use a clock signal: it goes 0, 1, 0, 1, 0, 1\u2026\no Oscillation\u2026 on purpose this time.\nEach period is called a clock cycle.\no We typically electrocute rocks to do this, as usual. (poor rocks L)\n20\n1\n0\ntime\nHigh Low\nwe can synchronize our circuits to a clock state:\nwhen it is high (1) or low (0)\ncircuit\nsymbol\nAdding a Clock\n\u25cf We need to augment our latch to wait for the clock before updating the\nvalue.\n\u25cf We need to account for the clock signal and only transmit a \u201c1\u201d on R or S if\nand only if the clock is high (or low).\n\u25cf Which leads us to something like this maybe\u2026\no But let\u2019s refine it a bit\u2026 (btw, how complex is this? How many transistors?)\n21\nR\nS\nQ\nQ\nC\nR\nS\nD(ata) Latch\n\u25cf If we do something like this, we simplify our S/R Latch into a nicer\nsynchronized latch called a D-Latch.\n\u25cf \u201cC\u201d is the clock. \u201cD\u201d is the data to latch when the clock is high.\n\u25cf Circuit only changes the value when the clock signal is 1\u2026\no Latches when clock is 0!\n22\nC\nQ\nQ\nD\nR\nS\nD Latch\n\u25cf When clock is low and D is \u2026 don\u2019t care!\no Nothing changes\n23\nC\nQ\nQ\nD\nR\nS\nD Latch\n\u25cf When clock is high and D is high\no It\u2019s a set operation\n24\nC\nQ\nQ\nD\nR\nS\nD Latch\n\u25cf When clock is high and D is low\no It\u2019s a reset operation\n25\nC\nQ\nQ\nD\nR\nS\nD Latch\n\u25cf We can abstract this away and start using this symbol:\n26\nC\nQ\nQ\nD\nD Latch\n\u25cf We often omit the \u201cC\u201d for the clock and use a triangle instead:\no Sometimes you\u2019ll see a square instead. Logisim uses triangles.\n27\nQ\nQ\nD\nD Latch\nTick Tock: D Latch\n\u25cf This diagram shows the behavior of the system over time.\no This is \u201chigh\u201d triggered.\no Note the propagation delay. And how Q depends on D AND clock.\n28\n1\n0 time\n1\n0\n1\n0\nD\nC\nQ\nProblems: Owner of a lonely (D) Latch\n\u25cf What if we don\u2019t want to change the value of Q.\no This means we have to constantly recharge the value, that is \u201cD\u201d has to be\nwhat we want Q to be every tick, limiting the usefulness.\n\u25cf We need a way to enable or disable the update.\n29\nC\nQ\nQ\nD\nProblems: Owner of a lonely (D) Latch\n\u25cf We could simply add a signal that we usually keep \u201c0\u201d and only allow the\nlatch when that \u2018write enable\u2019 (W) signal is \u201c1\u201d\n30\nC Q\nQ\nD\nW\nLet\u2019s look at some circuits\n\u25cf Weird behaviour when clock is used in logic!!\no Note: N-e-v-e-r, never ever, connect logic to a clock port.\n\u00a7 It\u2019s hard to predict the behavior of circuits!\n\u25cf d_latch.circ\n\u25cf broken_latch.circ\n31\nAnd The Flip-Flop\n32\nThe New Problem\n\u25cf Remember propagation delay? Pesky thing, that.\n\u25cf Clocks don\u2019t always help.\no We sometimes need a clock cycle to compute a value\no \u2026and then another clock cycle to compute the next thing.\no \u2026but the next thing needs to be computing the CURRENT thing.\no \u2026but we would overwrite that input\u2026 so it would compute something else\no \u2026before it was done computing the first thing\u2026\n\u25cf AHHHHH!!!!!\n33\nWaiting for Godata\n\u25cf We want to record an intent to store (latch) a value.\no That is, to delay the latch by around a cycle.\n\u25cf (But only actually do it at an idle moment)\no When do we have an idle moment in the latch???\n\u00a7 When the clock is low!!\n\u25cf If we cascade two D-Latches, and cleverly handle the clock\u2026\no We can create a register! (Specifically, a D Flip-Flop)\n\u00a7 Yes, that\u2019s actually what it is called. J\n\u25cf We will create a component that latches a value on the clock\u2019s falling edge.\no You can also make a rising edge D Flip-Flop by inverting the clock signal.\n34\nThe D Flip-Flop\n\u25cf While the clock is \u201c1\u201d (high), D\u2019 can be computed while Q remains unaffected.\no Q is being used, after all, by whatever component is after the flip-flop\no While D is not immediately known and is being computed by the\ncomponent before the flip-flop\n\u25cf Falling clock edge: value is copied from the first latch to the second.\no This handles data propagation within a sequential circuit.\n35\nQ\nQ\nD\nD Latch\nQ\nQ\nD\nD Latch\nD\nC\nQ\nQ\nD\u2019\nTick Tock\n\u25cf In this example, we are using the clock edges\no The circuit only updates its output in the instant the clock changes!\n\u25cf During the remaining time, other circuits\ncan compute the values\n36\n1\n0\ntime\nrising edge falling edge\nwe can synchronize our circuits to a clock edge:\nwhen it changes between 0 and 1\nTick Tock: Falling Edge D Flip-Flop\n\u25cf This diagram shows the behavior of the system over time.\no This is \u201cfalling edge\u201d triggered.\no Note the propagation delay. And how Q depends on D && clock.\n37\n1\n0 time\n1\n0\nC\nQ Q remains stable while clock\nremains high and low\n1\n0\nD\nA Flip-Flop doesn\u2019t race \u201cD\u201d\nThe D Flip-Flop\u2026 Abstracted\n\u25cf We can of course reduce the flip-flop\u2026 it looks the same as the D Latch.\no This is effectively a 1-bit Register!\no That is, it is a simple 1-bit volatile memory cell.\n38\nQ\nQ\nD\nD Flip-Flop\nLet\u2019s look at some circuits\n\u25cf D_flip_flop.circ\n\u25cf broken_latch.circ \u2026 again\n39\nReal-world clocking issues\n40\nDetermining clock speed\n41\ntime\nR is\nclocked\nR\u2019s Q\nbecomes\nvalid\nthe adder has\nfinished; clock\nR to store\n0ns 2ns 5ns\nR 1\nD Q A\nS\nB\nDetermining clock speed\n\u25cf It takes 5ns for a signal to propagate through our circuit\n\u25cf How fast can we clock it?\no if the time between clocks is less than 5ns, we'll clock the register too\nearly (while the adder's outputs are invalid)\no if the time between clocks is more than 5ns, no big deal\n\ufffd\n\ufffd\u00d7\ufffd\ufffd!\ufffd \ufffd\n= \ufffd. \ufffd\u00d7\ufffd\ufffd\ufffd \ufffd\ufffd\n= \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n\u25cf The fastest we can clock a sequential circuit is the reciprocal of the\ncritical path's propagation delay\n42\nClock Skew\n\u25cf The clock signal itself isn't immune to propagation delay!\n43\nIN\nCLK\n12???\nB\nD Q\nEN\nA\nD Q\nEN\n12 ???\nwatch the input as the\nclock pulse travels down\nthe wire to B.\n\u25cf This is a race condition: the data and clock are having a race, and\nthe outcome depends on who wins\no the winner could change based on temperature, power, etc!\nSummary\n44\nThe S/R Latch \u2026 Abstracted\n\u25cf We now know the S/R Latch!\no Allows you to store a value (1/0) but with a pit fall!\no It could turn into an oscillator if input an invalid combination\n\u00a7 R=S=1 \u00e8 R=S=0\n45\nQ\nQ\nR\nS/R\nS latch\nThe D Latch \u2026 Abstracted\n\u25cf We improved it by adding some input logic\no Creating the D Latch\no But it was transparent (active) during the high clock state\n46\nQ\nQ\nD\nD Latch\nThe D Flip-Flop\u2026 Abstracted\n\u25cf Lastly, we saw the heroic D Flip-Flop!\no This is effectively a 1-bit Register!\no That is, it is a simple 1-bit volatile memory cell.\n47\nQ\nQ\nD\nD Flip-Flop\nQ\nQ\nD\nD Latch\nQ\nQ\nD\nD Latch\nCircuits using Flip-Flops\n48\nCreating an Adder Circuit\n\u25cf Suppose we want to (for 1 bit):\no Have three 1-bit registers: A, B, C\no Compute: C = A + B\n\u25cf We would need:\no Three D Flip-flops (for A, B, and C)\no A 1-bit adder\no What is the circuit?\n49\nRegister-backed 1-bit Adder\n(assume clock is connected)\n50\nQ\nQ\nD\nD Flip-Flop\nQ\nQ\nD Flip-Flop\nS\nC\nA\nHalf-Adder\nB\nQ\nQ\nD\nD Flip-Flop\nC Register\nA Register\nB Register\nRegister-backed 1-bit Adder\n51\nQ\nQ\nD\nD Flip-Flop\nS\nCo\nA\nHalf-Adder\nB\nQ\nQ\nD\nD Flip-Flop\nA Register\nB Register\n(assume clock is connected)\n\u25cf What is the difference here?\n\u25cf A = A + B\n\u25cf This is fairly conventional\nsequential logic, actually.\n4-bit Counter\n\u25cf Another simple component we can now build is a counter.\n\u25cf This is a register that increments every clock tick.\no On the falling-edge, in this case. (assume clock is connected)\n52\nD Q\nD Flip-Flop\nD Q\nD Flip-Flop\nD Q\nD Flip-Flop\nD Q\nD Flip-Flop\nA B\nAdder\nCo S Ci\nA B\nAdder\nCo S Ci\nA B\nAdder\nCo S Ci\nA B\nAdder\nCo S Ci\n0 0 0 0\n1\n3rd bit 2nd bit 1st bit 0th bit\n4-bit Counter: Thoughts\n\u25cf Hmm, adding takes some time because it ripples\n\u25cf Hmm, how long does our clock cycle have to be?\no No shorter than the propagation delay.\no If you assume latches take 2ns and adders take 4ns\u2026\n53\nD Q\nD Flip-Flop\nD Q\nD Flip-Flop\nD Q\nD Flip-Flop\nD Q\nD Flip-Flop\nA B\nAdder\nCo S Ci\nA B\nAdder\nCo S Ci\nA B\nAdder\nCo S Ci\nA B\nAdder\nCo S Ci\n0 0 0 0\n1\n0ns\n4-bit Counter: Clocking\n54\nD Q\nD Flip-Flop\nD Q\nD Flip-Flop\nD Q\nD Flip-Flop\nD Q\nD Flip-Flop\nA B\nAdder\nCo S Ci\nA B\nAdder\nCo S Ci\nA B\nAdder\nCo S Ci\nA B\nAdder\nCo S Ci\n0 0 0 0\n1\n1\n0\n0 0 1 0\nQ\nQ\nD\nD Flip-Flop\nQ\nQ\nD\nD Latch\nQ\nQ\nD\nD Latch\n2ns\n4-bit Counter: Clocking\n55\nD Q\nD Flip-Flop\nD Q\nD Flip-Flop\nD Q\nD Flip-Flop\nD Q\nD Flip-Flop\nA B\nAdder\nCo S Ci\nA B\nAdder\nCo S Ci\nA B\nAdder\nCo S Ci\nA B\nAdder\nCo S Ci\n0 0 0 0\n1\n2ns\n1\n0\n10268ns\n1\n0\n0\n1\n14ns\n0\n0\n168\n0\n0\n20\n0 0 01 01\n4-bit Counter: Circuit Delay\n56\nD Q\nD Flip-Flop\nD Q\nD Flip-Flop\nD Q\nD Flip-Flop\nD Q\nD Flip-Flop\nA B\nAdder\nCo S Ci\nA B\nAdder\nCo S Ci\nA B\nAdder\nCo S Ci\nA B\nAdder\nCo S Ci\n0 0 0 0\n1\nParallelized\nSerialized 4ns + 4ns + 4ns + 4ns\n2ns + 2ns 20ns\n4-bit Counter: Delay Explanation\n\u25cf Values of output bits must all be stable.\no That is, can\u2019t pulse clock until all 4 bits are computed\n\u25cf However, the adder is a ripple-carry: Each bit waits for previous.\no 4ns per adder\no 4-bit adder\no Thus: 4 * 4ns = 16ns for the 4-bit adder\n\u25cf Flip-Flops\no Must wait for 1st latch to stabilize Q (2ns in parallel)\no Must wait for 2nd latch to stabilize Q (2ns also in parallel)\no Thus: 2ns + 2ns = 4ns\n\u25cf Overall delay: 16ns + 4ns = 20ns. Clock pulse is 20ns.\n57\nDetermine Maximum Clock Speed\n\u25cf If this operation takes 20ns, this bounds our clock speed.\n\u25cf Our clock period must be 20ns.\no Which means our frequency is once every 20ns: 1s \u00f7 20ns\no What is that frequency in Hz? (Hertz is \u201ccycles per second\u201d)\no This would be the maximum clock speed for our circuit to work.\n1\ufffd\n20\ufffd\ufffd\n= 50,000,000 \ufffd\ufffd = 50 \ufffd\ufffd\ufffd"
        },
        {
            "lecture": 3,
            "content": "Binary addition\n3\nAdding in binary\n\u25cf It works the same way as you learned in school\no Except instead of carrying at 1010, you carry at\u2026 102!\n\u00a7 1 + 1 = 102 (210)\n\u00a7 1 + 1 + 1 = 112 (310)\n\u25cf Let's try it. (what are these in decimal?)\n4\n1011 0010\n+0010 1111\n1110 0001\n0 1 1 1 1 1 0\nFormalizing the algorithm\n\u25cf for each pair of bits starting at the LSB,\no add the two bits and the carry\no the low bit of the sum goes into the sum row\no the high bit of the sum is the carry for the next higher bit\n\u25cf this is the grade school algorithm\no cause it's how you learned to add in grade school\n5\n1 0 1 1 0 0 1 0\n+0 0 1 0 1 1 1 1\nThe finitude of variables\naka. Overflow\n6\n\u2022 These slides were made for high-school students and their parents!\n\u2022 But I hate wasting slides!\nLet\u2019s program \u2013 this is C++ for reasons\nI made a cute\ntiny positive\nnumber\nbecause\ncomputers\nwork\nwith much\nlarger numbers.\nWhich are\nterrible as\nexamples J\nLet\u2019s program\nWhat\u2019s up, Doc? \ufffd\u2013 Overflow!\n1111\n1110\n0000\n0001\n15\n14\n0\n1\nBy Hellbus - Own work, Public Domain,\nhttps://commons.wikimedia.org/w/index.php?curid=3089\n111\npositive_tiny\nCan only hold 4 bits\nIt\u2019s more like a carrousel\n0\n1\n2\n345\n6\n9\n8\n7\n10\n11\n12\n13\n14\n15\n0000\n0010\n0100\n0011\n0001\n0101\n0110\n0111\n1000\n1001\n1010\n1011\n1100\n1101\n1110\n1111\n0123456789\n10\n11\n12\n13\n14\n15\n0000\n0001\n0010\n0011\n0100\n0101\n0110\n0111\n1000\n1001\n1010\n1011\n1100\n1101\n1110\n1111\nComputer Maths is always right\n0 1\n2\n3\n4\n5\n6\n9 8 7\n10\n11\n12\n13\n14\n15\n0000\n0010\n0100\n0011\n0001\n0101\n0110\n0111\n1000\n1001\n1010\n1011\n1100\n1101\n1110\n1111\nComputer Maths is always right\n0 1\n2\n3\n4\n5\n6\n9 8 7\n10\n11\n12\n13\n14\n15\n0000\n0010\n0100\n0011\n0001\n0101\n0110\n0111\n1000\n1001\n1010\n1011\n1100\n1101\n1110\n1111\nisn\u2019t\nThis is OVERFLOW!\nThis is fine!!!!\n\u2022 After all, actual computer numbers can hold MUCH bigger values\nPac-Man \u2013 I know this is not exactly how it happens! But it\u2019s the same process!\nLevel: 256\nBinary:\nSource:\nhttps://pacman.fandom.com/wiki/Map_256_Glitch\nLevel: 255\nBinary:\nSource:\nhttps://www.cnn.com/style/article/pac-man-40-\nanniversary-history/index.html\nYou cleared level 255\nCongrats, you made\nit to computer\nchaos\n0 0 0 0 0 0 0 0\n1 1 1 1 1 1 1 1\n+ 1 = 1\nPositive number overflow?\n15\n0 1\n2\n3\n4\n5\n6\n9 8 7\n10\n11\n12\n13\n14\n15\n0000\n0010\n0100\n0011\n0001\n0101\n0110\n0111\n1000\n1001\n1010\n1011\n1100\n1101\n1110\n1111\nwhat is 14 + 7?\n1110\n+0111\n10101\nIf the result is smaller\nthan either addend,\nthere is an overflow\nBecause there is no\nspace for the extra\ncarry\nOverflow\n\u25cf Essentially, all arithmetic on the computer is modular arithmetic!\n16\na+b =\n(a+b)%2n\nn \u00e0 number of bits\nwe can store\nHow many bits?\n\u25cf if you add two 2-digit decimal numbers, what's the\nlargest number you can get?\n\u25cf what about two 4-digit decimal numbers?\n\u25cf what about two 4-bit numbers?\n\u25cf what's the pattern of the number of digits?\no if you add two n-digit numbers in any base\u2026\no the result will have at most n + 1 digits\n\u25cf that means if we add two 32-bit numbers\u2026\no \u2026we might get a 33-bit result!\no if we have more bits than we can store in our\nnumber, that's overflow.\n17\n99\n+99\n198\n9999\n+9999\n19998\n1111\n+1111\n11110\nHandling overflow\n\u25cf we could ignore it\no in MIPS: addu, subu\no this is usually a bad idea\n\u00a7 your program is broken\no it's also the default in most languages, thanks C\n\u25cf we could fall on the floor - i.e. crash\no in MIPS add, sub\no can be handled and recovered from\no but more complex\n\u25cf we could store that 33rd bit somewhere else\n18\nMaybe the bit bucket is a real place\u2026\n\u25cf many other architectures do this\no MIPS does not.\n\u25cf they have a \"carry bit\" register\no this can be checked by the program after an add/sub\n\u25cf this is very useful for arbitrary precision arithmetic\no if you want to add 2048-bit numbers, chain many 32-bit additions\n19\n0010 1001\n+0001 1100\n1001\n+1100\n1\n0010\n+0001\n1\nadd8bit add4bit add4bit\n0 1 1 1 0 0 0\n0100 0101\n0 0 0\n0100 0101\n0 1 1 1\nSigned Numbers\n20\nCodes vs numbers\n\u25cf What if I told you\n21\nCode Number\n13 -3\n14 -2\n15 -1\n0 0\n1 1\n2 2\n3 3\nThis code Represents this\nnumber\nUnsigned integers \u2013 they are all positive!\n\u25cf We have numbers, they are all positive!\no On a number line:\n22\n4\n000\n001\n5\n010\n6\n011\n7\n101\n3\n110\n2\n111\n0 1\n100\n\u25cf What if we want to have negative numbers?\nIf you wanted to implement signed integers\u2026\n\u25cf What would be the most intuitive way of doing it?\no You could have a \"sign bit\" where 0 means +, and 1 means -\n\u25cf This is sign-magnitude representation. on a number line:\n23\n0\n000\n001\n+1\n010\n+2\n011\n+3\n101\n-1\n110\n-2\n111\n-3\n\u25cf What about the pattern 100?\no negative sign, 0 magnitude\no NEGATIVE ZERO??\n\u25cf Arithmetic is a bit awkward 100\nSign-magnitude arithmetic\n\u25cf Negation\n24\n-(3) 1011\nbit pattern for Flip MSB!\npositive 3?\n0011\n-(-3) 0011\nbit pattern for Flip MSB!\nnegative 3?\n1011 \nSign-magnitude arithmetic\n\u25cf Negation\n\u25cf (wrong) Addition\n25\n0110\n3\n+-3\n 0\n3\n+ 3\n 6\n11\n+0011\n0011\n1110\n11\n+1011\n0011\nto binary?\nbit pattern for\n-3\u2026 positive 3?\nto decimal?\n1011 -6\n\u25cf It\u2019s not impossible\no But it is awkward\n-(3) 0011 1011\n-(-3) 1011 0011\nWell, what if\u2026\n\u25cf We use a technique borrowed from old accounting practices and\nmechanical calculators, we can flip all the bits to negate a number\n\u25cf This is ones' complement. on a number line:\n\u25cf We have the same problem with 111\nas sign-magnitude had with 100\n\u25cf This does make arithmetic easier\n\u25cf But it is not used in modern computers.\n26\n0\n000\n001\n+1\n010\n+2\n011\n+3\n110\n-1\n101\n-2\n100\n-3\n111\nOnes\u2019 complement arithmetic\n\u25cf Negation\n27\n-(3) 1100\nbit pattern for flip!\npositive 3?\n0011\n-(-3) 0011\nbit pattern for flip!\nnegative 3?\n1100 \nOnes\u2019 complement arithmetic\n\u25cf Negation\n\u25cf Addition\n28\n-(3) 0011 1100\n-(-3) 1100 0011\n0101\n3\n+-2\n 1\n3\n+ 2\n 5\n0010\n+0010\n0011\n0000???\n+1101\n0011\nto binary?\nbit pattern for\n-2\u2026 positive 2?\n0010\n1101\nflip!\nthis is positive, so don\u2019t flip to decimal?\n1\n1111\n+0001\n0001\nAdd the\ncarry back in\nFinally, two's complement\n\u25cf First, we flip all the bits\no Just like with 1\u2019s complement\n\u25cf Then add 1.\n\u25cf The number line looks a little bit stranger\no But there is only one 0, and it is 0!\n29\n110\n-2\n101\n-3 0\n000\n001\n+1\n010\n+2\n011\n+3\n111\n-1\n100\n-4\nFinally, two's complement\n\u25cf First, we flip all the bits\no Just like with 1\u2019s complement\n\u25cf Then add 1.\n\u25cf The number line looks a little bit stranger\no But there is only one 0, and it is 0!\n\u25cf It's lopsided: There is no +4!\no But arithmetic is easy!\no when someone says \"signed,\" 99% of the time they mean this\no When I say \u201csigned\u201d, I 100% of the time mean this\n30\n110\n-2\n101\n-3 0\n000\n001\n+1\n010\n+2\n011\n+3\n111\n-1\n100\n-4\nTwo\u2019s complement arithmetic\n\u25cf Negation\n\u25cf You don\u2019t need to subtract!!\no flip(k)+1 == flip(k-1)\n\u00a7 If you ignore the carry! J\n31\n-(3) 1100\nbit pattern for flip!\npositive 3?\n0011\n-(-3) 0010\nbit pattern for flip!\nnegative 3?\n1101\nAdd 1!\n1101\nAdd 1!\n0011\n1010\n3\n+-7\n-4\nTwo's complement addition\n\u25cf the great thing is: you can add numbers of either sign without having to do\nanything special!\n32\n3\n+ 7\n10\n0111\n+0111\n0011 0111\n1000 1100\n0011\n+1001\n0011\n0011\n0100\nto binary?\nbit pattern for\n-7\u2026 positive 7?\nflip! +1\nthis is negative, so\nwhat is it? flip!\nto decimal?\n+1\n4\nthe actual patterns of bits are the same.\nso how does the computer \"know\" whether it's\ndoing signed or unsigned addition?\n-\nIgnore the carry\n33\nIT DOESN'T\nNeat properties\n\u25cf If we take a positive number and add zeros:\no 12010 = 0111 10002\no 0000 0000 0111 10002 = 12010\n\u25cf If we take a negative number and add ones:\no 1000 01112 = - 0111 10002 + 12\n= - 0111 10012 = -12110\no 1111 1111 1000 01112 = - 0000 0000 0111 10002+12\n= - 0000 0000 0111 10012\n= - 12110\n34\nArbitrariness\u2026 Again\n\u25cf What does this mean?\n35\n10001010\nIs it signed? \u00af\\_(\u30c4)_/\u00af Is it\nunsigned?\nWhat\u2019s the\ndifference?\nYour turn\n36\nQ: What is the minimum number of\nbits you need to represent -16 in 1s\u2019 complement?\nQ: What is the minimum number of\nbits you need to represent -16 in 2\u2019s complement?\n1s\u2019 complement uses 1 bit for sign, including negative zero.\nSo: range of a n-bit number is -2n-1-1\u00e0 2n-1-1\nAnswer: 6 bits are needed\n0001 0000 \u00e0flip\u00e0 1110 1111 \u00e0truncate\u00e0 10 1111\n2\u2019s complement uses 1 bit for sign, excluding negative zero.\nSo: range of a n-bit number is -2n-1 \u00e0 2n-1-1\nAnswer: 5 bits are needed\n0001 0000 \u00e0flip\u00e0 1110 1111 \u00e0add 1\u00e0 1111 0000 \u00e0truncate\u00e0 1 0000\nThe finitude of variables\naka. Overflow\n37\n\u2022 These slides were made for high-school students and their parents!\n\u2022 But I hate wasting slides!\nLet\u2019s program\nI made a\ncute tiny\nnumber\nthat now\nholds both\npositive\nand\nnegative\nnumbers\nRemember the carrousel\n0\n1\n2\n345\n6\n-\n7\n-\n8\n7\n-\n6\n-\n5\n-\n4-3-\n2\n-\n1\n0000\n0010\n0100\n0011\n0001\n0101\n0110\n0111\n1000\n1001\n1010\n1011\n1100\n1101\n1110\n1111\n01234567-8-7-6-5-4-3-2-1\n0000\n0001\n0010\n0011\n0100\n0101\n0110\n0111\n1000\n1001\n1010\n1011\n1100\n1101\n1110\n1111\nComputer Maths is always right\n0 1\n2\n3\n4\n5\n6 -7 -8 7 -6\n-5\n-4\n-3\n-2 -1\n0000\n0010\n0100\n0011\n0001\n0101\n0110\n0111\n1000\n1001\n1010\n1011\n1100\n1101\n1110\n1111\nThis is OK!\nWhat\u2019s up, Doc? \ufffd\n0111\n0110\n1000\n1001\n7\n6\n-8\n-7 By Hellbus - Own work, Public Domain,\nhttps://commons.wikimedia.org/w/index.php?curid=3089\n111\nComputer Maths is always right\n0 1\n2\n3\n4\n5\n6 -7 -8 7 -6\n-5\n-4\n-3\n-2 -1\n0000\n0010\n0100\n0011\n0001\n0101\n0110\n0111\n1000\n1001\n1010\n1011\n1100\n1101\n1110\n1111\nisn\u2019t\nThis is OVERFLOW!\nThis is fine!!!!\n\u2022 After all, actual computer numbers can hold MUCH bigger values\nBoeing\nhttps://www.govinfo.gov/content/pkg/FR-2015-05-01/pdf/2015-10066REBOOT\nBy pjs2005 from Hampshire, UK - Boeing 787 N1015B ANA Airlines, CC\nBY-SA 2.0,\n\nCan we detect that?\nHow much is -6 -\n7?\n1010\n+1001\n0011\nHow much is 6 + 7?\n0110\n+0111\n1101\n0 1\n2\n3\n4\n5\n6 -7 -8 7 -6\n-5\n-4\n-3\n-2 -1\n0000\n0010\n0100\n0011\n0001\n0101\n0110\n0111\n1000\n1001\n1010\n1011\n1100\n1101\n1110\n1111\nThis is\nimpossible:\nMax positive = 7\n-1+7=6!\nWhat about this?\nHow can we detect\nif operations with\ndifferent signs\noverflow?\nAdd 2 negative\nnumbers, the\nresult is positive\n\u274c\nAdd 2 positive\nnumbers, the\nresult is negative\n\u274c\nTwo's complement negation\n\u25cf (assuming 4 bits) What about??? -8?\no What happens if we negate -8?\n\u00a7 i.e. -(-8)?\n46\n0 1\n2\n3\n4\n5\n6 -7 -8 7 -6\n-5\n-4\n-3\n-2 -1\n0000\n0010\n0100\n0011\n0001\n0101\n0110\n0111\n1000\n1001\n1010\n1011\n1100\n1101\n1110\n1111\n-(-8) 0111\nbit pattern for flip!\nnegative 8?\n1000\nAdd 1!\n1000 -8???\nWHAT DID YOU\nDO WRONG??????\nAbsolutely Bonkers\npublic class AbsTest {\npublic static int abs(int x) {\nif (x < 0) {\nx = -x;\n}\nreturn x;\n}\npublic static void main(String[] args) {\nSystem.out.println(\nString.format(\"|%d| = %d\", Integer.MIN_VALUE,AbsTest.abs(Integer.MIN_VALUE))\n);\n}\n} // Outputs: |-2147483648| = -2147483648\n47 Q: How many bits is a Java int? What happened here?\nMore Bonkers\npublic class Main {\npublic static void main(String []args) {\nint w = Integer.MAX_VALUE;\nif (w + 1 > w) {\nSystem.out.println(\"This does not happen.\\n\");\n}\nint z = w + 1;\nif (z > w) {\nSystem.out.println(\"This does not happen.\\n\");\n}\nSystem.out.println(\"The end.\\n\");\n}\n}"
        },
        {
            "lecture": 2,
            "content": "Numbers and bases o Why is 2021 worth 2021?? o Or is it? \u00a7 Maybe it\u2019s worth 8225? \u25cf Number representation o Binary \u2013 what do 0s and 1s mean? \u25cf Other representations o Hexadecimal and octal \u25cf How does a computer interpret them? o (bait) The answer will surprise you!!\n2\nNumbers and bases\n3\n\u25cf The numbers we use are written positionally: the position of a digit within\nthe number has a meaning.\n4\nPositional number systems\n2 0 0 0\n0 0 0\n2 0\n+ 4\n2 0 2 4 =\n2 x 103\n0 x 102\n2 x 101\n4 x 100\n=\n\u25cf The numbers we use are written positionally: the position of a digit within\nthe number has a meaning.\n5\nPositional number systems\n2 0 2 4\n1000s 100s 10s 1s\n100 101 102 103\n\u25cf How many (digits) symbols do we have in our number system?\n\u25cb 10: 0, 1, 2, 3, 4, 5 ,6 ,7, 8, 9\nMost Significant Least Significant\nWhat are the limits?\nUsing base 10\n\u25cf A 4-digit number, e.g.:\n2024\n\u25cf Has\tthe\tvalue\n2\u00d710! + 0\u00d7\ufffd\ufffd\" + 2\u00d710# + 4\u00d710$\n\u25cf Using 4 digits we can represent _______ different numbers\n\u25cf The smallest non-negative number representable with 4 digits is _______\n\u25cf The largest number representable with 4 digits is _________, or 10___\n______\n\u25cf Using ____ symbols: ________________________________\n6\nSo\u2026 with the numbers we use every day\u2026\n\u25cf A number represented by the digits\n\ufffd&'# \u2026 \ufffd#\ufffd$\n\u25cf Has\tthe\tvalue\n\ufffd&'#\u00d710&'# + \u22ef + \ufffd#\u00d710# + \ufffd$\u00d710$\n\u25cf Using \ufffd digits we can represent 10& different numbers\n\u25cf The smallest non-negative number representable with \ufffd digits is 0\n\u25cf The largest number representable with \ufffd digits is 10& \u2212 1\n\u25cf Using 10 symbols: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\n7\nSo\u2026 with the numbers we use every day\u2026\n8\nNumeric Bases\n\u25cf These 10s keep popping up\u2026 and for good reason\n\u25cf We use a base-10 (decimal) numbering system\no 10 different symbols, and each place is a power of 10\n\u25cf But we can use (almost) any number as a base!\n\u25cf The most common bases when dealing with computers are base-2 (binary), base-16\n(hexadecimal), and (rarely) base-8 (octal)\n\u25cf When dealing with multiple bases, you can write the base as a subscript to be explicit\nabout it:\n510 = 1012\n9\nMaking a number system\nUsing base B\n\u25cf A number represented by the digits\n\ufffd&'# \u2026 \ufffd#\ufffd$\n\u25cf Has\tthe\tvalue\n\ufffd&'#\u00d7B&'# + \u22ef + \ufffd#\u00d7B# + \ufffd$\u00d7B$\n\u25cf Using \ufffd digits we can represent B& different numbers\n\u25cf The smallest non-negative number representable with \ufffd digits is 0\n\u25cf The largest number representable with \ufffd digits is B& \u2212 1\n\u25cf Using B symbols\n10\nIf you use base 0 you\ndon\u2019t need to\nremember any symbols\nBinary \u2013 Base 2\n11\nHow many symbols in binary????\n2\n12\nLet's make a base-2 number system\nUsing base 2\n\u25cf A number represented by the digits\n\ufffd&'# \u2026 \ufffd#\ufffd$\n\u25cf Has\tthe\tvalue\n\ufffd&'#\u00d72&'# + \u22ef + \ufffd#\u00d72# + \ufffd$\u00d72$\n\u25cf Using \ufffd digits we can represent 2& different numbers\n\u25cf The smallest non-negative number representable with \ufffd digits is 0\n\u25cf The largest number representable with \ufffd digits is 2& \u2212 1\n\u25cf Using 2 symbols: 0, 1\n13\nBinary (base-2)\n14\n\u2022 We call a Binary digIT a bit \u2013 a single 1 or 0\n\u2022 When we say an n-bit number, we mean one with n binary digits\n27 26 25 24 23 22 21 20\n1001 0110\n128s 64s 32s 16s 8s 4s 2s 1s\n1 \u00d7 128 +\n0 \u00d7 64 +\n0 \u00d7 32 +\n1 \u00d7 16 +\n0 \u00d7 8 +\n1 \u00d7 4 +\n1 \u00d7 2 +\n0 \u00d7 1\n= 15010\n=\nTo convert binary to decimal: ignore 0s,\nadd up place values wherever you see a 1.\nMSB LSB\nIt\u2019s the only\nodd number!\nMaking change\n\u25cf You want to give someone $9.63 in change, using the fewest bills and coins possible.\nHow do you count it out?\n15\n\u2022 Biggest to smallest\n\u2022 Most significant to least significant\n\u2022 WHERE COULD THIS BE GOING...\n1 4 2 1 0 3\n$4.63 -$4= $0.63 -50\u00a2= $0.13-10\u00a2=$0.03-0\u00a2=$0.03-3\u00a2=$0.00\n$5\u00d7 $1\u00d7 25\u00a2\u00d7 10\u00a2\u00d7 5\u00a2\u00d7 1\u00a2\u00d7__\nLeft:$9.63-$5=\nConverting decimal to binary\n16\n\u2022 For each place from MSB:\n\u2022 If place value <= remainder:\no digit = 1\no remainder = remainder - place\n\u2022 Else, digit = 0.\n\u2022 You want to convert the number 8310 to binary.\n01010 - 64 =\n011\n83 19 - 0 =19- 16 = 3 - 0 = 3 - 0 = 3 - 2 = 1 - 1 = 0\n128s 64s 32s 16s 8s 4s 2s 1s\nLeft:83- 0 =\nBits, bytes, nibbles, and words\n\u25cf A bit is one binary digit, and its unit is lowercase b.\n\u25cf A byte is an 8-bit value, and its unit is UPPERCASE B.\no This is (partially) why your 30 megabit (Mbps) internet connection can only give you\nat most 3.57 megabytes (MB) per second!\n\u25cf A nibble (also nybble) is 4 bits\no Corresponds nicely to a single hex digit.\n\u25cf A word is the \"most comfortable size\" of number for a CPU.\n\u25cf When we say \"32-bit CPU,\" we mean its word size is 32 bits.\no This means it can, for example, add two 32-bit numbers at once.\n\u25cf BUT WATCH OUT:\no Some things (Windows, x86) use word to mean 16 bits and double word (or\ndword) to mean 32 bits.\n17\n\u2013 half of a byte\nKilo, mega, tera\n18\nPotatoes Bytes Bytes\n1g (gram) 1B (Byte) 1B (Byte)\n1kg (Kilogram) = 1000g 1kB (Kilobyte) = 1000B 1kiB (Kibibyte) = 1024B\n(power of 2 nearest to 1000)\n1Mg (Megagram) = 1000Kg 1MB (Megabyte) = 1000kB 1MiB (Mebibyte) = 1024kiB\n1Gg (Gigagram) = 1000Mg 1GB (Gigabyte) = 1000MB 1GiB (Gibibyte) = 1024MiB\n1Tg (Teragram) = 1000Gg 1TB (Terabyte) = 1000GB 1TiB (Tebibyte) = 1024GiB\n1Eg (Exagram) = 1000Tg 1EB (Exabyte) = 1000TB 1EiB (Exbibyte) = 1024TiB\nUsed for hard drive capacity and\nnetwork speeds\nUsed for most other things!\nBecause binary!\nA 1TB drive only has 931GiB!\nThe real world IS CONFUSING!!!!\n19\nSometimes this is used to mean\n931GiB L This always means 931GiB! J\n931GB 931GiB\nWhy binary? Whynary?\n20\n\u2022 Why indeed?\nolog\" 10 = 3.322\noThe number of bits required to represent 10 digits\noThe increase on number of components in a computer!\n\u2022 Because it\u2019s soooooo much easier to implement the hardware!\noAnd robust!\n\u2022 Arithmetic becomes really easy (as we'll see in several weeks)\nWhy binary? Whynary?\n\u25cf Why indeed?\n\u25cf What color is this?\n21\n0 1 2 3 4 5 6 7 8 9\nWhy binary? Whynary?\n\u25cf Why indeed?\n\u25cf What color is this?\n22\n0 1\nWhy binary? Whynary?\n23\n\u2022 Why indeed?\nolog\" 10 = 3.322\noThe number of bits required to represent 10 digits\noThe increase on number of components in a computer!\n\u2022 Because it\u2019s soooooo much easier to implement the hardware!\noAnd robust!\n\u2022 Arithmetic becomes really easy (as we'll see in several weeks)\nEverything in a computer is a number\n\u25cf So, everything on a computer is represented in binary.\no everything.\n01100101 01110110 01100101 01110010 01111001 01110100 01101000\n01101001 01101110 01100111 00001010 00000000\n\u25cf Java strings are encoded using UTF-16\no Most letters and numbers in the English alphabet are < 128.\no \u201cStrings are numbers\u201d\n\u00a7 83 116 114 105 110 103 115 32 97 114 101 32 110 117 109 98 101 114 115 0\n\u25cf ASCII is also pretty common (the best kind of common)\no That\u2019s what we will be using \u00e0 8 bit numbers represent characters\no Letters and numbers (and most/all ascii characters) have the same value as UTF-16\n24\nDo try this at home: what does this mean?\n\u2022 71 111 111 100 32 74 111 98 0\nEVERYTHING\n25\n\u2022Images and colors? Numbers!\n\u2022 Videos? Numbers!\n122 185 32\n239 97 181\n181 40 41\n\u25cf All information on computers is stored as patterns of bits, but\u2026\n\u25cf How these bits are interpreted, transformed, and displayed is up to the\nprogrammer and the user.\n26\nOne number, many possible meanings\n11000100\n-59 Signed integer\n196\nUnsigned integer\n0xC4\nHexadecimal\n\u00c4\nUnicode\ncall nz\nz80 instruction\nR3G3B2 color\nWhat it means to be \"arbitrary\"\n27\n\u2022It means there's no reason for it to be that way.\n\u2022 we just know/agree that it's how things are.\n\u2022 One of the biggest things I want you to know is:\nWhat a pattern of bits means is arbitrary.\n\u2022 As a corollary:\nThe same pattern of bits can be interpreted many\ndifferent ways.\nThe calculat--hum--computer doesn't know or care.\n28\n\u2022 when writing assembly (and C!) programs, the computer has no idea what you\nmean, cause nothing means anything to it\n\u2022 \"my program assembles/compiles, why is it crashing?\"\nocause the computer is stupid\n\u00a7 it's a big fast calculator\n\u2022there's no difference between nonsense code and useful code\n\u2022it's good at doing fun things with bit patterns\n\u2022 but don't confuse what it does with intelligence\n\u2022 every \"smart\" thing a computer does, it does because a human programmed it\nto act like that\nHexadecimal \u2013 Base 16\n29\nHow many symbols in hexadecimal????\n16\n30\nShortcomings of binary and decimal\n\u25cf Binary numbers can get really long, really quickly.\no 3,927,66410 = 11 1011 1110 1110 0111 00002\n\u25cf But nice \"round\" numbers in binary look arbitrary in decimal.\no 10000000000000002 = 32,76810\n\u25cf This is because 10 is not a power of 2!\n\u25cf We could use base-4, base-8, base-16, base-32, etc.\no Base-4 is not much concise than binary\n\u00a7 e.g. 3,927,66410 = 120 3331 2323 00004\no Base-32 and up? would require 32+ symbols. Nope.\n\u00a7 Well at least for humans\u2026 They are actually used!\no Base-8 and base-16 look promising!\n31\nLet's make a base-2 16 number system\nUsing base 16\n\u25cf A number represented by the digits\n\ufffd&'# \u2026 \ufffd#\ufffd$\n\u25cf Has\tthe\tvalue\n\ufffd&'#\u00d716&'# + \u22ef + \ufffd#\u00d716# + \ufffd$\u00d716$\n\u25cf Using \ufffd digits we can represent \ufffd\ufffd& different numbers\n\u25cf The smallest non-negative number representable with \ufffd digits is 0\n\u25cf The largest number representable with \ufffd digits is 16& \u2212 1\n\u25cf Using 16 symbols: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F\n32\nHexadecimal, or \"hex\" (base-16)\n\u25cf Digit symbols after 9 are A-F, meaning 10-15 respectively.\n\u25cf Usually we call one hexadecimal digit a hex digit. No fancy name :(\n33\n167 166 165 164 163 162 161 160\n003B EE70\n0 \u00d7 167 +\n 0 \u00d7 166 +\n 3 \u00d7 165 +\n11 \u00d7 164 +\n14 \u00d7 163 +\n14 \u00d7 162 +\n 7 \u00d7 161 +\n 0 \u00d7 160 =\n3,927,66410\n=\nTo convert decimal to hex: use a calculator!\nBUT WE REALLY WANT TO KNOW!!\n34\n\u2022 Ok! then. Let\u2019s go back to decimal for a bit\n2 0 2 4 How would you\nextract this\nnumber???\nJust divide by 10!\n10 2 0 2 4\n10 2 0 2 R 4\n10 2 0 R 2\n2 R 0\nWhen you divide by the\nBASE you are moving the\ndecimal point in that BASE\nHow I like to think of it:\n10\n0 R 2\nBUT WE REALLY WANT TO KNOW!!\n35\n\u2022 Turns out that dividing by 10 in any base has the same outcome\n3 927 664\n245 479 R 0\n15 342 R 7\nR 14\n1610\n958\n59\n3\nR 14\nR 11\n003B EE7016\n0x10 1610\n1610\n1610\n1610\n1610\nBUT WE REALLY WANT TO KNOW!!\n36\n\u2022 Turns out that dividing by 10 in any base has the same outcome\n110012\n0b10 210\n25\n12 R 1\n6 R 0\nR 0\n210\n3\n1 R 1\n210\n210\n210\nThe relationship between binary and hex\n\u25cf Four bits are equivalent to one hex digit.\n\u25cf Converting between them is easy!\n\u25cf Say we had this binary number:\n11101111101110011100002\n\u25cf Starting from the LSB, divide into groups of 4\nbits (put 0s before the first digits if there are\nleftovers). Then use the table.\n0011 1011 1110 1110 0111 0000\n37\nBin Hex Bin Hex\n0000 0 1000 8\n0001 1 1001 9\n0010 2 1010 A\n0011 3 1011 B\n0100 4 1100 C\n0101 5 1101 D\n0110 6 1110 E\n0111 7 1111 F\n0x3 B E E 7 0\n(this is common notation for hex,\nderived from the C language.) know how to make\nthis table.\nLet\u2019s do it!\n38\n100100011001111000111010010101\nSplit into\ngroups of 4 bits\nStarting from\nthe right\nLet\u2019s do it!\n39\n0010 0100 0110 0111 1000 1110 1001 0101\nExtend the\nnumber on\nthe left!\nLet\u2019s do it!\n40\n0010 0100 0110 0111 1000 1110 1001 0101\n2 4 6 7 8 E 9 5\n2467869516\n0x24678695\nReverse to convert hex to bin\nWhy?\n41\n1111 1111\nF F\n1\u00d72! + 1\u00d72\" + 1\u00d72# + 1\u00d72$ + 1\u00d72% + 1\u00d72& + 1\u00d72' + 1\u00d72(\n1\u00d72% + 1\u00d72& + 1\u00d72' + 1\u00d72( =\n8 + 4 + 2 + 1 =\n15\n1\u00d72% + 1\u00d72& + 1\u00d72' + 1\u00d72( \u00d72$ + 15\n2$ = 16\n15\u00d716' + 15\u00d716( This works with Factoring\nany base that is a\npower of 2 E.g. Base 4=22\nSplit into groups\nof 2 bits\nPowers of Two\n\u25cf Memorize at least the powers up to ~28 or 210.\no If you can't remember one, double the previous one.\n\u25cf These are the place values for binary, and they are also\nnice \"round\" numbers in binary and hex.\n\u25cf What is the largest number that an 8-bit value can hold?\nWhat is that in hexadecimal?\no 255: 0xFF\n\u25cf How about a 16-bit value?\no 65535: 0xFFFF\n\u25cf \"0xFFFF\" is kinda like \"9999\" in decimal.\n42\nDec Hex\n20 1 0x1\n21 2 0x2\n22 4 0x4\n23 8 0x8\n24 16 0x10\n25 32 0x20\n26 64 0x40\n27 128 0x80\n28 256 0x100\nOctal \u2013 Base 8\n43\nHow many symbols in octal????\n8\n44\nOctal (base-8)\n45\n83 82 81 8\n6370\n0\n6 \u00d7 83 +\n3 \u00d7 82 +\n 7 \u00d7 81 +\n 0 \u00d7 80 =\n3,32010\n=\nTo convert decimal to octal: divide by 8!\nTo convert octal to binary: groups of 3!\n63708\n06370\n0o6370\nBase-8?\n\u25cf base-8, octal, used to be commonplace but isn't anymore\n\u25cf each octal digit (0-7) corresponds to three bits\no this made it a nice fit for 9-, 12-, 18-, and 36-bit machines\n\u25cf buuuut no one cares about octal anymore L\n\u25cf SORRY OCTAL\no it's okay, it has its revenge from time to time\no try this out in Java sometime:\nSystem.out.println(\"012345 = \" + 012345);"
        },
        {
            "lecture": 1,
            "content": "More Notes about Cheating\n\u25cf Again, do not cheat.\n\u25cf I\u2019m not grading projects assignments, but I still look at your work.\n\u25cf Ask for help (There are PLENTY of resources)\no TAs and my own office hours\no Undergraduate Helpdesk (CRC)\no We want you to succeed!\n\u25cf I can definitely tell when someone cheats.\nAnd\u2026 believe it or not, I can use google!\no It is very obvious.\no Do not do it.\no The University is justifiably strict about it.\n\u25cf Do not publish your code until after the semester (if at all)\no Use private git repositories if you want to share with employers\n8\nTeaching Pedagogy / Philosophy\n\u25cf I will help you, but you must ask for help.\no You are learning, it\u2019s expected you are confused at times.\no That\u2019s why I\u2019m here!\n\u25cf Work with other students.\no Study groups are good!\no Companies value ability to work with others! (You won\u2019t work alone)\n\u25cf No questions are dumb!\no You ARE learning! You are not supposed to know things\u2026\no If you have a question, likely other people will also have it!\no Even if you are supposed to know that, you don\u2019t\u2026 so ask!\no So ASK QUESTIONS!\no DON\u2019T STRUGGLE IN SILENCE\n9\nTeaching\n\u25cf No questions are dumb!\n\u25cf Are you confused?\no Surprise, surprise, surprise! IT\u2019S EXPECTED!\no You are learning a bunch of new stuff!\no So ASK QUESTIONS!\no DON\u2019T STRUGGLE IN SILENCE ON YOUR PROJECTS/LABS!!!!!!!\n\u25cf Regret #1 of my students:\no I should have started earlier ;)\n\u25cf Come to lectures synchronously if you can!\no You have access to me, we can interact\no You can ask questions, and get the answers promptly!\no Please\u2026 be interactive J\n10\nLessons learned\n\u25cf I scare some students (source: OMETs)\no Sorry :\u2019)\no Don\u2019t be scared! I like to help!\n\u25cf If I exclaim \u201coh god\u201d looking at your code\no Sorry? :D\n\u25cf Regret #1 of my students:\no I should have started earlier ;)\n\u25cf Come to lectures!\no You have access to me, we can interact\no You can ask questions, and get the answers promptly!\no Please\u2026 be interactive J\n\u25cf If you are bored, let me know\n11\nIntroduction and Context\n12\nGoals of this course\n\u25cf Why should I take it?\no Looking under the hood (car analogy)\u2026\no How do you understand complex modern architectures?\n\u00a7 Learning the basics (here)\n\u25cf Topics covered\no Data representation\no Assembly language\no Program execution\n\u25cf Learning important fundamental skills:\no Representing numbers in different bases (binary, hexadecimal, \u2026)\no Logical operations: The binary revolution\no Logic design: Making circuits without knowing EE :sad:\no Programming an assembly language \u2013 FUN! (your mileage may vary)\n13\nComputational Theory\nAlgorithm Design\nApplications\nOperating Systems\nISA\nLogic Design\nElectrical Design\nPhysics\nmore abstract more concrete\nWhere does this material fit in with CS and EE?\n\u25cf The \u201chardware-software interface\u201d\no where CS and EE overlap\n\u25cf Each layer affects/is affected by\nlayers above and below\n\u25cf ISA: Instruction Set Architecture\no Programmer's interface to\nthe computer hardware\n\u25cf logic design\no how we make 0\u2019s and 1\u2019s do stuff\no How do we build a CPU\n14\nMore goals\n\u25cf Let\u2019s learn Assembly!\no Now YOU are the compiler!\n\u25cf Let\u2019s unlearn High-level languages (Java, C)\no Datatypes/structures? Nope!\no Infinite number of variables? Nope-ish!\n\u25cf \u201cLearning assembly is like a car mechanic learning how an engine runs\u201d\no Normal people don\u2019t want to, but it\u2019s fun to take things apart!!!\n\u00a7 Also putting them back together and (hopefully) see them work!\no And we are not normal people!\n15\nFAQ\n\u25cf Maybe the answer for my question is in the next slide. Should I ask?\no Yes! I\u2019ll let you know if that\u2019s the case\n\u25cf I\u2019m sure I should know this. I shouldn\u2019t ask!\no NO! Probably you should not know that yet! So just ASK!\no NO! Maybe you should know, BUT you don\u2019t\u2026 So ASK!\n\u25cf I\u2019m embarrassed I don\u2019t want to ask\no That\u2019s fine! But don\u2019t be! Others will have the same question! I assure you!\no But if you want, write the question down, send it to me privately!\no BUT ASK!!!! (later)\n\u25cf Should I ask?\no YES! Interrupt me at any time!!!\no Like now? INTERRUPT ME!!!\n16\nComputers\n17\nThey are old!\n18\n\u2022 Thousands of years old\n\u00a7 Late second/early first century BC\n\u00a7 That\u2019s like -100 ish\n\u2022 Used for astronomy\n\u00a7 Eclipses\n\u00a7 Astronomical positions\nThe Antikythera\nMechanism\nThey are not (ALL) war machines\n19\n\u2022 Mechanical loom (1804)\n\u00a7 Programmed using perforated cards\n\u00a7 Used to produce complex patterns\nJacquard machine\nWoven in silk\nusing 24k punch\ncards!\nThe pre-history of computers\n20\n\u2022 Designed by Charles Babbage\n\u00a7 1792-1871\n\u2022 Ermmm\u2026 Designed\u2026 right!\n\u00a7 It was intended as a programmable\ncalculator\n\u00a7 A multipurpose calculator!\nThe Differential\nEngine\nThe pre-history of computers\n\u25cf The Differential Engine\no Devised by J.H. M\u00fcller in the Hessian army (1784)\no Designed by Charles Babbage (1819-ish)\no Built at Science Museum library in London (1980s)\no Outputs to a table that can be used for printing\n\u00a7 Copying was a source of error\n\u00a7 It still is nowadays\n\u00a7 So never copy results manually if you can avoid it\n21\nThe pre-history of computers\n22\n\u2022 Designed by Charles Babbage\n\u00a7 YES! Designed\u2026 again!\n\u2022 Mechanical general-purpose\ncomputer\n\u00a7 Which had many modern\ncharacteristics\nThe Analytical\nEngine\nNo actual picture because\u2026 it was never built\n\u201cThe Enchantress of Numbers\u201d - the first programmer\n\u25cf Augusta Ada King, Countess of Lovelace\no Wrote algorithms for this computer \u00e0\n\u00a7 Yeah, that one!\n\u00a7 But they probably would have worked\no Translating a paper, she added notes\no A LOT of notes\n\u00a7 More than the actual paper\no Including instructions on how to calculate\na number series\n\u00a7 Note G\no Studied the relation between maths and music\n23\nPart of note G\n24\nThe Analytical Engine has no pretensions\n(\u2026) to originate anything. It can do\nwhatever we know how to order it to\nperform.\nIt can follow analysis; but it has no\npower of anticipating any analytical\nrelations or truths.\nThe pre-history of computers\n25\n\u2022 Census happen every 10 years\n\u00a7 Hey, they just did!\n\u2022 It took people 8 years to count\nresponses (in 1880)\n\u00a7 It would soon take more than 10!\n\u00a7 7,000 cards a day using this system\n\u2022 Company would become IBM\n\u00a7 After a merge with others\nHollerith Electric\nTabulating System\n(replica)\nhttps://www.computerhistory.org/revoluti\non/punched-cards/2/2/5\nBubbles\n26\n\u2022 Check what Bubbles has to say about it J\n\u00a7 https://www.youtube.com/watch?v=L7jAOcc9kBU\nDriven by the need for complex calculations\n\u25cf George Stibitz (Bell Labs)\no Day-job: Electrical engineer\no Model K \u2013 binary addition with relays (Boolean algebra)\no Complex Number Computer \u2013 used remotely via telegraph lines!!\no Art with Amiga (1990s) - http://stibitz.denison.edu/art.html\n\u25cf Konrad Zuse (Germany)\no Day-job: Aircraft designer (civil engineer)\no World's first programmable computer\no Several computers used for military calculations\n\u25cf John Atanasoff (Iowa State)\no Day-job: Physics professor\no Built the ABC (Atanasoff-Berry Computer)\n\u00a7 solved 30 equations in 30 unknowns\n27\nhttps://computerhistory.org/blog/first-steps-lectures-from-the-dawn-ofcomputing/\nThe first \u201cmodern\u201d computers\n28\nU. S. Army Photo\n\u2022 1946 \u2013 ENIAC\n\u00a7 University of Pennsylvania\n\u00a7 Developed during WWII to calculate\nbalistic missile trajectories\n\u00a7 Designed by :\n\u2022 John Mauchly\n\u2022 J. Presper Eckert\n\u00a7 Joined by a huge team!\n\u00a7 Modular and reconfigurable\n\u2022 Flipping switches and connecting cables\nENIAC (Electronic Numerical Integrator and Computer) \nENIAC (Electronic Numerical Integrator and Computer)\n\u25cf Some numbers:\no 18000 valves (tubes)\no 1500 relays\no 30 tons\no 175 kW\no 5000 additions / s\no 357 multiplications / s\no 40 divisions / s\no Programs \"hardwired\"\n29\nU. S. Army Photo\nThe first \u201cmodern\u201d computers\n30\nU. S. Army Photo\n\u2022 1947 \u2013 EDVAC\n\u00a7 University of Pennsylvania\n\u00a7 The ENIAC team joined by John Von Neumann\n\u00a7 A computer with a new concept:\n\u2022 \"Memory Stored Program\" \u2013 same as data\n\u00a7 Became operational in 1951\nEDVAC (Electronic Discrete Variable Automatic Computer)\nThe first \u201cmodern\u201d computers\n31\n\u2022 1949 \u2013 EDSAC\n\u00a7 Cambridge University\n\u00a7 Designed by Maurice Wilkes\n\u00a7 Based on the first EDVAC draft\n\u2022 Not to be better, but to be used!\n\u2022 accessible and practical vs. push technology\n\u2022 Was completed before the EDVAC!\n\u00a7 Used for scientific research\n\u2022 Chemistry, Medicine, Physics\nEDSAC (Electronic Delay Storage Automatic Calculator)\nhttps://www.tnmoc.org/edsac\nhttps://en.wikipedia.org/wiki/EDSAC\nThe first \u201cmodern\u201d computers\n32\n\u2022 1951 \u2013 UNIVAC\n\u00a7 First commercial computer!\n\u2022 Sold 46! Units\n\u2022 Used to predict the 1952 presidential election\n\u00a7 Used MERCURY!! memory (as did the EDSAC)\nUNIVAC (Universal Automatic Computer)\nDelay\nStorage\nhttps://en.wikipedia.org/wiki/Delay_line_memory\nThen came the transistor\n33\n\u2022 The symbol for a transistor\n\u00a7 Photo taken in the university\nwhere I did my master degree\n\u2022 They were tiny\n\u00a7 Didn\u2019t get HOT!\n\u00a7 Didn\u2019t break as often\nhttps://en.wikipedia.org/wiki/Transistor\nThen came the Integrated circuit\n34\n\u2022 Things became tiny\n\u00a7 More transistors could be fitted\n\u00a7 Cheaper circuits\n\u00a7 More affordable\n2300 of these\nin there\nExtremely brief story of Intel CPUs\n\u25cf 1971 \u2013 Intel 4004\no 4-bit microprocessor\no with 2300! Transistors\n\u25cf 2004 \u2013 Pentium 4\no x86 32-bit\no 125 Million transistors\n\u25cf 2017 \u2013 Kaby Lake\no x86_64 64-bit\no >1000 Million! (undisclosed?)\n35\nMoore\u2019s Law\n36\n82944 processors\nfrom a supercomputer\nWhere used to simulate\n1s of human brain activity\nIn 40m\nIllustration:\nhttps://www.wired.com/2013/05\n/neurologist-markam-humanbrain/\nAll different but all (mostly) the\nsame\n37\nClasses of computers: Embedded (Microcontrollers)\n\u25cf 8/16-bit architectures are still common\no What does this mean?\n\u25cf As little as 32 BYTES of memory!\no almost always run one, built-in program\n\u25cf Focus on ultra-low power, cost, and size\no becoming more common every day\no \u201cInternet of Things\u201d (IoT)\no now your fridge can crash,\nyour TV can crash,\nyour dishwasher can crash,\neverything can crash!\n38\nClasses of computers: Consumer-grade (PC/Mobile)\n\u25cf 1-8 cores, 32/64-bit architectures, MB-GB of\nmemory, GB-TB of persistent storage\n\u25cf multitasking operating systems\n\u25cf similar capabilities, different design goals\n\u25cf focus is real-time user interaction:\nproductivity, media, browsing, games\n\u25cf Energy consumption is still relevant\no Mobile\n39\nClasses of computers: Servers and Mainframes\n\u25cf from high end desktops to much more powerful\nmachines or groups of machines\n\u25cf dozens of cores, 32GB+ of RAM, massive storage\nsystems, very high-speed networking\n\u25cf focus on real-time data delivery - either from\nstorage or after processing\n\u25cf redundancy and hot-swappability\n\u25cf goal is 100% uptime\n\u25cf power and cooling become huge concerns\n40\nClasses of computers: Supercomputers\n\u25cf cluster of hundreds to thousands of CPUs\n\u25cf focus on crunching ENORMOUS datasets non-interactively\n\u25cf science, research, design, and simulation\no and now, stock trading and \"cryptocurrencies\"\u2026\n41\nAll looking pretty much the same\n42\nThe Internet\nGeneral computer organization\n43\nControl\nRegisters\nDatapath\nProcessor\nMemory\nPersistent\nStorage\nOther\nPeripherals\nOther\nComputers\nInput/Output\nDevices\nNetwork\nAssembly\n44\nWhat assembly?\n45\n10011101100110011001111101111001\n11011110110010111011101001111001\n10011100100110110001101111111011\nlw $t0, x\naddi $t0, $t0, 1\nsw $t0, x\nx=x+1\nMachine language\nSpoken by the CPU\u00e0 Binary\nAssembly language\nWritten by humans\u00e0 No abstraction\nHigh-level language\nWritten by humans \u00e0 Abstracted Closer to the\nhardware\nEasier to\nread\nRandom numbers J\nWHY assembly? Because ALL of these run C (a popular high-level language)\n46\nhttps://en.wikipedia.org/wiki/PDP7#/media/File:Pdp7-oslo-2005.jpeg\nAnd they are VERY different\ncomputers (if you can\u2019t tell!)\nHigh-level languages\nHEAVILY abstract the\nhardware underneath!\nSo what exactly is assembly?\n47\n\u2022 Assembly: Human-readable representation of machine code\n\u2022 Machine code: Machine code is what a CPU actually runs\n\u2022 Essentially it's the \"atoms\" that make up a program\noCPUs are actually pretty simple in concept\n\u00a7 (oh wait, we still have a whole semester about it\u2026 huh)\n\u2022 Each CPU has its own machine language and therefore its own assembly\nlanguage\n\u2022 We\u2019ll be using MIPS:\noNot that common (why then?)\noYet, often found in surprising places. (Nintendo 64, PS1/2, FPGAs)\noVery influential, and most common assembly looks like it.\n\u00a7 ARM and RISC-V are similar-ish ISA\nseeing much more usage\nDifferent language levels\n48\nlea x, %eax\nmov 0(%eax), %ecx\ninc %ecx\nmov %ecx, 0(%eax)\nx=x+1\n010011110111100100011\n011001011100111101100\n101110011010110100111\n101111001000110110010\n1110\n1001110110011001100\n1111101111001110111\n1011001011101110100\n1111001100111001001\n1011000110111111101\n1\nlw $t0, x\naddi $t0, $t0, 1\nsw $t0, x\nMachine language\n\u00e0 Different for different CPUs\nAssembly language\n\u00e0 Different for different CPUs\nHigh-level language\n\u00e0 Same for different CPUs\nRandom numbers J Random numbers J\nis assembly language useful today?\n49\n\u2022 Short answer: YES\n\u2022 Assembly is \u201cfast\u201d, so we should use it for everything!\n--- NO!!! ---\n\u2022 No type-checking, no control structures, very few abstractions\noProbably you can be fairly fast using compiler optimizations\n--- Fairly impractical for large things ---\n\u2022 Tied to a particular CPU.\noSo, large programs have to be rewritten (usually) to work on new things.\n\u2022 Yet: good for specialized stuff.\noCritical paths and \u201cboot\u201d code in Kernels / Operating Systems\noHPC (simulators, supercomputer stuff)\noReal-time programs (video games; tho increasingly less / abstracted away)\noAnd\u2026\nEmbedded systems\n\u25cf You\u2019d be amazed at how many consumer devices have CPUs.\n\u25cf Many are programmed largely/entirely in assembly (or C)\n50\nand next time we'll start\n51\n\u2022 Data representations\n\u2022 How does a CPU look at numbers, letters, etc.\n\u2022 Learn about number bases:\no Decimal (that\u2019s what we use!)\no Binary\no Octal\no Hexadecimal"
        },
        {
            "lecture": 5,
            "content": "Class announcements\n\u25cf Repeat after me:\no Store copies from the CPU to memory\no Load copies from memory to CPU\n2\nSo far\u2026\n\u25cf Putting numbers into registers\n\u25cf COPYing register contents\n3\nli a0, 3\nmove a0, t0\nIn another perspective\nOther operations\nadd\nsub\nmul\nsyscall\n\u2026 4\nCPU\nRegisters\nmove\nli\nRunning into a problem\n\u25cf How many registers does MIPS have?\no 32!\n\u25cf Do you think that\u2019s enough to run your programs?\no I hope that was a no!\no Cause you can\u2019t!\n\u25cf So what can we do?\n5\nMemory\n6\nWhat is the memory?\n7\n\u2022 The system memory is a piece of temporary storage hardware\noit's smaller and faster (more expensive!) than the persistent storage.\n\u00a7 maybe in the future it won't be temporary\n\u00a7 the line between system memory and persistent storage will fade away\u2026\n\u2022It's where the programs and data that the computer is currently executing\nand using reside\noall the variables, all the functions, all the open files etc.\nothe CPU can only run programs from system memory!\nBytes, bytes, bytes\n\u25cf The memory is a big one-dimensional array of bytes\n\u25cf What do these bytes mean?\no \u00af\\_(\u30c4)_/\u00af\n\u25cf Every byte value has an address\no This is its \"array index\"\no Addresses start at 0, like arrays in C/Java\n\u00a7 Gee wonder where they got the idea\n\u00a7 Addresses are the offset from the beginning!\n\u25cf When each byte has its own address, we call it a byteaddressable machine\n8\nAddr Val\n0 00\n1 30\n2 04\n3 00\n4 DE\n5 C0\n6 EF\n7 BE\n8 6C\n9 34\nA 00\nB 01\nC 02\nBut they are possible\n\u25cf Other types are not common\no E.g. When each word has its own address, we call it a\nword-addressable machine\n9\nAddr Val\n0 00300400\n1 DEC0EFBE\n2 6C340001\nDon\u2019t confuse with this!\nThis is only the representation of\nwords in a byte-addressable\nAddr Val\n0 00300400\n4 DEC0EFBE\n8 6C340001\nIn word-addressable\nmemory, each\naddress is a word Note the\naddresses\nthey\nincrement\nby 4!\nHow much memory?\n\u25cf If each address refers to one byte. if your addresses are n bits long\u2026\nhow many bytes can your memory have?\no 2n B\n\u25cf machines with 32-bit addresses can access 232 B = 4GiB of memory\no with 64-bit addresses\u2026 16EiB\n\u25cf Remember:\no kibi, Mebi, Gibi, Tebi, Pebi, Exbi are powers of 2\n\u00a7 kiB = 210, MiB = 220\n, GiB = 230 etc.\no kilo, mega, giga, tera, peta, exa are ostensibly powers of 10\n\u00a7 kB = 103\n, MB = 106\n, GB = 109 etc.\n10\nWords, words, words\n\u25cf For most things, we want to use words\no The \"comfortable\" integer size for the CPU\no On this version of MIPS, it's 32b (4B)\n\u25cf But our memory only holds bytes\u2026\n\u25cf Combine multiple bytes into larger values\no The CPU can handle this for us\no But importantly, the data is still just bytes\n\u25cf When we talk about values bigger than a byte\u2026\no The address is the address of their first byte\n\u00a7 The byte at the smallest address\no So what are the addresses of the three words here?\n11\nAddr Val\n0 00\n1 30\n2 04\n3 00\n4 DE\n5 C0\n6 EF\n7 BE\n8 6C\n9 34\nA 00\nB 01\nC 02\nMemory access in different\narchitectures\n12\nAccumulator architectures\n\u25cf Early architectures only used one register (usually called the Accumulator)\no They were expensive!\no Example: add the word in memory address 200 to the value of acc and\nplace the result in acc\nadd 200\n\u25cf The next evolutionary step was adding more registers that served specific\npurposes: called special-purpose\no Intel had some of these (ax, bx, cx, dx)\no Some of those registers were used implicitly by some instructions.\n13\nThe destination is\nacc, the only register\nGeneral-purpose register architectures\n\u25cf Multiple registers that can be used for any purpose.\no As a generalization of the special-purpose registers\n\u25cf Can be further divided:\no register-memory architectures\n\u00a7 E.g.: x86, x86-64\no Many instructions can access memory and registers at the same time\no register-register architectures (aka load-store architectures)\n\u00a7 E.g.: MIPS, ARM, RISC-V\no Only special instructions can access memory\n14\nGeneral-purpose register architectures\n\u25cf In x86-64 (register-memory), many instructions can access memory\no Example: add [rsp-8], rcx\n\u00a7 Adds the contents of register rcx\nto the value at memory address rsp-8\n\u25cf MIPS is a load-store architecture, all memory accesses are done with two\nkinds of instructions: loads and stores\n15\nRegisters Memory\nloads loads copy data from memory\ninto CPU registers\nstores stores copy data from CPU\nregisters into memory\nMIPS cannot\ndo this!\nLoad immediate is not a \u201cload\u201d\n16\nWhen we talk about\nloads and stores\nwe are only talking\nabout instructions\nthat access memory.\n! !\nMIPS: Variables, Loads, Stores\n17\nMemory addresses\n\u25cf Everything in memory has an address\no the position in memory where it begins\n\u00a7 where its first byte is\no this applies to variables, functions, objects, arrays etc.\n\u25cf A super important concept:\nevery piece of data really has two parts:\nan address and a value\n\u25cf If you want to put a variable in memory\u2026\no first you need to figure out what address to put it in\no this extremely tedious task is handled by assemblers\n\u00a7 whew\n18\nPutting a variable in memory\n\u25cf we can declare a global variable like this:\n.data\nx: .word 4\n\u25cf the Java/C equivalent would be static int x = 4;\n\u25cf .data says \"I'm gonna declare variables\"\no you can declare as many as you want!\no to go back to writing code, use .text\n\u25cf if we assemble this little program and make sure Tools > Show Labels\nWindow is checked, what do you see?\no the assembler gave the variable that address\no it'll do that for every variable\n19\nname type initial value\nAccessing memory in MIPS\n20\nMIPS ISA: What is the address? O.o\n\u25cf You can load the 32-bit address of a variable with la\nla t0, x # loads the ADDRESS of x into t0\nt0 \u00df will now contain 4: The address of variable x\n21\nstatic int x = 0xDEC0EFBE;\nt0 = &x;\nAddr Val\n0 00300400\n4 DEC0EFBE\n8 6C340001\nx\nx: .word 0xDEC0EFBE\n\u2026\nla t0, x # loads the ADDRESS of x into t0\nIn C, &x means\nthe memory\naddress of x\nThis is SORT-OF equivalent. Details being ignored (the assembly address should be a void pointer if you know about them)\nMIPS ISA: Access the data!\n\u25cf You can load and store entire 32-bit words with lw and sw\n\u25cf The instructions look like this:\nlw/sw register_data, offset(register_address)\n\u25cfIndirect addressing with offset :\noIndirect: The memory address is the value in a register\noOffset: You add a constant to that value\n22\nEffective address = value of register_address + offset\nMIPS ISA: Pseudo-instruction\n\u25cf Ermm\u2026 In MIPS, stores are written with the destination on the right. !?\no well, you can remember it with this diagram\u2026\no the memory is \"on the right\" for both\nloads and stores\n23\nRegisters Memory\nlw\nsw\nMIPS ISA: Examples\nComparing with a HLL (C, cause Java don\u2019t do this!)\n24\nstatic int x = 0xDEC0EFBE;\nt0 = &x;\ns0 = *t0;\n*t0 = s0;\nx: .word 0xDEC0EFBE\n\u2026\nla t0, x # loads the ADDRESS of x into t0\nlw s0, 0(t0) # loads from variable x into s0\nsw s0, 0(t0) # stores from s0 into variable x\nIn C, *t0 means the\ncontents in the memory.\nThis is equivalent to just x\nJ\nThis is SORT-OF equivalent. Details being ignored (the assembly address should be a void pointer if you know about them)\nMIPS ISA: Pseudo-instruction\n\u25cf The Assembler gives us a shortcut :D (pseudo-instruction)\nlw s0, x # loads from variable x into s0\nsw s0, x # stores from s0 into variable x\n25\nstatic int x = 0xDEC0EFBE;\ns0 = x;\nx = s0;\nx: .word 0xDEC0EFBE\n\u2026\nlw s0, x # loads from variable x into s0\nsw s0, x # stores from s0 into variable x\nOperating on variables in memory (animated)\n\u25cf We want to increment a variable that is in memory\no where do values have to be for the CPU to operate on them?\no what do we want the overall outcome to be?\n\u25cf so, what three steps are needed to increment that variable?\n1. load the value from memory into a register\n2. add 1 to the value in the register\n3. store the value back into memory\n\u25cf Every variable access works like this!!!\no HLLs just hide this from you\n26\n45 45 x\nRead, modify, write\n\u25cf you now know enough to increment x!\n\u25cf But first, lets look at some code\n\u25cf first we load x into a register\n\u25cf then\u2026\n\u25cf and then\u2026\n\u25cf let's see what values are in t0 and memory after this program runs\n27\nlw t0, x\nadd t0, t0, 1\nsw t0, x\nIt really is that simple\n\u25cf variables in asm aren't THAT scary\n\u25cf please don't be afraid of them\n\u25cf you just gotta remember to store if you wanna change em\n28\nQuestions?\n29\n\u2022 Just in case I prepared some for you:\no Does load word (lw) put or get data from memory?\noI already know the word is the most \u201ccomfortable\u201d size for the CPU, but are\nthey the only size it can work with?\nSmaller values\n30\nSmaller numeric\n\u25cf MIPS also understands smaller and tiny datatypes\n.data\nx: .word 4 => 0x00000004\nsmall: .half 4 => 0x0004\ntiny: .byte 4 => 0x04\n\u201cDatatypes\u201d: Unlike HLL, these assembly datatypes are\nall about the size, not the data contained\n31\nMIPS ISA: loading and storing 8/16-bit values\n32\n\u2022to load/store bytes, we use lb/sb\n\u2022to load/store 16-bit (half-word) values, we use lh/sh\n\u2022these look and work just like lw/sw, like:\nlb t0, tiny # loads a byte into t0\nsb t0, tiny # stores a byte into tiny\nlh t0, small # loads a half-word into t0\nsh t0, small # stores a half-word into tiny\no\u2026or DO THEY?!?!?!?\n\u2022 how big are registers?\nowhat should go in those extra 16/24 bits then?\n\u00a7 ???\ncan I get an extension? \u2026 no\n\u25cf Sometimes you need to widen a number with fewer bits to more\n\u25cf zero extension is easy: put 0s at the beginning.\n10012 \u00e8 to 8 bits \u00e8 0000 10012\n\u25cf But then there are also signed numbers\no the top bit (MSB) of signed numbers is the sign (+/-)\n\u25cf Sign extension puts copies of the sign bit at the beginning\n10012 \u00e8 to 8 bits \u00e8 1111 10012\n00102 \u00e8 to 8 bits \u00e8 0000 00102\no like spreading peanut butter\n33\n\u25cf if you load a byte\u2026\n34\nE X P A N D V A L U E\n31 0\n00000000 00000000 00000000 00000000\n10010000\n31 0\n11111111 11111111 11111111 10010000\nIf the byte is signed\u2026 what should it become?\n31 0\n00000000 00000000 00000000 10010000\nIf the byte is unsigned\u2026 what should it become?\nlb does\nsign extension.\nlbu does\nzero extension.\nHow does the CPU know whether it's signed or unsigned\n35\n\u2022 Do YOU think the CPU knows this?\nono\n\u00a7 it doesn't\n\u2013 you have to use the right instruction.\n\u2022It\u2019s particularly easy to mess this up\nolbu is usually what you want for byte variables but lb is one character\nshorter and just looks so nice and consistent\u2026\noBut don\u2019t! \n31 0\n10100010 00001110 11111111 00000100\nTruncation\n\u25cf If we go the other way, the upper part of the value is cut off.\n\u25cf The sign issue doesn't exist when storing, cause we're going from a larger\nnumber of bits to a smaller number\no therefore, there are no sbu/shu instructions\n36\n31 0\n10100010 00001110 11111111 00000100\n11111111 00000100\nsh\nEndianness\n37\nA matter of perspective\n\u25cf let's say there's a word at address 4\u2026 made of 4 bytes\n\u25cf wh\u2026what word do those 4 bytes represent?\n38\nAddr Val\n... ...\n7 DE\n6 C0\n5 EF\n4 BE\n... ...\n\u2026is it\n0xBEEFC0DE?\n\u2026is it\n0xDEC0EFBE?\nEndianness\n\u25cf When interpreting a sequence of bytes as larger values, endianness is\nthe rule used to decide what order to put the bytes in memory\n39\n0xBEEFC0DE 0xDEC0EFBE\nbig-endian means \u201cyou\nstart with the BIG end\"\nlittle-endian means \u201cyou\nstart with the LITTLE end\u201d DE C0 EF BE\n0 1 2 3\nNothing to do with value of\nbytes, only the order you\nstore them in memory\nWhich is better: little or big?\n\u25cf it doesn't matter.* as long as you're consistent, it's fine\n\u25cf for political (x86) reasons, most computers today are little-endian\n\u25cf but endianness pops up whenever you have sequences of bytes:\no like in files\no or networks\no or hardware buses\no or\u2026 memory!\n\u25cf which one is MIPS?\no it's bi-endian, meaning it can be configured to work either way\no but MARS uses the endianness of the computer it's running on\n\u00a7 so little-endian for virtually everyone\n\u2013 cause x86\n\u2013 Apple ARM CPUs will use a little-endian architecture\n40 *big endian is better\nWhat DOESN'T endianness affect?\n\u00d7 the arrangement of the bits within a byte\no it just changes meaning of order of the bytes\n\u00a7 note the bytes are still DE, C0 etc.\n\u00d7 1-byte values, arrays of bytes, ASCII strings\u2026\no single bytes don\u2019t care about endianness at all\n\u00d7 the ordering of bytes inside the CPU\no there's no need for e.g. \"big-endian\" arithmetic\no the CPU works with whole words\n\u25cf endianness only affects moving/splitting data:\no larger than single bytes\no between the CPU and memory\no or between multiple computers\n# Increments the value of a variable x in memory\n# C equivalent:\n#  int main(void) {\n#    static int x = 4;\n#    x = x + 1;\n#    printf(\"%d\", x);\n#    return 0;\n#  }\n\n.data\n  x: .word 4        # Declare variable x of word size and value 4\n\n.text\n.globl main\nmain:\n\tlw t0, x          # Load variable x from memory into register t0\n\tadd t0, t0, 1     # t0 = t0 + 1\n\tsw t0, x          # Store variable x from t0 into memory\n\n\tli v0, 1          # Print service provided by the OS (implemented in MARS)\n\tmove a0, t0       # Pass the value we want to print in a0 (it is so defined)\n\tsyscall           # Invoke the OS\n\n\tli v0, 10         # Terminate program service\n\tsyscall           # Invoke the OS"
        },
        {
            "lecture": 4,
            "content": "Programs and Instructions\n3\nWhat are they?\n\u25cf An instruction is a single, simple operation for the computer to carry out, such as:\no \"add two numbers together\"\no \u201ccopy a number from one location to another\"\no \"go to a different place in the program\"\no \"search a string for a character\u201c\n\u25cf A program is a series of these tiny instructions\no How do we create these instructions?\no And how does the computer \"understand\" them?\n\u00a7 does the computer understand anything?\n4\nA program\n\u25cf For example a set of instructions to calculate 3+5:\no (4, 2)\no (4, 3)\no (3, 1)\no (5, 3)\n\u25cf Any guesses? J\n5\nMachine language and Assembly language\n\u25cf Machine language instructions are the patterns of bits that a processor\nreads to know what to do\n\u25cf Assembly language (or \"asm\") is a human-readable, textual\nrepresentation of machine language\n6\nMIPS asm MIPS machine language\nadd t2, s2, t0 000000 10010 01000 01010 00000 100000\n<math> s2 t0 t2 n/a add\nlw t0, 1200(t1) 100011 01001 01000 0000010010110000\nlw t1 t0 1200\nsw t2, 1200(t1) 101011 01001 01010 0000010010110000\nsw t1 t2 1200\nWhat can a CPU do?\n7\nMaths Go execute\nsomewhere else\nLoad/Store things\nfrom/to memory\nExample: Count up to 10\n1. Load variable from memory (memory)\n2. If value equals 10 stop (cond. Go execute)\n3. Add 1 to variable value (maths)\n4. Place new value in the variable (memory)\n5. Go back to the top (incond. Go execute)\n6. stop\nIS THAT ENOUGH?\n8\nRemember the Turing machine?\n\u25cf Has infinite memory represented by a single tape.\no A head moves along the tape and can read and write values.\n\u00a7 The movement (left or right) is based upon the value read and the state of the machine.\n\u25cf The machine:\n1. Reads/writes the memory (tape)\n2. Compares that data and decides where to move (execute) next\n\u25cf Everything that can be computed, is computed by a Turing machine\n9\nRulebook 1\n\u00e8\nRead Write Move Next\n0 1 \u00df 20\n1 0 \u00e0 12\nRulebook 20\nRead Write Move Next\n0 0 \u00e0 15\n1 1 \u00e0 15\nCPUs are WAY\nmore complex\nHow a CPU runs a program\n10\n1. read an instruction\n2. do what it says\n3. go to step 1\no...okay there's a little more to it than that\nControl Registers\nDatapath\nProcessor\nMemory\nPersistent\nStorage\nHow a CPU runs a program\n11\n\"C = A + B\"\nProgram Program\ninstruction\n3 5\n+\n8 A B\nC\n\u2026and repeat!\nISAs\n12\nInstruction Set Architecture (ISA)\n\u25cf An ISA is the interface that a CPU presents to the programmer\no When we say \u201carchitecture\u201d, this is what we mean\n\u25cf ISAs define:\no WHAT the CPU can do (add, subtract, call functions, etc.)\no WHAT registers it has (we'll get to those)\no WHAT the machine language is\n\u00a7 Machine language: the bit patterns used to encode instructions\n\u25cf ISAs do not define:\no HOW the CPU does it\no HOW to design the hardware!\n\u00a7 \u2026if there's any hardware at all\n\u2013 Java\n13\nWHY? O.o\nISAs example: x86 \u25cf Descended from 16-bit 8086 CPU from 1978 o Implemented in a rush by intel \u25cf Extended to 32 bits, then 64 \u25cf Each version can run all programs from the\nprevious version o you can run programs written in 1978 on\na brand new CPU!\n\u25cf So why don't we learn x86 in this course? o It can do a lot of things o Its machine language is very complex o Making an x86 CPU is\u2026 difficult o Ultimately, we would waste a ton of time\n14\nI\u2019m an x86 CPU!\nI\u2019m an x86\nCPU!\nI\u2019m an\nx86\nCPU!\nAll three processors run the exact same programs\u2026\n\u25cf but they're TOTALLY different on the inside\n15\nIntel Core i7\nAMD Zen\nVIA Nano\nKinds of ISAs: CISC\n\u25cf CISC: \"Complex Instruction Set Computer\"\n\u25cf ISA designed for humans to write asm\no from the days before compilers!\n\u25cf lots of instructions and ways to use them\n\u25cf complex (multi-step) instructions to shorten\nand simplify programs\no \"search a string for a character\"\no \"copy memory blocks\"\no \"check the bounds of an array access\"\n\u25cf x86 is very CISCy\n16\nprguitarman.com\nKinds of ISAs: RISC\n\u25cf RISC: \"Reduced Instruction Set Computer\"\n\u25cf ISA designed to make it easy to:\no build the CPU hardware\no make that hardware run fast\no write compilers that make machine code\n\u25cf a small number of instructions\n\u25cf instructions are very simple\n\u25cf MIPS is very RISCy\n\u25cf MIPS and RISC were the original RISC architectures\ndeveloped at two universities in California\no the research leads were\u2026 Patterson and Hennessy\u2026\n17\nPopular ISAs today\n\u25cf x86 (these days, it\u2019s x86-64 or \u201camd64\u201d)\no most laptops/desktops/servers have one\no (modern x86 CPUs are just RISC CPUs that can read the weird x86 instructions)\n\u00a7 (unless you ask Intel, they will say otherwise J)\n\u25cf ARM\no almost everything else has one\no ARMv8 (AArch64) is pretty similar to MIPS!\n\u00a7 More than to ARMv7: \u201cthe main similarity between ARMv7 and ARMv8 is the\nname\u201d \u2013 Comp. Org. & Design page 159\n\u25cf Everything else: Alpha, Sparc, POWER/PPC, z, z80, 29K, 68K, 8051, PIC, AVR, Xtensa,\nSH2/3/4, 68C05, 6502, SHARC, MIPS...\no microcontrollers, mainframes, some video game consoles, and historical/legacy\napplications\n\u25cf despite its limited use today, MIPS has been incredibly influential!\n18\nThe MIPS ISA:\nRegisters\n19\nThe registers\n\u25cf Registers are a small and fast temporary memory\ninside the CPU\n\u25cf The CPU can only operate (add, etc.) on data in\nregisters\n\u25cf MIPS has 32 registers, and each is 32 bits (one word)\n\u25cf The registers are numbered 0 to 31\u2026\no \u2026but they also have nice names\n\u00a7 The MARS version on the course website is modified\n\u2013 so you don't have to use them $ signs in the registers\n\u2013 $s0, $t1 vs. s0, t1\n20\n#\n0\n1\n2, 3\n4..7\n8..15\n16..23\n24, 25\n26, 27\n28\n29\n30\n31\nName\nzero\nat\nv0, v1\na0..a3\nt0..t7\ns0..s7\nt8, t9\nk0, k1\ngp\nsp\nfp\nra\nSpecial\npurpose\nHI\nLO\nPC\nGeneral Purpose\nUsed for multiplication\n(more on that later)\nKeeps track of the next\ninstruction to be executed\nUsed for\nfunctions\nUsed for almost\neverything else\nErm\u2026\nAvoid Totally\nFor later ;)\nAlso for later ;)\nDon\u2019t need\nthese\nDon\u2019t matter\nThe juggler\n\u25cf Registers are\u2026 like\u2026.. hands\n\u25cf You have a limited number and they can only hold small things\n\u25cf Your program's variables primarily live in memory\n\u25cf The registers are just a temporary stopping point for those values\n21\nRegisters\nMemory\n3 5 8 A B C\nIMPORTANT!\nless important\nReally, you don't have that many\n\u25cf You cannot write every program using only registers\no Don't try to\n\u00a7 please.\n\u25cf Every piece of your program has to SHARE the registers.\no Unlike high-level languages\no Where everyone gets their own locals\no Not in assembly!\n22\nThe s (saved) and the t(temporary) registers\n\u25cf There are ten temporary registers, t0 through t9\no These are used for temporary values \u2013 values that are used briefly\n\u25cf There are 8 saved registers, s0 through s7\no These are kinda like\u2026 local variables inside a function\n23\nName\nt0..t9\nName\ns0..s7\nThe trash registers\n- Thomas, UTA\nWhen to use each\n\u25cf We'll learn more about this in the coming weeks\n\u25cf Rule of thumb:\no Use t register\no Unless you need the value to persist when calling functions\n\u00a7 ok that's not too clear yet\n\u25cf 90% (made up percentage) of your code will use s and t registers\n24\nThe MIPS ISA:\nWHAT can it do?\n25\nWe have a semester to learn ;)\n26\nFor now:\nli \u00e0 Loads a number (Immediate)\nadd \u00e0 It adds 2 numbers\nsub \u00e0 It subtracts 2 numbers\nmul \u00e0 It multiplies 2 numbers\ndiv \u00e0 It divides 2 numbers\nmove \u00e0 It \u2026 ermmm\u2026 COPIES a number\nExample: Loading immediates and adding them\n27\ns0 = 3;\ns1 = 5;\ns2 = s0 + s1;\nli s0, 3\nli s1, 5\nadd s2, s0, s1\n\u25cf li stands for \"load immediate.\" what does it look like it does?\no \"immediate\" means \"number inside the instruction\"\n\u25cf add, uh, makes coffee. \u00ac_\u00ac\n\u25cf Just like in Java, C, whatever: the destination is on the left\nExample: Complex expression\n\u25cf We can re-use registers (t0 in the example) as a temporary\no For example, say we had a longer expression:\ns4 = (s0 + s1 \u2013 s2) * s3\n\u25cf What does algebra say about what order we should do this in?\n28\nadd t0, s0, s1\nsub t0, t0, s2\nmul s4, t0, s3\nYou will be thinking like a compiler\n\u25cf Writing ASM is a different way of programming than you're used to\n\u25cf To make the transition easier, try to reduce your cognitive load\no cognitive load is \"the set of ideas you have to keep in your mind to perform some\ntask.\"\no high-level languages (HLLs) reduce cognitive load by hiding the machine code,\nusing a compiler to write it for you\n\u25cf you can do the same thing: think about how to write a program in e.g. C, and then\nturn that into asm\n29\nc=a+b\nadd c, a, b\nadd s2, s0, s1\nThe other way around\n\u25cf going the other way is also useful\n30\nmul t0, s2, 33\ndiv t1, s3, s4\nsub s1, t0, t1\nt0 = s2 * 33\nhow would we write this in C/Java?\nt1 = s3 / s4\ns1 = t0 \u2013 t1\ns1 = (s2 * 33) \u2013 (s3 / s4)\nor, if we rolled it all together,\nthat's what this asm does\nWhy do you need to know this?\n\u25cf CS0447 is about building a mental model of how a computer works\n\u25cf Understanding what is happening when you write code or run programs gives you a\nmuch deeper understanding\no \"why should I avoid using this programming language feature in this speed-critical\npart of my code?\"\no \"why wouldn't this crazy idea be very fast on current architectures?\"\no \"this program is breaking in a really confusing way, I have to look at the asm to\ndebug it\"\n\u25cf This stuff is specialized but hey you're majoring/minoring in it!"
        },
        {
            "lecture": 6,
            "content": "# This program creates an array of four integers\n# and prints out a single integer.\n# :: c equivalent ::\n# void main(void) {\n#\tint myArray[] = {1,2,3,4};\n#\tprintf( \"%d\", myArray[3] );\n# }\n\n\n# Let's print out the 3rd element (the number 3)\n# Recall: we want to get the address of this\n#         array element: myArray + (i * b)\n# i will be 2 (the 1st element is at index 0!)\n# b is 4 since this is an array of \"word\" types\n#        which are 4 bytes in size.\n\n# Explore:\n#   1. Print myArray[3] instead.\n#   2. What happens if we try to print myArray[4],\n#      Does it let us? What does it print?\n#   3. What happens if we try to print myArray[4]?\n#      Does it let us? What does it print?\n#      Hint: Look at the variable declarations and memory.\n\n.data\n\t# int[] myArray = {1, 2, 3, 4}\n\tmyArray: .word 1, 2, 3, 4\n\t\n.text\n.globl main\nmain:\n\t# Print myArray[2]\n\tla t0, myArray\t# t0 = &myArray (address of myArray)\n\tli t1, 2\t# t1 = 2 (we want the 3rd element)\n\tmul t1, t1, 4\t# t1 = t1 * 4 (multiplied by 4 bytes per item)\n\tadd t2, t0, t1\t# t2 = t0 + t1 ... that is: t2 = myArray + (2 * 4)\n\t\n\tlw t0, (t2)\t# t0 = myArray[2]\n\t\n\tmove a0, t0\t# syscall(PRINT_INTEGER, t0)\n\tli v0, 1\n\tsyscall\n\t\t\n\tli v0, 10\t# syscall(EXIT)\n\tsyscall\n\n\n# This program creates an array of four integers\n# and prints out each integer.\n\n# This is fairly exhausting code, isn't it?\n# We pull the address of the array using \"la\"\n# and then manipulate the address to point at\n# the array item we care about.\n\n# We then do that over and over again.\n# We probably want a loop instead. Stay tuned!\n# (or look at array_loop_ex1.asm)\n\n# Explore: (Once you learn about functions and loops)\n#   1. Try to clean this up by using a loop instead.\n#      (see array_loop_ex1.asm for solution)\n#   2. Make a function to print an array item by\n#      passing the array address and index:\n#      printInteger(a0: array, a1: index)\n\n.data\n\t# int[] myArray = {1, 2, 3, 4}\n\tmyArray: .word 1, 2, 3, 4\n\t\n.text\n.globl main\nmain:\n\t# Print myArray[0]\n\tla t0, myArray\t# t0 = &myArray (address of myArray)\n\tlw t1, (t0)\t# t1 = myArray[0]\n\t\n\tmove a0, t1\t# syscall(PRINT_INTEGER, t1)\n\tli v0, 1\n\tsyscall\n\t\n\t# Print myArray[1]\n\tla t0, myArray\t# t0 = &myArray (address of myArray)\n\tadd t0, t0, 4\t# t0 = t0 + 4 (move to second word, which is a 4 byte integer)\n\tlw t1, (t0)\t# t1 = myArray[1]\n\t\n\tmove a0, t1\t# syscall(PRINT_INTEGER, t1)\n\tli v0, 1\n\tsyscall\n\t\n\t# Print myArray[2]\n\tla t0, myArray\t# t0 = &myArray (address of myArray)\n\tadd t0, t0, 8\t# t0 = t0 + 8 (move to third word, which is a 4 byte integer)\n\tlw t1, (t0)\t# t1 = myArray[2]\n\t\n\tmove a0, t1\t# syscall(PRINT_INTEGER, t1)\n\tli v0, 1\n\tsyscall\n\t\n\t# Print myArray[3]\n\tla t0, myArray\t# t0 = &myArray (address of myArray)\n\tadd t0, t0, 12\t# t0 = t0 + 12 (move to fourth word, which is a 4 byte integer)\n\tlw t1, (t0)\t# t1 = myArray[3]\n\t\n\tmove a0, t1\t# syscall(PRINT_INTEGER, t1)\n\tli v0, 1\n\tsyscall\n\t\n\tli v0, 10\t# syscall(EXIT)\n\tsyscall\n\n# Asks users which element from an array they want to print\n#\n# :: c equivalent ::\n# void main(void) {\n#\tchar request[] = \"Which position of the array do you want to print?\\n\";\n#\tchar reply1[] = \"In position \";\n#\tchar reply2[] = \" the value is \";\n#\tint array[10] = {2, 1, 3, 4, 7, 11, 18, 29, 47, 76}\n#\tprintf(\"%s\", request);\n#\tint user_input;\n#\tscanf(\"%d\", &user_input);\n#\tprintf(reply1);\n#\tprintf(\"%s%d%s%d\", reply1, user_input, reply2, array[user_input]);\n#\treturn 0;\n# }\n#\n# Explore:\n#   1. Replace .asciiz by .ascii on the request variable.\n#      What does it print now?\n#      Why? Hint: Remember how strings are terminated? With a zero!\n#                 Check the memory and find the first zero after the request string.\n#   2. How can you ask the user multiple entries?\n\n.data\n\t# asciiz contains a null terminator (the end of the string)\n\trequest: \t.asciiz \"Which position of the array do you want to print?\\n\"\n\treply1: \t.asciiz \"In position \"\n\treply2: \t.asciiz \" the value is \"\n\tnewline:\t.byte   '\\n'\n\t# Array with Lucas numbers\n\tarray: \t\t.word 2, 1, 3, 4, 7, 11, 18, 29, 47, 76\n\n.text\n.globl main\nmain:\n\n\t# Print the request for input\n\tli\tv0, 4\n\tla\ta0, request\n\tsyscall\t\t\t\t# print request\n\n\t# Get the user's input\n\tli\tv0, 5\n\tsyscall\t\t\t\t# read user input\n\tmove s0, v0\t\t\t# user_input is in s0\n\n\n\t# Get the value from the array\n\tla\tt0, array\t\t# array address is in t0\n\tli\tt1, 4\t\t\t# t1 gets 4 (the size of a word\n\tmul\tt1, t1, s0\t\t# t1 = 4* user_input\n\tadd\tt1, t0, t1\t\t# t1 = array + t1 (the number we are interested in)\n\tlw\ts1, 0(t1)\t\t# s1 gets the value of the user_input-th position of array\n\n\t# Print the requested value\n\tli\tv0, 4\n\tla\ta0, reply1\n\tsyscall\t\t\t\t# print reply1\n\n\tli\tv0, 1\n\tmove\ta0, s0\n\tsyscall\t\t\t\t# user selection\n\n\tli\tv0, 4\n\tla\ta0, reply2\n\tsyscall\t\t\t\t# print reply2\n\n\tli\tv0, 1\n\tmove\ta0, s1\n\tsyscall\t\t\t\t# array entry\n\n\tli\tv0, 11\n\tlb\ta0, newline\n\tsyscall\t\t\t\t# print new line\n\t\n\t# Exit\n\tli\tv0,10\t\t\t# exit\n\tsyscall\n\n# Arrays and loops: Shifting arrays\n\n# We will have an array defined by 'myArray'\n# We will then have a loop shift the values over 1\n# And then we will replace the last item with a new value.\n\n# Exercises:\n#   1. Can you alter this to do the opposite?\n#      Shift the items to the right and assign\n#      myArray[0]\n#   2. How about shifting at a *certain point*\n#      and assigning to a value within?\n#   3. Make the shift array routine the given function:\n#\n#      int arrayInsert(a0: arrayAddress, a1: arrayLength, a2: index, a3: value)\n#        Insert 'value' into the finite array at the given index.\n#        The values from index to the end of the array are shifted to \n#        make room for the new value. The value at the end of the array\n#        is returned in $v0.\n#      returns: $v0 contains the previous last item which was removed from the\n#               array.\n\n.data\nmyArray:\t.word\t0,5,3,7,3,1,2,9,4,5\nmyArraySize:\t.word\t10\n\n.text\n.globl main\nmain:\n\t\n\t# We will begin our loop\n\t\n\t# It will be a for-loop style\n\t\n\t# We need a counter register\n\t# So, we'll use $t0\n\tli\tt0, 1\t\t\t\t# t0 = 1;\n_mainLoop:\n\n\t# Now we need an invariant expression\n\t# This tells us when to *not* loop\n\t# So, in assembly, we write the opposite\n\t# expression we would in Java, etc.\n\tlw\tt1, myArraySize\n\tbge\tt0, t1, _mainLoopExit\t\t# while(t0 < myArraySize) {\n\t\n\t# Determine the address of the current\n\t# item: A + (i*b)\n\n\t# Get the address of our array (A)\n\tla\tt1, myArray\t\t\t# \tt1 = &myArray[0];\n\t\n\t# Get the offset by multiplying the\n\t# index by the element size (i * b)\n\t# b is 4 because the array holds words\n\tmul\tt2, t0, 4\t\t\t# \tt2 = t0 * 4;\n\t\n\t# Now, do the A + (i*b) part.\n\t# Note: t1 is currently A\n\t#       t2 is currently i * b\n\tadd\tt1, t1, t2\t\t\t#\tt1 = t1 + t2;\n\t\n\t# Now we need the address of the\n\t# previous item. Here's a simple\n\t# trick... that is the address\n\t# we computed minus...?\t\t\t#\tt2 = t1 - 4;\n\tsub\tt2, t1, 4\n\t\n\t# Now t1 is the address of myArray[i]\n\t# and t2 is the address of myArray[i-1]\n\t\n\tlw\tt3, (t1)\t\t\t# \tt3 = *t1; (aka t3 = myArray[i])\n\tsw\tt3, (t2)\t\t\t#\t*t2 = t3; (aka myArray[i-1] = myArray[i])\n\t\n\t# Don't forget the increment!!!\n\tadd\tt0, t0, 1\t\t\t#\tt0++;\n\t\n\tj\t_mainLoop\t\t\t# }  (the end of our loop)\n_mainLoopExit:\n\n\t# Now, assign myArray[9]\n\tli\tt0, 9\n\tla\tt1, myArray\n\tmul\tt2, t0, 4\n\tadd\tt1, t1, t2\t\t\t# t1 = &myArray[9];\n\t\n\t# When this construction makes more\n\t# sense, we can shorten our pseudo-code\n\t# comments to what we have there...\n\t#   just the t1 = &myArray[i], etc\n\t\n\tli\tt0, 42\n\tsw\tt0, (t1)\t\t\t# myArray[9] = 42;\n\n_mainExit:\n\t# exit\n\tli\tv0, 10\n\tsyscall\t\t\t\t# syscall(EXIT)"
        },
        {
            "lecture": 7,
            "content": "Putting numbers into registers\n\u25cf COPYing register contents\n\u25cf COPYing from/to memory\n2\nli a0, 3\nmove a0, t0\nlw/sw, lh/lhu/sh, lb/lbu/sb\nlw t0, x sw t0, x\nla t1, x\nlw t0, 0(t1)\nla t1, x\nsw t0, 0(t1)\nla a0, x\n.data\nx: .word 4\nlabel\nDo the\nsame thing\nUnsigned! These do zero\nextension \u00e8\nIn another perspective\nOther operations\nadd\nsub\nmul\nsyscall\n\u2026 3\nCPU\nRegisters\nMemory\nlw, lh, lhu, lb, lbu\nsw, sh, sb\nmove\nli, la Datatypes\nword\nhalf\nbyte\nasciiz\n\u2026\nWe\u2019ve learned how to use a calculator!\nIntroduction to conditions\n\u25cf What distinguishes a computer from a calculator?\n\u25cf It can make decisions based on values that it calculates\no If the value of this register is this, do something.\no Otherwise, do something else.\n\u25cf The possible decisions make up the potential control flow of the program.\no When there is no possible route to a piece of code in your program, that is\ncalled dead code.\n\u00a7 It\u2019s like procrastination!\n4\nif(false) {\n do_some_work()\n}\nControl flow\n5\nWith great power\u2026\n\u25cf Control flow determines the order that your instructions run in\no What kinds of control flow statements do you know of?\no What about functions?\n\u25cf In asm, the only thing you get for free is that instructions run in order\n\u25cf You're responsible for coming up with everything else.\no If you screw up your control flow, the CPU doesn't care\no You'll just have a broken, malfunctioning program\n\u00a7 And it'll be half an hour before the lab is due\n\u2013 And you'll be sad\n\u00bb This is like 90% of the bugs\n6\nGetting a little further from familiarity\n\u25cf all control flow is done with branches and jumps\no these are instructions which say \"go somewhere else\"\n\u25cf for example\u2026\n_main_loop:\n# clear screen\n# draw one thing\n# sleep\n# draw another thing\n# etc\nj _main_loop\n7\nthis is an infinite loop,\nwhich is sometimes useful\nbut not too interesting\nj stands for \u201djump\" \u2013 go\nsomewhere else\nBuilding blocks\n\u25cf A basic block is a chunk of code that has no control flow in it\n\u25cf Control flow statements separate basic blocks\n8\nif(x == w - 1) {\n do_thing\n} else {\n other_thing\n}\nthird_thing\nother_thing do_thing\nx == w - 1?\nthird_thing\nthinking about this is REAL HELPFUL\nEssentially\u2026\n\u25cf The way control flow works in asm is you make basic blocks\no You gotta name (label) them\n\u25cf Then, you use special instructions to choose where to go\no Ask yourself \u201cWhich basic block runs next?\"\no Select the instruction you need!\n\u00a7 Don\u2019t worry, we look into these instructions in a moment\n\u25cf And don\u2019t forget!\no Write pseudo-code (with comments) to keep track of control flow\no Or make a drawing of a flow-chart!\no Or \u2026 any other guide you think it\u2019s helpful\n9\nConditionals: if and if-else\n10\nMIPS ISA: conditional branch instructions\n\u25cf conditional branch instructions do one of two things:\no if the condition is met, we go to the label\no otherwise, nothing happens, and we go to the next instruction\n11\nInstruction Meaning\nbeq a, b, label if(a == b) { goto label }\nbne a, b, label if(a != b) { goto label }\nabove, a must be a register, but b can be a register or immediate\n(by the powers of the pseudo-instruction)\nHow do these work?\n12\nNext\ninstruction\nOther\ninstruction\nt0==t1\nlabel:\nPrevious\ninstruction\nThis is the branch\nFalse\nTrue\nbeq t0, t1, label\n# branch if equal\nHow do these work?\n13\nbeq t0, t1, label\n# branch if equal\nNext\ninstruction\nOther\ninstruction\nt0==t1\nlabel:\nPrevious\ninstruction\nThis is the branch\nFalse\nTrue\nHow to write asm (again!)\n\u25cf Remember:\n14\nif(x == w - 1) {\n do_thing()\n} else {\n other_thing()\n}\nIGNORE THE STUFF INSIDE\nTRANSLATE THE CONTROL FLOW\nTO ASM FIRST!!!!!!\nWRITE PSEUDOCODE ALWAYS REALLY!!!\nLike mad libs, but for code\n\u25cf From now on, I\u2019ll use these 'blocks' to represent the basic blocks\no cause they don\u2019t matter\n15\nif(some condition) {\n} else {\n}\nblock A\nblock B\nblock C\nA simple conditional block (if)\n\u25cf If there is no else, it's pretty simple.\n16\nif(s0 == 30) {\n}\nblock A\nblock B\nbne s0, 30, _blockB\nO.o\n_blockA:\nIsn\u2019t that Branch NOT\n_blockB Wait, what???? :\nequal?\nA simple conditional block (if)\n\u25cf If there is no else, it's pretty simple.\n17\nif(s0 == 30) {\n}\nblock A\nblock B\nbne s0, 30, _blockB\nIn Java/C what happens in an if? You JUMP OVER when the condition is true or\nfalse?\nWhen its FALSE!!\nA simple conditional block (if)\n\u25cfIn MIPS you jump when the condition is TRUE\n18\nif(s0 == 30) {\n}\nblock A\nblock B\ncoming up with unique\nnames for all the control flow\nlabels is kind of a chore\n_blockA:\n_blockB:\nblock A\nblock B\nbne s0, 30, _blockB\nAn if-else with a simple condition\n\u25cf more blocks now\u2026\n19\nif(s0 == 30) {\n}\nelse {\n}\nblock A\nblock B\nblock C\n_blockB:\n_blockC:\nblock A\nblock B\nblock C\nbne s0, 30, _blockB\nj _blockC\nwe NEED THIS \u2013 the CPU doesn't\nsee/care about your labels!!\nThe other way around\n\u25cf Because in HLL we \u201cexecute smth if\u201d and In assembly we \u201cjump over if\u201d\n\u25cf We usually negate the condition in the assembly to skip over code\no It\u2019s a preference.\no You can still invert the process\n\u00a7 How?\n20\nif(s0 == 30) {\n}\nelse {\n}\nblock A\nblock B\nblock C\n j _blockExit # skip the else\n_blockElse:\n_blockExit:\nblock A\nblock B\nblock C\nbeq s0, 30, _blockA\n j _blockElse\n_blockA:\nMIPS ISA: conditional branch instructions\n\u25cf MIPS also supports instructions that compare to zero\n21\nInstruction Meaning\nbltz a, label if(a < 0) { goto label }\nblez a, label if(a <= 0) { goto label }\nbgtz a, label if(a > 0) { goto label }\nbgez a, label if(a >= 0) { goto label }\nMIPS ISA: set if less than\n\u25cf And\u2026\n22\nInstruction Meaning\nslt c, a, b if(a < b) { c = 1 } else { c = 0 }\nSet if Less Than: register c will be set to 1 if a<b.\nOtherwise, register c will be set to 0.\nUsing slt together with bne and beq all conditionals can be implemented!\na=b , a\u2260b, a>b, a\u2265b, a<b, a\u2264b\nThanks, De Morgan\nMIPS ISA: conditional branch instructions\n\u25cf Or\u2026 we can just use the pseudo-instructions :D\n23\nInstruction Meaning\nblt a, b, label if(a < b) { goto label }\nble a, b, label if(a <= b) { goto label }\nbgt a, b, label if(a > b) { goto label }\nbge a, b, label if(a >= b) { goto label }\nabove, a must be a register, but b can be a register or immediate\nExamples\n24\nslt t, b, a\nbne t, zero, label\nbgt a, b, label\nExample 1: branch if a>b\nslt t, a, b\nbeq t, zero, label\nbge a, b, label\nExample 2: branch if a\u2265b\nSolution: branch if b<a\nSolution: branch if !(a<b)\n# Goto label if a>b\n# t=1 if b<a\n# Goto label if t\u22600\n# Goto label if a\u2265b\n# t=1 if a<b\n# Goto label if t=0\nComplex conditionals\n25\nIn this code\u2026\nif(dog_size < 10 || dog_name() == \"Fluffy\")\n26\nif dog_size is 3, is dog_name() called?\nNO!\nthis is short circuit evaluation.\nfor || (logical OR), if the first condition is true, the\nsecond one is skipped. (cause there's no way for\nthe result of the OR to be false.)\nfor && (logical AND), if the first condition is\nfalse, the second one is skipped.\nIn this code\u2026\nif(dog_size < 10)\nsmall();\nelse if(dog_size < 20)\nmedium();\nelse if(dog_size < 30)\nlarge();\nelse\nenormous();\n27\nif dog_size is 3, is this\ncondition checked?\nNO!\nonce a true condition is found, no\nmore conditions are checked.\nafter small(), it comes down here.\nAnd-and!\n\u25cf Block A is run if both conditions are true.\no to think of it another way\u2026 it's skipped if? What\u2019s the inverse?\no either condition is false\u2026\n28\nif(s0 == 30 &&\n s1 > 1) {\n}\nblock A\nbne s0, 30, _skipA\nble s1, 1, _skipA\n_skipA:\nblock A\nOr-or!\n\u25cf We go to block A if either condition is true.\no to think of it another way\u2026 it's skipped if? What\u2019s the inverse?\no all conditions are false.\n29\nif(s0 == 30 ||\n s1 > 1)\n{\n}\nblock A\nbeq s0, 30, _blockA\nble s1, 1, _skipA\n_blockA:\n_skipA:\nblock A\nLooooops\n30\noooo\nooooo\no\nDis-assembling a for-loop\n\u25cf How does a for loop work?\n31\nfor(i=0; i<10; i++)\n{\n}\n// carry on\nAnd???\nThen\u2026\nFinally?\nWhat is the first thing a for does?\nInitialize: i=0\nCheck condition:\nGo back up to the top\nexecute while i<10\nIncrement: i++\nblock A\nblock A\nLooping in MIPS assembly\n\u25cf Let\u2019s use s0 to hold i\n32\n__________________ which conditional branch?\n_carry_on:\nHow do\nwe go up?\nLet\u2019s start with a\nrecipe\n_______________\n_loop_top:\n# carry on\nWhat\u2019s the first\nthing a for\ndoes?\n__________ li s0, 0\nfor(i=0; i<10; i++)\n{\n}\n// carry on\n____________\naddi s0, s0, 1\nHow do we\nincrement?\nj _loop_top\nblock A block A\nThat\u2019s bge, actually\n\u25cf In HLL we \u201cexecute smth if\u201d\n\u25cf In assembly we \u201cjump over if\u201d\n\u25cf Thus negate the condition in\nthe assembly to skip over\ncode\n33\n_____________________\nWe want to leave the loop\u2026\nwhen the opposite of i<10\nhappens!\nmove a0, ___\n_carry_on:\n_______________\n_loop_top:\nli v0, 1\nsyscall\ns0\n# carry on\n__________\nbge s0, 10, _carry_on\n____________\naddi s0, s0, 1\nj _loop_top\nli s0, 0\nThe other way around\n34\nmove a0, ___\n_carry_on:\n_______________\n_loop_top:\nli v0, 1\nsyscall\ns0\n# carry on\n__________\nblt s0, 10, _loop_code\n____________\naddi s0, s0, 1\nj _loop_top\nli s0, 0\n_loop_code:\nb _carry_on\nWhile looks the same, no initialization or increment\n35\nwhile(s2 < 10)\n{\n // stuff!!\n}\n// more stuff\nbge s2, 10,____________\n_stuff:\n# stuff!!\n_more_stuff:\n# more stuff\n_more_stuff\nj _loop_top\n_loop_top:\nThe whole story\n\u25cf Remember continue?\n\u25cf Remember break?\n36\n_____________________\nmove a0, ___\n_loop_break:\n_______________\n_loop_top:\nli v0, 1\nsyscall\ns0\n# carry on\n__________\nbge s0, 10, _loop_break\n____________\naddi s0, s0, 1\nj _loop_top\nli s0, 0\n_loop_continue:\n\n# This is a demonstration of loops over strings.\n#\n# We will take a string, and replace the spaces with some\n# other character. We will do this \"in place\" which means\n# we will alter the string directly in memory (not copy it\n# to a new string)\n\n# This is the C/Java style equivalent code\n# void main(void) {\n#   char str[] = \"Hello CS 447!\\n\";\n#   print_string(str);                   // syscall\n#   char *str_addr = &str[0];            // the address of the string in memory\n#   while(true) {\n#     char value = *str_addr;            // value in memory at the address str_addr\n#     if (value == '\\0') { break; }      //exit the while loop\n#     if (value == ' ') {\n#       value = '+';\n#   \t*str_addr = value;             // set current character to a '+'\n#     }\n#     str_addr = str_addr + 1;           // increment the address... t0 looks at the next character\n#   }\n#   print_string(str);                   // syscall(PRINT_STRING, str)\n#   return;                              // syscall\n# }\n\n\n# Explore:\n#   1. Change the character that gets replaced.\n#   2. Add the ability to input your own string.\n#      (look up the system call you might need in the MARS Help)\n#   3. Add the ability to select what character gets replaced.\n#   4. Add the stringReplace function so you can reuse this\n#      code elsewhere! Consider: What arguments should it take?\n\n.data\n\t# This is a string.\n\t# The 'asciiz' means the string ends with a null character\n\t# The null character is represented as '\\0'\n\tstr:\t.asciiz\t\t\"Hello CS 477!\\n\"\n\n.text\n.globl main\nmain:\n\n\tla\ta0, str\n\tli\tv0, 4\n\tsyscall\t\t\t\t\t# syscall(PRINT_STRING, str)\n\n\tla\tt0, str\t\t\t\t# t0 = &str[0] (the address of the string in memory)\n\n_main_loop:\t\t\t\t\t# loop {\n\t# Main loop implementation\n\tlbu\tt1, (t0)\t\t\t# \tt1 = *t0; (value in memory at the address in t0)\n\tbeq\tt1, '\\0', _main_loopExit \t#\tif (t1 == '\\0') { break; }\n\n\t# Condition (note the negation!)\n\tbne\tt1, ' ', _main_ifSkip\t\t#\tif (t1 == ' ') {\n\t# If implementation\n\tli\tt1, '+'\t\t\t\t#\t\tt1 = '+';\n\tsb\tt1, (t0)\t\t\t#\t\t*t0 = t1;\t(set current character to a '+')\n\t# End of if implementation\n_main_ifSkip:\t\t\t\t\t#\t}\n\t\tadd\tt0, t0, 1\t\t# \tt0 = t0 + 1; (increment the address... t0 looks at the next character)\n\t# End of main loop implementation\n\tb\t_main_loop\t\t\t# }\n_main_loopExit:\n\n\t# Print the string again\n\t# (notice, it is the SAME string!)\n\tla\ta0, str\n\tli\tv0, 4\n\tsyscall\t\t\t\t\t# syscall(PRINT_STRING, str)\n\n\tli\tv0, 10\t\t\t\t# syscall(EXIT)\n\tsyscall"
        },
        {
            "lecture": 9,
            "content": "Logical, right?\n\u25cf What is the output?\n3\nclass Main {\npublic static void main(String[] args) {\nint a = 4;\nint b = 1;\nSystem.out.println( a|b );\n}\n}\nclass Main {\npublic static void main(String[] args) {\nboolean a = true;\nboolean b = true;\nSystem.out.println(a||b);\n}\n}\ntrue\n\u25cf What is the output?\n5\nWhat are \"bitwise\" operations?\n\u25cf The \"numbers\" we use on computers aren't really numbers right?\n\u25cf It's often useful to treat them instead as a pattern of bits\n\u25cf Bitwise operations treat a value as a pattern of bits\n4\n01 0 0 0\nThe simplest operation: NOT (logical negation)\n\u25cf If the light is off, turn it on\n\u25cf If the light is on, turn it off\n\u25cf We can summarize this in a truth table\n\u25cf We write NOT as ~A, or \u00acA, or A!\n5\nA Q\n0 1\n1 0\nApplying NOT to a whole bunch of bits\n\u25cf if we use the not instruction (or ~ in C/Java), this is what happens:\n6\n~ 0 0 1 1 1 0 1 0\n= 1 1 0 0 0 1 0 1\nwe did 8 independent NOT operations\nthat's it it's super simple\nonly 8 bits shown cause 32 bits on a slide is too much\nLet's add some switches\n\u25cf There are two switches in a row connecting the light to the battery.\n\u25cf How do we make it light up?\n7\nAND (Logical product)\n\u25cf AND is a binary (two-operand) operation.\n\u25cf It can be written a number of ways:\nA&B A\u2227B A\u22c5B AB\n\u25cf If we use the and instruction (& in C):\n8\nA B Q\n0 0 0\n0 1 0\n1 0 0\n1 1 1\n& 0 0 1 1 1 0 1 0\n= 0 0 1 1 0 0 0 0\n1 1 1 1 0 0 0 0\nwe did 8 independent AND operations\nAND (Logical product)\n\u25cf AND is a binary (two-operand) operation.\n\u25cf It can be written a number of ways:\nA&B A\u2227B A\u22c5B AB\n\u25cf If we use the and instruction (& in C):\n9\nA B Q\n0 0 0\n0 1 0\n1 0 0\n1 1 1\n& 0 0 1 1 1 0 1 0\n= 0 0 1 1 0 0 0 0\n1 1 1 1 0 0 0 0\nwe did 8 independent AND operations\nx&0 = 0 \u00e8 Forces zero\nx&1 = x \u00e8 Remains unchanged\nGreat to reset bits:\ni.e., make them zero.\nWhy?\n\"Switching\" things up\n\u25cf NOW how can we make it light up?\n10\nOR (Logical sum\u2026?)\n\u25cf we might say \"and/or\" in English\n\u25cf it can be written a number of ways:\no A|B A\u2228B A+B\n\u25cf if we use the or instruction (or | in C/Java):\n11\nA B Q\n0 0 0\n0 1 1\n1 0 1\n1 1 1\n| 0 0 1 1 1 0 1 0\n= 1 1 1 1 1 0 1 0\n1 1 1 1 0 0 0 0\nWe did 8 independent OR operations.\nOR (Logical sum\u2026?)\n\u25cf we might say \"and/or\" in English\n\u25cf it can be written a number of ways:\no A|B A\u2228B A+B\n\u25cf if we use the or instruction (or | in C/Java):\n12\nA B Q\n0 0 0\n0 1 1\n1 0 1\n1 1 1\n| 0 0 1 1 1 0 1 0\n= 1 1 1 1 1 0 1 0\n1 1 1 1 0 0 0 0\nWe did 8 independent OR operations.\nx|1 = 1 \u00e8 Forces one\nx|0 = x \u00e8 Remains unchanged\nGreat to set bits:\ni.e., make them one.\nWhy?\n3-way switching\n\u25cf NOW how\ncan we make\nit light up?\n13\noff\noff\noff\non off\non\non\non\nXOR (\u201cLogical\u201d difference?)\n\u25cf We might say \"or\" in English.\n\u25cf It can be written a number of ways:\nA^B A\u2295B\n\u25cf If we use the xor instruction (^ in C):\n14\nA B Q\n0 0 0\n0 1 1\n1 0 1\n1 1 0\n^ 0 0 1 1 1 0 1 0\n= 1 1 0 0 1 0 1 0\n1 1 1 1 0 0 0 0\nWe did 8 independent XOR operations.\nXOR (\u201cLogical\u201d difference?)\n\u25cf We might say \"or\" in English.\n\u25cf It can be written a number of ways:\nA^B A\u2295B\n\u25cf If we use the xor instruction (^ in C):\n15\nA B Q\n0 0 0\n0 1 1\n1 0 1\n1 1 0\n^ 0 0 1 1 1 0 1 0\n= 1 1 0 0 1 0 1 0\n1 1 1 1 0 0 0 0\nWe did 8 independent XOR operations.\n1^0 = 0^1 = 1 \u00e8 Is different\n1^1 = 0^0 = 0 \u00e8 Is not different\nGreat to capture the different\nbits:\nWhy?\nXOR (\u201cLogical\u201d difference?)\n\u25cf We might say \"or\" in English.\n\u25cf It can be written a number of ways:\nA^B A\u2295B\n\u25cf If we use the xor instruction (^ in C):\n16\nA B Q\n0 0 0\n0 1 1\n1 0 1\n1 1 0\n^ 0 0 1 1 1 0 1 0\n= 1 1 0 0 1 0 1 0\n1 1 1 1 0 0 0 0\nWe did 8 independent XOR operations.\nx^0 = x \u00e8 Doesn\u2019t change\nx^1 = ~x \u00e8 Flip!\nGreat to flip bits:\nWhy?\nlui, ori\u2026\n\u25cf If I write li t0, 0xDEADBEEF in MIPS, the assembler turns it into:\nlui at, 0xDEAD\nori t0, at, 0xBEEF\n\u25cf at is used by the assembler, sooooo\u2026\n\u25cf The reason it splits it up is that there's only enough space in each\ninstruction to fit half of 0xDEADBEEF\no As we\u2019ve seen in the lab, each immediate is 16 bits long\no We'll learn about instruction encoding later\n\u25cf What the heck are these instructions doing tho\n17\nNever use at!!\nNEVER!!\nBy your powers combined\u2026\n\u25cf lui means load upper immediate. it puts the immediate value into the\nupper 16 bits of the register, and zeroes out the rest\nlui at, 0xDEAD\n\u25cf then, ori does logical OR of at and its zero-extended immediate\nori t0, at, 0xBEEF\n18\n1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1\n1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1\n0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n| 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1\nD E A D B E E F\nBit shifting\n19\nBit shifting\n\u25cf besides AND, OR, and NOT, we can move bits around, too.\n20\n1 1 0 0 1 1 1 1\n1 1 0 0 1 1 1 1 0\n1 1 0 0 1 1 1 1 0 0\n1 1 0 0 1 1 1 1 0 0 0\n1 1 0 0 1 1 1 1 0 0 0 0\nif we shift these\nbits left by 1\u2026\nwe stick a 0 at the bottom\nagain!\nAGAIN!\nAGAIN!!!!\nLeft-shifting in C/Java and MIPS (animated)\n\u25cf C and Java use the << operator for left shift\nB = A << 4; // B = A shifted left 4 bits\n\u25cf MIPS has the sll (Shift Left Logical) instruction\nsll t2, t0, 4 # t2 = t0 << 4\n\u25cf MIPS has the sllv (Shift Left Logical Variable) instruction\no No, registers are not variables!\nsllv t2, t0, t1 # t2 = t0 << t1\n\u25cf if the bottom 4 bits of the result are now 0s\u2026 o \u2026what happened to the top 4 bits?\n21\n0011 0000 0000 1111 1100 1101 1100 1111\nBit\nBucket\nthe bit bucket is not a real place\nit's a programmer joke ok\n<_< >_> <_<\n\u25cf we can shift right, too\n22\n0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1\n0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1\n0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1\n0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1\n0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0\n\u25cf C/Java use >>, MIPS uses srl (Shift Right Logical)\nNumbers they are a-changing\n\u25cf let's start with a value like 5 and shift left and see what happens\n23\nBinary Decimal\n101 5\n1010 10\n10100 20\n101000 40\n1010000 80\nwhy is this happening\nwell uh... what if I gave you\n49018853\nhow do you multiply that by 10?\nby 100?\nby 100000?\nsomething very similar is\nhappening here\na << n == a * 2n\n\u25cf shifting left by n is the same as multiplying by 2n\no you probably learned this as \"moving the decimal point\"\n\u00a7 and moving the decimal point right is like shifting the digits left\n\u25cf shifting is fast and easy on most CPUs\no way faster than multiplication in any case\n\u25cf hey\u2026 if shifting left is the same as multiplying\u2026\n24\na >> n == a / 2n\n, ish\n\u25cf You got it\n\u25cf Shifting right by n is like dividing by 2n\no sort of.\n\u25cf What\u2019s 510 (01012) shifted right by 1?\no 102, which is 2\u2026\n\u00a7 It's like doing integer (or flooring) division\n\u00a7 Which is a fancy way of saying we round to the smallest number\n\u25cf What if the number is signed?\n\u25cf What\u2019s -310 (11012) shifted right by 1?\no 01102, which is 610???\n\u00a7 Ohhhhh\n25\nShift Right (Arithmetic)\n\u25cf We can shift right with sign-extension, too\n26\n1 1 1 0 0 1 1 1 1\nif we shift these bits\nright by 1\u2026\nwe copy the 1 at the top (or\n0, if MSB was a 0)\n1 1 0 0 1 1 1 1\n0 0 1 0 0 1 1 1 1\n0 0 0 1 0 0 1 1 1\n0 1 0 0 1 1 1 1\nShift Right (Arithmetic)\n\u25cf We can shift right with sign-extension, too\n27\n1 1 1 0 0 1 1 1 1\n1 1 1 1 0 0 1 1 1\nif we shift these bits\nright by 1\u2026\nwe copy the 1 at the top (or\n0, if MSB was a 0)\nagain!\nAGAIN!\nAGAIN!!!!!! (It\u2019s still\nnegative!)\n1 1 0 0 1 1 1 1\n1 1 1 1 1 0 0 1 1\n1 1 1 1 1 1 0 0 1\n<_< >_> <_<\n\u25cf This is how it looks with a negative number\n28\n1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1\n1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1\n1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1\n1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1\n1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0\n\u25cf MIPS uses sra (Shift Right Arithmetic)\n\u25cf What\u2019s -310 (11012) shifted right by 1?\no 11102, which is -210\n\u00a7 Why is this -2????? \nMIPS ISA: Bitwise operations\n\u25cf Bitwise logical operators\n29\nInstruction Meaning\nnot a, b a = ~b\nor a, b, c a = b|c\nori a, b, imm a = b|imm\nand a, b, c a = b&c\nandi a, b, imm a = b&imm\nMIPS ISA: Bitwise shifts\n\u25cf Bitwise logical operators\n30\nInstruction Meaning\nsll a, b, imm a = b<<imm\nsllv a, b, c a = b<<c\nsrl a, b, imm a = b>>imm (zero extension)\nsrlv a, b, c a = b>>c (zero extension)\nsra a, b, imm a = b>>imm (sign extension)\nsrav a, b, c a = b>>c (sign extension)\nBitfields\n31\nclicky clicky\n\u25cf In the LED Keypad plugin in MARS, input works like this (lab 7):\n32\n0 0 0 0 0 0 0 0 0 0 0 0\ninput_get_keys returns a value in v0\u2026\nB R L D U\nWhy do we do this??\n\u25cf It lets us cram several booleans into a single value!\n\u25cf This technique is known as bit flags\n33\n1 0 1 0 0 0 1 0 1 0\nB R L D U B R L D U\nThe masters of meaning\n\u25cf well what if we wanted to store multiple integers in one value?\n34\n15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0\n1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 1\nred green blue\ndecimal? 23 32 19\nThat's this color, in RGB565.\nThe masters of meaning\n\u25cf This bitfield has 3 fields: red, green, and blue\n35\n15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0\n1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 1\nred green blue\nPosition 11 Position 5 Position 0\nWhyyyyy???\n\u25cf It's smaller\no really, that's it\no but that's super important in a lot of cases\n\u25cf Smaller data\u2026\no Takes up less space in memory\no Takes up less space in cache\n\u00a7 extremely important thing in modern CPUs that we talk about in 1541\no Is faster to move between memory and the CPU\no Is faster to transfer across the internet and other networks\no It allows a MIPS instruction to contain references to multiple registers\n36\nI wanna turn the light on!!\n\u25cf I have a sequence of 0s. I wanna turn one of them into a 1.\n\u25cf what bitwise operation can I use to do that?\n37\n0 0 0 0\n1\n1 0 0 0\n0 0 0\n?\nI wanna turn the light off!!\n\u25cf I wanna turn one of the 1s into a 0.\n\u25cf what bitwise operation can I use to do that?\n38\n1 0 1 1\n1\n1 1 0 1\n0 0 1\n?\n0 0\nTurning off the first three, leaving the others alone\n\u25cf more bits, but one of the same operations\u2026\n39\n1 0 1 1\n0\n0 1 1 1\n0 1 1\n?\n1 0\n0 0\nRemember this?\nlui at, 0xDEAD\nori t0, at, 0xBEEF\n40\n1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1\n1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1\n0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n| 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1\nD E A D B E E F\nHow can we assemble on of these bitfields?\n41\n15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0\nred green blue\n1 0 1 1 1 1 0 1 1 1\n1 0 0 0 0 0\n1 0 0 0 0 0\n1 0 0 1 1\n\u2026\n\u25cf hmm\n42\n1 0 1 1 1\n1 0 0 0 0 0\n1 0 0 1 1\n0 0 0 0 0 0 0 0 0 0 0\n0 0 0 0 0 0 0 0 0 0\n0 0 0 0 0 0 0 0 0 0 0\n1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 1\nLeft-shifting and ORing\n\u25cf if you have the values of the fields\n\u25cf and you want to put them together into a bitfield\no shift each value left to the correct bit position\no OR the shifted values together\n\u25cf for RGB565,\no red is shifted left 11\no green is shifted left 5\no blue isn't shifted (shifted left 0\u2026)\ncolor = (red << 11) | (green << 5) | blue;\n43\nGoing the other way\n\u25cf let's go from the bitfield to three separate values.\n44\n15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0\n1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 1\n1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0\nlet's say we somehow set all the non-red bits to 0.\nwhat value is this?\nit's not 23, that's for sure.\nso how do we fix that?\nIt's the exact opposite\n\u25cf we have to shift right to put the field at position 0\n45\n15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0\n1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 1\n0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1\n0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0\nshift right by 11 and\u2026\ncool. what about green? shift right by\u2026?\nuh oh.\nMasquerade\n\u25cf we need to get rid of (zero out) the bits that we don't care about\n\u25cf a mask is a specially-constructed value that has:\no 1s in the bits that we want to keep\no 0s in the bits that we want to discard\n\u25cf which bits do we want to keep? which do we want to discard?\n46\n0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0\n0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n&\nthis is the mask\nComing up with the mask value\n\u25cf if you want to mask a 3 bit value, the mask is 1112\n\u25cf if you want to mask a 4 bit value, the mask is 11112\n\u25cf if you want to mask a 5 bit value, it's\u2026?\n47\nSize(n) Mask 2n\nMask in\ndecimal\n7\n15\n31\n1112\n11112\n111112\n8\n16\n32\n3\n4\n5\n2n-1\nRight-shifting and ANDing\n\u25cf to extract one or more fields from a bitfield:\no shift the bitfield right to put the desired field at bit position 0\no AND that with 2n-1, where n is the number of bits in the field\n\u25cf so for RGB565\u2026\no the red and blue masks are 25-1 = 31 (or 0x1F)\no the green mask is 26-1 = 63 (or 0x3F)\nred = (color >> 11) & 0x1F;\ngreen = (color >> 5) & 0x3F;\nblue = color & 0x1F;\n48\nNOW it works\n\u25cf let's extract green\n49\n15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0\n1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 1\n0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0\nshift right by 5 and\u2026\nand then AND with 0x3F\u2026\n0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\nCan't you AND then shift?\n\u25cf sure, but\u2026\n50\n15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0\n1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 1\nAND with 0x7E0 (!)\u2026\n0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\nshift right by 5\u2026\n0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\nwhere did I get 0x7E0??\nit's 0x3F << 5. I feel like that's uglier.\nExperience shows me it leads to more mistakes\nSo don\u2019t do this: Keep the mask aligned to the right!!!\nExercise!\n\u25cf This bitfield represents the following MIPS instruction:\naddi s0, zero, 0x1234\n\u25cf Using these operations: <<, >>, &, |, ~ write expressions to extract the value\nof each field\no E.g.: ( instruction << 3 )|( ~0xFFFF )\n\n.data\n\n# LED colors (don't change)\n.eqv COLOR_OFF\t\t0\n.eqv COLOR_BLACK\t0\n.eqv COLOR_RED         1\n.eqv COLOR_ORANGE      2\n.eqv COLOR_YELLOW      3\n.eqv COLOR_GREEN       4\n.eqv COLOR_BLUE        5\n.eqv COLOR_MAGENTA     6\n.eqv COLOR_WHITE       7\n.eqv COLOR_DARK_GREY   8\n.eqv COLOR_DARK_GRAY   8\n.eqv COLOR_BRICK       9\n.eqv COLOR_BROWN       10\n.eqv COLOR_TAN         11\n.eqv COLOR_DARK_GREEN  12\n.eqv COLOR_DARK_BLUE   13\n.eqv COLOR_PURPLE      14\n.eqv COLOR_LIGHT_GREY  15\n.eqv COLOR_LIGHT_GRAY  15\n\n# Board size (don't change)\n.eqv\tLED_SIZE\t2\n.eqv\tLED_WIDTH\t32\n.eqv\tLED_HEIGHT\t32\n\n# System Calls\n.eqv\tSYS_PRINT_INTEGER\t1\n.eqv\tSYS_PRINT_STRING\t4\n.eqv\tSYS_PRINT_CHARACTER\t11\n.eqv\tSYS_SYSTEM_TIME\t\t30\n\n# Key states\nleftPressed:\t\t.word\t0\nrightPressed:\t\t.word\t0\nupPressed:\t\t.word\t0\ndownPressed:\t\t.word\t0\nzPressed:\t\t.word\t0\nxPressed:\t\t.word\t0\ncPressed:\t\t.word\t0\nbPressed:\t\t.word\t0\n\n# Frame counting\nlastTime:\t\t.word\t0\nframeCounter:\t\t.word\t0\n\n.text\n.globl main\nmain:\t\n\t# Initialize the game state\n\tjal\tinitialize\t\t\t\t# initialize()\n\t\n\t# Run our game!\n\tjal\tgameLoop\t\t\t\t# gameLoop()\n\t\n\t# The game is over.\n\n\t# Exit\n\tli\tv0, 10\n\tsyscall\t\t\t\t\t\t# syscall(EXIT)\n\n# void initialize()\n#   Initializes the game state.\ninitialize:\n\tpush\tra\n\t\n\t# Set lastTime to a reasonable number\n\tjal\tgetSystemTime\n\tsw\tv0, lastTime\n\t\n\t# Clear the screen\n\tli\ta0, 1\n\tjal\tdisplayRedraw\t\t\t\t# displayRedraw(1);\n\t\n\t# Initialize anything else\n\t\n\tpop\tra\n\tjr\tra\n\t\t\t\t\n# void gameLoop()\n#   Infinite loop for the game logic\ngameLoop:\n\tpush\tra\n\ngameLoopStart:\t\t\t\t\t\t# loop {\n\tjal\tgetSystemTime\t\t\t\t#\n\tmove\ts0, v0\t\t\t\t\t# \ts0 = getSystemTime();\n\t\n\tmove\ta0, s0\n\tjal\thandleInput\t\t\t\t# \tv0 = handleInput(elapsed: a0);\n\t\n\t# Determine if a frame passed\n\tlw\tt0, lastTime\n\tsub\tt0, s0, t0\n\tblt\tt0, 50, gameLoopStart\t\t\t# \tif (s0 - lastTime >= 50) {\n\t\n\t# Update last time\n\tsw\ts0, lastTime\t\t\t\t# \t\tlastTime = s0;\n\t\n\t# Update our game state (if a frame elapsed)\n\tmove\ta0, s0\n\tjal\tupdate\t\t\t\t\t# \t\tv0 = update();\n\t\n\t# Exit the game when it tells us to\n\tbeq\tv0, 1, gameLoopExit\t\t\t# \t\tif (v0 == 1) { break; }\n\t\n\t# Redraw (a0 = 0; do not clear the screen!)\n\tli\ta0, 0\n\tjal\tdisplayRedraw\t\t\t\t# \t\tdisplayRedraw(0);\n\t\t\t\t\t\t\t#\t}\n\tj\tgameLoopStart\t\t\t\t# }\n\ngameLoopExit:\n\tpop\tra\n\tjr\tra\t\t\t\t\t# return;\n\t\t\t\n# int getSystemTime()\n#   Returns the number of milliseconds since system booted.\ngetSystemTime:\n\t# Now, get the current time\n\tli\tv0, SYS_SYSTEM_TIME\n\tsyscall\t\t\t\t\t\t# a0 = syscall(GET_SYSTEM_TIME);\n\t\n\tjr\tra\t\t\t\t\t# return v0;\n\t\n# bool update(elapsed)\n#   Updates the game for this frame.\n# returns: v0: 1 when the game should end.\nupdate:\n\tpush\tra\n\tpush\ts0\n\t\n\t# Increment the frame counter\n\tlw\tt0, frameCounter\n\tadd\tt0, t0, 1\n\tsw\tt0, frameCounter\t\t\t# frameCounter++;\n\t\n\tli\ts0, 0\t\t\t\t\t# s0 = 0;\n\t\n\t# Update all of the game state\n\tjal\tupdateStuff\n\tor\ts0, s0, v0\t\t\t\t# s0 = s0 | updateStuff();\n\t\n_updateExit:\n\tmove\tv0, s0\n\t\n\tpop\ts0\n\tpop\tra\n\tjr\tra\t\t\t\t\t# return s0;\n\t\n# void updateStuff()\nupdateStuff:\n\tpush\tra\n\t\n\tli\ta0, 8\n\tli\ta1, 16\n\tli\ta2, COLOR_OFF\n\tjal\tdisplaySetLED\n\t\n\tli\ta0, 16\n\tli\ta1, 24\n\tli\ta2, COLOR_OFF\n\tjal\tdisplaySetLED\n\t\n\tli\ta0, 16\n\tli\ta1, 8\n\tli\ta2, COLOR_OFF\n\tjal\tdisplaySetLED\n\t\n\tli\ta0, 24\n\tli\ta1, 16\n\tli\ta2, COLOR_OFF\n\tjal\tdisplaySetLED\n\t\n\tli\ta0, 14\n\tli\ta1, 16\n\tli\ta2, COLOR_OFF\n\tjal\tdisplaySetLED\n\t\n\tli\ta0, 15\n\tli\ta1, 16\n\tli\ta2, COLOR_OFF\n\tjal\tdisplaySetLED\n\t\n\tli\ta0, 17\n\tli\ta1, 16\n\tli\ta2, COLOR_OFF\n\tjal\tdisplaySetLED\n\t\n\tli\ta0, 18\n\tli\ta1, 16\n\tli\ta2, COLOR_OFF\n\tjal\tdisplaySetLED\n\t\n_updateStuffLeft:\n\tlw\tt0, leftPressed\n\tbeq\tt0, 0, _updateStuffRight\n\t\n\tli\ta0, 8\n\tli\ta1, 16\n\tli\ta2, COLOR_RED\n\tjal\tdisplaySetLED\n\n_updateStuffRight:\n\tlw\tt0, rightPressed\n\tbeq\tt0, 0, _updateStuffUp\n\t\n\tli\ta0, 24\n\tli\ta1, 16\n\tli\ta2, COLOR_GREEN\n\tjal\tdisplaySetLED\n\n_updateStuffUp:\n\tlw\tt0, upPressed\n\tbeq\tt0, 0, _updateStuffDown\n\t\n\tli\ta0, 16\n\tli\ta1, 8\n\tli\ta2, COLOR_YELLOW\n\tjal\tdisplaySetLED\n\n_updateStuffDown:\n\tlw\tt0, downPressed\n\tbeq\tt0, 0, _updateStuffC\n\t\n\tli\ta0, 16\n\tli\ta1, 24\n\tli\ta2, COLOR_MAGENTA\n\tjal\tdisplaySetLED\n\n\n_updateStuffC:\n\tlw\tt0, cPressed\n\tbeq\tt0, 0, _updateStuffX\n\t\n\tli\ta0, 14\n\tli\ta1, 16\n\tli\ta2, COLOR_BROWN\n\tjal\tdisplaySetLED\n\n_updateStuffX:\n\tlw\tt0, xPressed\n\tbeq\tt0, 0, _updateStuffZ\n\t\n\tli\ta0, 15\n\tli\ta1, 16\n\tli\ta2, COLOR_TAN\n\tjal\tdisplaySetLED\n\n_updateStuffZ:\n\tlw\tt0, zPressed\n\tbeq\tt0, 0, _updateStuffB\n\t\n\tli\ta0, 17\n\tli\ta1, 16\n\tli\ta2, COLOR_DARK_BLUE \n\tjal\tdisplaySetLED\n\n\n_updateStuffB:\n\tlw\tt0, bPressed\n\tbeq\tt0, 0, _updateStuffExit\n\t\n\tli\ta0, 18\n\tli\ta1, 16\n\tli\ta2, COLOR_BRICK\n\tjal\tdisplaySetLED\n\t\n_updateStuffExit:\n\n\t# Return 0 so the game loop doesn't exit\n\tli\tv0, 0\n\t\n\tpop\tra\n\tjr\tra\t\t\t\t\t# return 0;\n\t\n# LED Input Handling Function\n# -----------------------------------------------------\n\t\n# bool handleInput(elapsed)\n#   Handles any button input.\n# returns: v0: 1 when the game should end.\nhandleInput:\n\tpush\tra\n\t\n\t# Get the key state memory\n\tli\tt0, 0xffff0004\n\tlw\tt1, (t0)\n\t\n\t# Check for key states\n\tand\tt2, t1, 0x1\n\tsw\tt2, upPressed\n\t\n\tsrl\tt1, t1, 1\n\tand\tt2, t1, 0x1\n\tsw\tt2, downPressed\n\t\n\tsrl\tt1, t1, 1\n\tand\tt2, t1, 0x1\n\tsw\tt2, leftPressed\n\t\n\tsrl\tt1, t1, 1\n\tand\tt2, t1, 0x1\n\tsw\tt2, rightPressed\n\t\n\tsrl\tt1, t1, 1\n\tand\tt2, t1, 0x1\n\tsw\tt2, bPressed\n\t\n\tsrl\tt1, t1, 1\n\tand\tt2, t1, 0x1\n\tsw\tt2, cPressed\n\t\n\tsrl\tt1, t1, 1\n\tand\tt2, t1, 0x1\n\tsw\tt2, xPressed\n\t\n\tsrl\tt1, t1, 1\n\tand\tt2, t1, 0x1\n\tsw\tt2, zPressed\n\t\n\tmove\tv0, t2\n\t\n\tpop\tra\n\tjr\tra\n\t\n# LED Display Functions\n# -----------------------------------------------------\n\t\n# void displayRedraw()\n#   Tells the LED screen to refresh.\n#\n# arguments: $a0: when non-zero, clear the screen\n# trashes:   $t0-$t1\n# returns:   none\ndisplayRedraw:\n\tli\tt0, 0xffff0000\n\tsw\ta0, (t0)\n\tjr\tra\n\n# void displaySetLED(int x, int y, int color)\n#   sets the LED at (x,y) to color\n#   color: 0=off, 1=red, 2=yellow, 3=green\n#\n# arguments: $a0 is x, $a1 is y, $a2 is color\n# returns:   none\n#\ndisplaySetLED:\n\tpush\ts0\n\tpush\ts1\n\tpush\ts2\n\t\n\t# I am trying not to use t registers to avoid\n\t#   the common mistakes students make by mistaking them\n\t#   as saved.\n\t\n\t#   :)\n\n\t# Byte offset into display = y * 16 bytes + (x / 4)\n\tsll\ts0, a1, 6      # y * 64 bytes\n\t\n\t# Take LED size into account\n\tmul\ts0, s0, LED_SIZE\n\tmul\ts1, a0, LED_SIZE\n\t\t\n\t# Add the requested X to the position\n\tadd\ts0, s0, s1\n\t\n\tli\ts1, 0xffff0008 # base address of LED display\n\tadd\ts0, s1, s0    # address of byte with the LED\n\t\n\t# s0 is the memory address of the first pixel\n\t# s1 is the memory address of the last pixel in a row\n\t# s2 is the current Y position\t\n\t\n\tli\ts2, 0\t\n_displaySetLEDYLoop:\n\t# Get last address\n\tadd\ts1, s0, LED_SIZE\n\t\n_displaySetLEDXLoop:\n\t# Set the pixel at this position\n\tsb\ta2, (s0)\n\t\n\t# Go to next pixel\n\tadd\ts0, s0, 1\n\t\n\tbeq\ts0, s1, _displaySetLEDXLoopExit\n\tj\t_displaySetLEDXLoop\n\t\n_displaySetLEDXLoopExit:\n\t# Reset to the beginning of this block\n\tsub\ts0, s0, LED_SIZE\n\t\n\t# Move to next row\n\tadd\ts0, s0, 64\n\t\n\tadd\ts2, s2, 1\n\tbeq\ts2, LED_SIZE, _displaySetLEDYLoopExit\n\t\n\tj _displaySetLEDYLoop\n\t\n_displaySetLEDYLoopExit:\n\t\n\tpop\ts2\n\tpop\ts1\n\tpop\ts0\n\tjr\tra\n\t\n# int displayGetLED(int x, int y)\n#   returns the color value of the LED at position (x,y)\n#\n#  arguments: $a0 holds x, $a1 holds y\n#  returns:   $v0 holds the color value of the LED (0 through 7)\n#\ndisplayGetLED:\n\tpush\ts0\n\tpush\ts1\n\n\t# Byte offset into display = y * 16 bytes + (x / 4)\n\tsll\ts0, a1, 6      # y * 64 bytes\n\t\n\t# Take LED size into account\n\tmul\ts0, s0, LED_SIZE\n\tmul\ts1, a0, LED_SIZE\n\t\t\n\t# Add the requested X to the position\n\tadd\ts0, s0, s1\n\t\n\tli\ts1, 0xffff0008 # base address of LED display\n\tadd\ts0, s1, s0    # address of byte with the LED\n\tlbu\tv0, (s0)\n\t\n\tpop\ts1\n\tpop\ts0\n\tjr\tra"
        },
        {
            "lecture": 8,
            "content": "Calling conventions\n3\nWhat's a calling convention?\n\u25cf It ensures our programs don't trip over their own feet\n\u25cf It's how machine-language functions call one another\no How arguments are passed\no How return values are returned\no How control flows into/out of the function\no What contracts exist between the caller and the callee\n4\nvoid fork() {\n knife();\n}\nvoid knife() {\n ...\n} caller callee\nThe program counter register\n\u25cf A program's instructions are in memory, so they have addresses\n\u25cf The PC (program counter) holds the address of the next instruction to run\no Is incremented by a word! Each instruction is a word\n5\n0x8000 lw t0, (s0)\n0x8004 add t0, t0, 1\n0x8008 sw t0, (s0)\n0x800C add s0, s0, 4\n0x8000\nPC\n0x8010 blt s0, s1, top\ntop:\n0x8004\n0x8008\n0x800C\n0x8010\n0x8000 ? 0x8014\ntime\nbtw what pattern do you notice\nabout these addresses?\nAddress\nMIPS ISA: conditional branch instructions\n\u25cf The conditional branch instructions we\u2019ve seen last class\no Actually interact with pc\n6\nInstruction Meaning\nbeq a, b, label if(a == b) { goto label }\nbne a, b, label if(a != b) { goto label }\nblt a, b, label if(a < b) { goto label }\nble a, b, label if(a <= b) { goto label }\nbgt a, b, label if(a > b) { goto label }\nbge a, b, label if(a >= b) { goto label }\n$pc = label\nThe flow of control\n\u25cf When the caller calls a function, where do we go?\n\u25cf When the callee's code is finished, where do we go?\n7\nvoid fork() {\n knife();\n spoon++;\n}\nvoid knife() {\n spork++;\n spatula--;\n} caller callee\nMIPS ISA: The jump and link instruction\n\u25cf We call functions with jal: jump and link\n8\nvoid main() {\n func();\n}\nmain:\njal func\nlabel\nMIPS ISA: The jump and link instruction\n\u25cf We call functions with jal: jump and link\n9\n0x8000 li a0, 10\n0x8004 jal func\n0x8008 li v0, 10\n... ...\n0x8C30 li v0, 4\n... ...\nfunc:\nPC 0x8004\nWhat address should\ngo into PC next? PC 0x8C30\nWhen func returns,\nwhere will we go? ra 0x8008\nThis is what jal does:\nit jumps to a new location, and\nmakes a link back to the old one\nin the ra (return address) register\nand this is ALL it does.\nMIPS ISA: The jump register instruction\n\u25cf We return from functions with jr: jump to address in register\n10\nvoid func() {\n return;\n}\nfunc:\nlabel\njr ra\nreturn\nvoid main() {\n func();\n}\nmain:\njal func\nlabel\nMIPS ISA: The jump register instruction\n\u25cf We return from functions with jr: jump to address in register\n11\n0x8000 li a0, 10\n0x8004 jal func\n0x8008 li v0, 10\n... ...\n0x8C30 li v0, 4\n0x8C34 syscall\n0x8C38 jr ra\nfunc:\nPC 0x8C38 Now we're at the end\nof func. ra still has the\nproper return address ra 0x8008\njr ra copies ra into pc. PC 0x8008\nand this is ALL it does.\nArguments and\nReturn Values\n12\nIt's pretty simple, remember register names!!\n\u25cf if we have a function in a higher level language\u2026\n13\nint gcd(int a, int b) {\nwhile(a != b) {\nif(a > b)\na -= b;\nelse\nb -= a;\n}\nreturn a;\n}\nwe use particular registers\nto pass arguments and\nreturn values.\nv0 a0 a1\nwe already know how to\nreturn. How do syscalls do it?\nfor this, just put the value you want\nto return in v0 before jr ra.\nThe a and v registers\n\u25cf a0-a3 are the argument registers\n\u25cf v0-v1 are the return value registers\no This is just a convention, there's nothing special about them\n\u00a7 Does that mean I can pass values in (e.g.) s-registers?\n\u2013 Yessssssss\u2026.????\u00ac.\u00ac\n\u00a7 Will I lose any points in midterms/labs/projects if I do?\n\u2013 Yessssssss!!!!\u00ac.\u00ac\n\u25cf By convention! We never do that!\no ALWAYS pass arguments in a-registers\no ALWAYS return arguments in v-registers\n14\nTo call a function\u2026\n\u25cf You put its arguments in the a registers before doing a jal\n\u25cf Once control is inside the callee\u2026\no The arguments are just \"there\" in the a registers.\n\u00a7 Cause they are.\n\u2013 They didn't go anywhere!\n15\n\u25cf Functions should be black boxes for the caller\no You don\u2019t need any information about\nthe implementation\no You only need to know inputs and outputs!\no \u2026 and conventions\nAmazing function that adds two\nnumbers. You do not need to\nknow how it is implemented!!!\nInputs:\n1. Number to add\n2. Number to add\nOutputs:\n1. Numbers added together\nadd_nums\nLet\u2019s call a function!\n\u25cf Let's make main do this:\nv0=add_nums(3, 8)\nprint(v0)\n\u25cf How do we set 3 and 8 as the arguments?\n\u25cf How do we call add_nums?\n\u25cf Afterwards, which register holds the sum?\n\u25cf So how can we print that value?\n\u25cf Why do syscalls put the number of the\nsyscall in v0?\no Well what do you get when you cross a neutron and a rhino?\n\u00a7 Hell if I know \u00af\\_(\u30c4)_/\u00af\n16\nli a0, 3\nli a1, 8\njal add_nums\nmove a0, v0\nli v0, 1\nsyscall Careful!\nIt\u2019s a neutrino\nInput, output\n\u25cf Now, let's write the function:\nint add_nums(int x, int y) {return x + y;}\n\u25cf inside of our add_nums asm function\u2026\no which register represents x?\no which register represents y?\no which register will hold the sum that we return?\nadd_nums:\nadd __, __, __\n17\nv0 a0 a1\njr ra\nMore conventions:\nSaved and Unsaved registers\n18\nLet\u2019s try something\n\u25cf Let's make a variable and a function to change it\n19\n.data\ncounter: .word 0\n.text\nincrement:\nla t0, counter\nlw t1, (t0)\nadd t1, t1, 1\nsw t1, (t0)\njr ra\nmain:\njal increment\njal increment\njal increment\nthen we can call it\nEverything's just fine, right?\n\u25cf let's write a loop that calls it ten times in a row\n\u25cf so we need a loop counter ('i' in a for loop)\n20\nli t0, 0 # our counter\nloop_begin:\njal increment\nadd t0, t0, 1\nblt t0, 10, loop_begin\nloop_end:\n(this is a do-while loop)\nif we run this, it only\nincrements the\nvariable once.\nwhy? let's put a\nbreakpoint on blt\nand see what it sees.\nScribbling on someone else's notes\n\u25cf both functions are trying to use t0 for different purposes\no but there's only ONE t0!\n\u25cf the increment function is in the clear\no the problem is actually the loop\n\u25cf this is one of the contracts between the caller and the callee\u2026\n21\na caller cannot depend on the t, a, or v registers\nto have the same values after a call as before it.\nor to put it another way, callees are\nallowed to trash those registers.\nAnother piece of the calling convention puzzle\n\u25cf When you call a function, it's allowed to change some registers\n\u25cf But other registers must be left exactly as they were\n22\nSaved\ns0-s7\nsp\nra*\nUnsaved\nv0-v1\na0-a3\nt0-t9\nfunctions are\nrequired to put\nthese registers\nback the way they\nwere before they\nwere called.\nanyone can change\nthese. after you call a\nfunction, they might\nhave totally different\nvalues from before\nyou called it.\n*ra is a little weird cause it's kinda \"out of\nsync\" with the other saved regs but you\nDO save and restore it like the others\nWhenever you call a function\u2026\n\u25cf after a jal, you have no idea what's in these registers.\n23\nUnsaved\nv0-v1\na0-a3\nt0-t9\n...\njal increment\n...\ncould be nonsense!\ngarbage! bogus!\nRemember functions are\nblackbox\u2026\nEVEN if YOU implemented it!\nWHAT IS IN t0 NOW??\nt0 is our loop counter and\neverything's fiiiine. li t0, 0\nloop_begin:\njal increment\nadd t0, t0, 1\nblt t0, 10, loop_begin\nloop_end:\nWhy it broke\n\u25cf if we look at this code again\u2026\n24\nuh oh.\ninstead, this is a great place to use an s register.\noh whew, we used an s\nregister, it's fine.\ns0 is our loop counter and\neverything's fiiiine.\nUsing the convention\n\u25cf if we use an s register\u2026\n25\nuh oh.\nbut s registers aren't magic. they don't do this automatically.\nli s0, 0\nloop_begin:\njal increment\nadd s0, s0, 1\nblt s0, 10, loop_begin\nloop_end:\nDon't step on each others' toes\n\u25cf let's track PC and ra as we run this code.\n26\n0x8000 jal fork\n0x8004 li v0, 10\n... ...\n0x8020 jal spoon\n0x8024 jr ra\n... ...\n0x8040 jr ra\nfork:\nspoon:\n0x0000\nra\nAfter jal spoon:\nAfter jal fork: 0x8004\n0x8024\n0x8000\nPC\n0x8020\n0x8040\nAfter jr ra: 0x8024 0x8024\nAfter jr ra: 0x8024 0x8024\nAfter jr ra: 0x8024 0x8024\nAfter jr ra: 0x8024 0x8024\nAfter jr ra: 0x8024 0x8024\nAftj0802408024UHHHHHHHH\nWhat's the deal?\n\u25cf There's only one return address register\n\u25cf If we call more than one level deep, things go horribly wrong\n\u25cf Could we put it in another register?\no Then what about three levels deep? four?\n\u00a7 We just don't have enough registers\u2026\n\u25cf So where do we put things when we don't have room in registers?\no Tip: NOT in other registers (obviously!)\n\u00a7 So don\u2019t give into the urge of doing it\no Put things in memory!\n27\n(yes, memory)\nThe Stack\n28\nOne busy desk\n\u25cf there's a tiny desk that three people have to share\n\u25cf person 1 is working at the desk. it's covered in their stuff.\n\u25cf person 2 interrupts them and needs to do some important work\n\u25cf what does person 2 do with the stuff?\no throw it in the trash?\n\u25cf they put it somewhere else.\n29\nP1\nTrash\nP1\nOne busy desk\n\u25cf there's a tiny desk that three people have to share\n\u25cf person 1 is working at the desk. it's covered in their stuff.\n\u25cf person 2 interrupts them and needs to do some important work\n\u25cf what does person 2 do with the stuff?\no throw it in the trash?\n\u25cf they put it somewhere else.\n\u25cf And once they are done\no They put it back.\n30\nP1\nTrash\nP1\nOne busy desk\n\u25cf now person 2 is interrupted by person 3.\n\u25cf when person 3 is done, person 2 will come back.\n\u25cf where do we put person 2's stuff?\no on top of the stack of stuff.\n\u25cf the desk is the registers.\n\u25cf the people are functions.\n\u25cf the stack of stuff is\u2026 the stack.\n31\nP2\nP1\nP2\nWhat's the stack?\n\u25cf it's an area of memory provided to your program by the OS\no when your program starts, it's already there\n\u25cf the stack holds information about function calls:\no the return address to the caller\no copies of registers that we want to change\no local variables that can't fit in registers\n\u25cf how do we access the stack?\no through the stack pointer (sp) register\no this register is initialized for you by the OS too\n32\nMemory\nStack\nProgram\nThe stack pointer (animated)\n\u25cf let's say sp starts at the address 0xF000\n\u25cf we want to push something on the stack\n\u25cf the first thing we'll do is move sp to the next available slot\n\u25cf clearly, that's the previous address\no subtract 4 from sp\n\u25cf then, we can store something in\nthe memory that sp points to.\n33\n... ...\n0xF008 0x00000000\n0xF004 0x00000000\n0xF000 0x00000000\n0xEFFC 0x00000000\nsp\n0xC0DEBEEF\nDoing that in MIPS (animated)\n\u25cf say ra = 0xC0DEBEEF\n\u25cf first: move the stack pointer down (up?):\nsub sp, sp, 4\n\u25cf then, store ra at the address that sp holds.\nsw ra, (sp)\n\u25cf now the value in ra is saved on the\nstack, and we can get it back later.\no and we can store as many return\naddresses as we want!\n34\n... ...\n0xF008 0x00000000\n0xF004 0x00000000\n0xF000 0x00000000\n0xEFFC 0x00000000\nsp\n0xC0DEBEEF\nGoing the other direction (animated)\n\u25cf now we wanna pop the value off the stack and put it back in ra\n\u25cf we do the same things, but in reverse\nlw ra, (sp)\n\u25cf then, we move the stack pointer\u2026\nup? down? whatever\nadd sp, sp, 4\n\u25cf now we got back the old value of ra!\n\u25cf and sp is back where it was before!\n35\n... ...\n0xF008 0x00000000\n0xF004 0x00000000\n0xF000 0x00000000\nsp 0xEFFC 0xC0DEBEEF\nra 0xC0DEBEEF 0xABAD1DEA\nShortening the pushes and pops\n\u25cf the push and pop operations always look and work the same\n\u25cf since you'll be using them in most functions, we shortened em\n\u25cf if you write push ra or pop ra, it'll do these things for you!\n36\nsubi sp, sp, 4\nsw ra, (sp)\nlw ra, (sp)\naddi sp, sp, 4\npush ra\npop ra\nthese can be used with ANY register, not just ra!\nthese are pseudo-ops: fake instructions to shorten common tasks\nit's really simple\n\u25cf treat pushes and pops like the { braces } around a function\n37\nspoon:\npush ra # {\n# 800 instructions\n# so much stuff omg\npop ra # }\njr ra\npushes come at the\nbeginnings of functions\npops come at the end\nthat is it, seriously, don't\nmake it more complicated\nnever push or pop anywhere else please\nToes = protected\n38\n0x8000 jal fork\nfork:\n0x8020 push ra\n0x8028 jal spoon\n0x802C pop ra\n0x8034 jr ra\nspoon:\n0x8040 jr ra\n0x0000\nra\nAfter jal spoon:\nAfter jal fork: 0x8004\n0x802C\n0x8000\nPC\n0x8020\n0x8040\nAfter spoon jr ra: 0x802C 0x802C\nBefore fork jr ra: 0x8034 0x8004\nAfter fork jr ra: 0x8004 0x8004\nThen we push ra on the stack!\nThen we pop ra off the stack!\nsp 0x8004 stuff\nWriting a simple function\n\u25cf Function calling conventions follows a simple structure :\n\u25cf Push everything you need! Pop it back in reverse order at the end!\n39\nspoon:\npush ra\npop ra\njr ra\nyour code goes here\n1. Give it a name (label).\n2. Save ra to the stack.\n3. Do whatever.\n4. Load ra from the stack.\n5. Return!\nWhat about other registers?\n\u25cf Function calling conventions follows a simple structure :\n\u25cf Push everything you need! Pop it back in reverse order at the end!\n40\nspoon:\npush ra\npop ra\njr ra\nyour code goes here\n1. Give it a name (label).\n2a. Save ra to the stack.\n3. Do whatever.\n4b. Load ra from the stack.\n5. Return!\n2b. Save s0 to the stack. push s0\n4a. Load s0 from the stack. pop s0\nThe s register contract\n\u25cf if you want to use an s register\u2026\n\u25cf you must save and restore it, just like ra.\n41\nmy_func:\npush ra\npush s0\npop s0\npop ra\njr ra\nmoving the papers off the desk\nputting the papers back the pops happen\nin reverse order!\ncode that uses s0! it's fine! we saved it!\nOh, and\u2026\n\u25cf You must always pop the same number of registers\nthat you push.\n\u25cf To make this simpler for yourself\u2026 make a label\nbefore the pops.\no then you can leave the function by\njumping/branching there.\n\u25cf Remember: These are the { braces }\no So\u2026 only push in the top and pop in the\nbottom of the function!\n\u00a7 Only!\n42\nmy_func:\npush ra\npush s0\n...\nbge ...\nb exit_func\n...\nexit_func:\npop s0\npop ra\njr ra\nSumming it up: Terminology\nmyFunction:\npush ra\npush s0\n# my code\npop s0\npop ra\njr ra\nActivation Frame\nFunction Epilogue\nFunction Prologue\nContains:\nl Arguments (that\naren\u2019t in registers)\nl Saved Registers\n(ra, s0, etc)\nl Local Variables\nMemory\nStack\n43\nProgram\nHeap\n0x0000\n0xffff\nExample \u2013 A function\u2019s local variable\n44\nint function(int a, int b) {\nint i;\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026stuff\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n}\n# 2 arguments:\n# a -> a0\n# b -> a1\nfunction:\naddi sp, sp, -16\n# Backup ra, s0, s1\nsw ra, 12(sp)\nsw s0, 8(sp)\nsw s1, 4(sp)\n# variable i is stored in memory at sp + 0\n# Backup arguments\nmove s0, a0\nmove s1, a1\n \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026stuff\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\n# Restore ra, s0, s1\nlw s1, 4(sp)\nlw s0, 8(sp)\nlw ra, 12(sp)\naddi sp, sp, 16\njr ra\nExample using the variable\n45\nfor(i=0; i<10; i++) {\nprint(i);\n}\n# variable i is stored in memory at sp + 0\n# loop initialization\nsw zero, 0(sp)\n# loop comparison\n_function_loop:\nlw t0, 0(sp)\nbge t0, 10, _function_loop_end\nlw a0, 0(sp)\nli v0, 1\nsyscall\n# loop increment\nlw t0, 0(sp)\naddi t0, t0, 1\nsw t0, 0(sp)\n# loop jump\nj _function_loop\n_function_loop_end:\nExample complete (unreadable, but copy-pastable)\n46\nint function(int a, int b) {\nint i;\nfor(i=0; i<10; i++) {\nprint(i);\n}\nreturn a+b;\n}\n# 2 arguments:\n# a -> a0\n# b -> a1\nfunction:\naddi sp, sp, -16\n# Backup ra, s0, s1\nsw ra, 12(sp)\nsw s0, 8(sp)\nsw s1, 4(sp)\n# variable i is stored in memory at sp + 0\n# Backup arguments\nmove s0, a0\nmove s1, a1\n# loop initialization\nsw zero, 0(sp)\n# loop comparison\n_function_loop:\nlw t0, 0(sp)\nbge t0, 10, _function_loop_end\nlw a0, 0(sp)\nli v0, 1\nsyscall\n# loop increment\nlw t0, 0(sp)\naddi t0, t0, 1\nsw t0, 0(sp)\n# loop jump\nj _function_loop\n_function_loop_end:\naddi v0, s0, s1\n# Restore ra, s0, s1\nlw s1, 4(sp)\nlw s0, 8(sp)\nlw ra, 12(sp)\naddi sp, sp, 16\njr ra\nSide Stacking\n(on your own)\n47\nSooooo\u2026..\n\u25cf Why this mysterious behavior?\no \u201cAllocating\u201d on the stack (making room) has you subtract from its base address.\n\u25cf Let\u2019s visit this from a different direction.\n\u25cf Let\u2019s consider\u2026 the problem itself.\no And how we might solve it.\n48\nThe Problem\n\u25cf We have a program. It uses memory.\n\u25cf We don\u2019t know exactly how much memory we need.\no It may depend on how long the program runs.\no Or the size of the data it is working on (arbitrarily specified by a human being,\nperhaps)\no Maybe our program responds to the available memory by choosing a different\nalgorithm when it has more or less.\n\u25cf Either way, a program does not have a static allocation of memory.\n\u25cf How do we allow a program to allocate memory on-demand?\n49\nOur Example: Video Editor\n\u25cf Let\u2019s consider a video editing program.\no But thankfully ignore all of the actual video details!\n\u25cf Data is large, and the memory usage is relative to the size of\nour video.\n\u25cf We want memory to be continuous.\no Could you imagine if data were all broken up?\no Your program would be difficult to code if an array was\nbroken up.\n\u00a7 Our array addressing math would no longer be general and\nwould cease to work well. (You\u2019d have multiple array base\naddresses)\n50\nMemory\nProgram\nAllocating Memory\n\u25cf You\u2019ll learn a lot more about this in CS 449\no But it\u2019s worth sequence breaking and talking about it now\n\u25cf We will maintain a section of memory: the heap.\no The heap is a section of memory used for dynamic memory.\no Dynamic memory is memory that is allocated during the\nruntime of a program and may be reclaimed later.\n\u25cf When we allocate memory, we add\nit to the end of the heap.\no It\u2019s like appending to an array.\no Look at it go!\n51\nMemory\nProgram\nHeap\n0x0000\n0x4000\n0x4100\n0x46f0\nRevisiting Functions: A Problem Arises\n\u25cf Now, consider functions.\n\u25cf When we call a function, we need to remember where we were.\no This is stored in the $ra register.\no But if we call a function twice, what happens to $ra?\n\u00a7 It is overwritten, and our first value in $ra is lost.\n\u00a7 This means after our second function is called, the first function will now be lost,\nand it will return to itself. (Refer to the previous slides)\n\u25cf What are our strategies for remembering ra?\n52\nRemembering RA\n\u25cf Bad Idea #1: Place it in another register\nmyFunction:\nmove t0, ra\n# overwrites ra!\njal myOtherFunction\n# it\u2019s ok though:\nmove ra, t0\njr ra\n53\nHowever:\n\u2022 What if myOtherFunction uses t0?\n\u2022 Ok, t0 isn\u2019t preserved, so let\u2019s use s0.\n\u2022 Wait\u2026 we need to preserve s0\u2026\n\u2022 Where do we put that?? s1???\n\u2022 Wait\u2026 we need to preserve s1!!\n\u2022 We will run out of saved registers and\nwe cannot trust unsaved registers.\n(other functions may overwrite them)\n\u2022 Therefore, we need memory.\nRemembering RA\n\u25cf We need memory. We have that heap thing.\n\u25cf So can\u2019t we just allocate some on the heap?\n\u25cf Sure can. But it is Bad Idea #2.\n\u25cf What happens if that function allocates memory?\n\u25cf And then calls another function.\n\u25cf And then we return\u2026\n\u25cf And return from the first function\u2026\n\u25cf Leaving gaps in our memory!\n54\nMemory\nProgram\nHeap\n0x0000\n0x4000\nLet\u2019s Design a Memory Layout (kinda)\n\u25cf Our video editing application wants to use large, continuous memory regions.\no Videos are big things! (Continuous memory makes things easier/faster\u2026 future\ncourses will convince you.)\n\u25cf We have very few registers, and need to remember ra\no So, we need to place ra in memory to recall it before we jr ra\n\u25cf However, placing it with other program memory creates gaps\no This is very very trash!!\n\u25cf How do we solve this.\no Occam\u2019s Razor to the rescue\u2026 and it will create a very weird situation.\no One that involves subtracting to allocate\u2026\n55\nMemory\nStack\nSolving our Problem: Step 1\n\u25cf How can we use memory, but not create gaps?\n\u25cf Good [rational] Idea: Maintain two dynamic memory\nsections.\n\u25cf We call our function.\n\u25cf What happens if that function allocates\nmemory?\n\u25cf And then calls another function.\n\u25cf And then we return\u2026\n\u25cf And return from the first function\u2026 WHEW!\nNo gaps.\n\u25cf (Ok, but now we start editing a LARGE video\u2026)\no Uh oh! We\u2019ve lost our $ra\n56\nProgram\nHeap\n0x0000\n0x4000\n0x8000\nMemory\nStack\nSolving our Problem: Step 2\n\u25cf Good [weird] Idea: Maintain two dynamic memory sections. One of which starts at the\nhighest memory address. Allocate via subtraction (append to bottom)\n\u25cf We call our function.\n\u25cf What happens if that function allocates memory?\n\u25cf And then calls another function.\n\u25cf And then we return\u2026\n\u25cf And return from the first function\u2026 No gaps.\n\u25cf As for our large memory case\u2026\n\u25cf It\u2019s fine! (only problem: running out of memory)\no But, my goodness, you have a bigger problem, then.\n57\nProgram\nHeap\n0x0000\n0x4000\n0xfffc\n0xfff0\nMemory\nStack\nSolving our Problem: Step 2\n\u25cf Good [weird] Idea: Maintain two dynamic memory sections.\nOne of which starts at the highest memory address.\nAllocate via subtraction (append to bottom)\n\u25cf We call our function. (subtract $sp, store)\n\u25cf What happens if that function allocates memory?\n\u25cf And then calls another function. (sub, store)\n\u25cf And then we return\u2026 (load, add to $sp)\n\u25cf And return from the first function\u2026 (load, add $sp)\n\u25cf Refer to the previous slides on the Stack with this\nknowledge in your mind.\n# A simple function to compute the greatest\n# common denominator of a set of two numbers.\n\n# Exercises:\n#   1. What happens when we remove the exit system call?\n#      This is why this is important!\n#   2. The LCM (lowest-common-multiple) is defined as\n#      lcm(a,b) = (a * b) / gcd(a, b)\n#\n#      Given this, implement the function lcm to call gcd.\n#\n#      Note: We must strengthen our gcd call by pushing\n#        $ra to the stack.\n\n.globl main\nmain:\n\n\tli\ta0, 81\n\tli\ta1, 6\n\tjal\tgcd\t\t\t\t# v0 = gcd(81, 6);   (result should be 3)\n\t\n\tmove\ta0, v0\n\tli\tv0, 1\n\tsyscall\t\t\t\t\t# syscall(PRINT_INTEGER, v0);\n\t\n\t# exit\n\tli\tv0, 10\n\tsyscall\t\t\t\t\t# syscall(EXIT);\n\n# int gcd(a0: int a, a1: int b)\n#\ngcd:\n\tmove\tt0, a0\n\tmove\tt1, a1\n\t\n_gcdLoop:\n\tbeq\tt0, t1, _gcdLoopExit\t\t# while(a != b) {\n\t\n\tble\tt0, t1, _gcdLoopElse\t\t# \tif (a > b) {\n\tsub\tt0, t0, t1\t\t\t# \t\ta -= b;\n\tj\t_gcdLoopEndIf\n_gcdLoopElse:\t\t\t\t\t# \t} else {\n\tsub\tt1, t1, t0\t\t\t# \t\tb -= a;\t\n_gcdLoopEndIf:\t\t\t\t\t#\t}\n\tj\t_gcdLoop\t\t\t# }\n_gcdLoopExit:\n\tmove\tv0, t0\n\tjr\tra\t\t\t\t# return a;"
        },
        {
            "lecture": 18,
            "content": "Instruction Execution\n3\n1. Fetch (IF or F)\no use PC to get the next instruction from memory\n2. Decode (ID or D)\no look at the fetched instruction and set control signals\n3. Execute (EX or X)\no wait for data to flow through the datapath\n4. Memory Access (MEM or M)\no if it's a load or store, do that\n5. Write-back (WB or W)\no if there's a destination register, write the result to it\n4\nPhases of instruction execution\nF D X M W\noften we can do multiple phases \"at the same time\"\n5\nWhich parts do what\nMemory\nPC\nControl\nRegister\nFile ALU\nMemory\nagain\nF D W X M\nHow does lw work?\nlw t0, 12(s0)\nA Thing about memory\n6\n\u25cf how many RAMs does your computer have? one or two?\n\u25cf if we try to do lw t0, (s0) with one memory in a single cycle\u2026\n7\n\u2622 Structural Hazards \u2622\nMemory\nPC\nInstruction\nAddress\nControl\nInstruction\nLoad word\naddress\u2026?\nLoaded\nword\u2026??\nwe can't really do this\u2026 memory hardware can't read\nfrom two addresses at the same time\nwhat about sw?!?\n\u25cf one way to solve this problem is to have two memories\n8\nVon Neumann vs Harvard\nInstruction\nMemory\nPC\nControl\nRegister\nFile\nALU\nData\nMemory\nthis is a Harvard\nArchitecture\na Von Neumann Architecture has one memory for both things\n\"Von Neumann\" is 2 words for 1 memory\u2026\n\"Harvard\" is 1 word for 2 memories\u2026\n\u25cf a Von Neumann machine has one memory, but uses multiple\nclock cycles to execute each instruction\n9\nMulti-cycle\nMemory\nPC\nInstruction\nAddress\nControl\nInstruction\nLoaded\nword\nCycle 1:\nCycle 2:\nLoad word\naddress\nlw t0, (s0)\nmulti-cycle machines are by\nfar the most common today\nbut they're more complex\u2026\nThe Interconnect\n10\n\u25cf we've got pieces of a CPU, but they don't operate in isolation\n\u25cf we gotta hook em together. but which parts hook to which?\n\u25cf the instructions in the ISA tell you what has to connect to what.\n11\nGotta keep em separated interconnected\nInstruction\nMemory\nPC that\ncan branch\nand jump Register\nFile\nALU\nData\nMemory\n\u25cf if we look at all the different instructions we want to support, we'll\nstart to get an idea of what data goes where\n12\nSlowly coming together\nRegister\nFile ALU\nt0\nt1\nv0 - Data\nMemory\nRegister\nFile\nALU\ns0\nt3\n+\n4\nData\nAddress\nsub v0, t0, t1 sw s0, 4(t3)\nALU?\nRegister\nFile\nPC\n+\n4\nra\naddress of\nmove_ball\njal move_ball\nhow do we make all\nthese different things\nhappen with one set\nof hardware\u2026?\n\u25cf the interconnect lets the CPU parts combine in many ways\n\u25cf it's like the CPU's \"circulatory system\" \u2013 it moves data around\n13\nPC to the left of me, ALU to the right, here I am\nRegister\nFile\nALU\nData\nMemory\nInstruction\nMemory\nadd, sub, etc.\nstores\nloads\nPC\njr\nli (immediate)\naddi, ori etc.\njal\nit's starting to take shape\u2026\n\u25cf you can make a table to keep track of what things connect to what.\n14\nA little technique: an interconnect matrix\nALU PC Regs IM DM\nALU\nPC\nRegs\nIM\nDM\n\u2026to here?\nDoes the data\nflow from\nhere\u2026\nnow consider all the\ninstructions your CPU\nshould support, and mark\nthe cells accordingly.\nlw\nadd, sub, and, or\nbeq sw j\nany component (column) with\nmultiple things coming\ninto it will need a MUX.\n(huh? next slide.)\n\u221a\n\u221a\n\u221a\n\u221a\n\u221a\nli? jal\n\u221a\n\u221a\n\u221a jr\n\u25cf the interconnect makes choices about which things go where\n15\nConjunction junction\nRegister\nFile\ndata from memory\nALU results\ninstruction immediates\nsaved PC for jal\nRegDataSrc\n2\nso how do we choooooose\nwhich thing to write?\nnow we have a select pin.\nthis is a control signal!\nthere will be several MUXes in the\ninterconnect, and each needs a control signal\nthe book calls this \"MemToReg\u201c.\nBecause in its model the value is 1 when\nthe memory is read into a register\nonly one of these is written\nto the register file\n\u25cf if we want to make a suuuuper simple version of MIPS, we can\nconnect the pieces together into a datapath like this\n16\nInterconnected (MIPS, not your project)\nRegister\nFile\nimm field\nALU\nMemWrite\nALUSrc ALUOp\ndest\nRegWrite\nRegDataSrc\nsource\nsource 2\nData\nMemory\nData\nAddress\n(this version doesn't\nsupport jal, and \u2026\nbut that's fiiiine)\nbut now we need\nto, uh, control the\ncontrol signals.\nhow can we use this\nto implement add?\nsub? addi? lw? sw?\nli? \nThe Forgotten Phase:\nOperand Fetch\n17\n\u25cf operand fetch is a phase of instruction execution you might see\n\u25cf it fetches the values to be operated on\n18\nA little extra step\nF DO?X M W\nit happens after the\ninstruction is decoded.\nwhere do values have to be for\nthe CPU to operate on them?\nin the registers\u2026?\n\u25cf in MIPS (and your project), operand fetch is super simple:\n19\nVestigial\nRegister\nFile\nimm field\nALU\nhere it is!\nthis is by design: load-store\narchitectures have very simple\noperand fetch phases.\nwhy? well\u2026\n\u25cf as a CISC, x86 has some\u2026 crazy instructions.\n20\nOperand Fetch in x86\ninc [eax + ecx*4 + 12]\nthis is operand fetch.\n(the brackets mean \"access memory.\")\nhere's what the CPU has to\ndo for this instruction:\n1. multiply ecx by 4\n2. add eax to that\n3. add 12 to that\n4. load a word from\nthat address\n5. add 1 to that value\n6. store that value back\ninto the address\nthis is an effective\naddress calculation.\nbe very glad you won't have\nto do this for your project.\nThe Control\n21\nData\nMemory\n\u25cf the control is what sets the write enables and selects to the\nappropriate values to make each instruction happen\n\u25cf it's like the CPU's brain and nervous system\n22\nFeeling nervous\nControl\nc'mon you\nlazy bums\nRegister\nFile\nALU\nawwwww we\ndon't wannaaaa\nit does this by reading\nthe instructions.\nsub v0, t0, t1\nRegister file, read t0 and t1, and write to\nv0. ALU, do subtraction. Interconnect,\nroute the data from the two registers into\nthe ALU and from the ALU into the register\nfile. Data memory, you get to take a break.\nyissssss\n\ufffd\nTwo kinds of control signals\n\u25cf first there are the selects\no these go into the select pins of\nmuxes, demuxes, or decoders\no they can be any number of bits\n\u25cf then there are the write enables\no these tell registers and memory\nwhen to store data\no they're Booleans - 0 or 1\n\u25cf they often come in pairs!\no like RegWrite and RegDataSrc.\no they decide what to write and\nwhen to write it.\n23\nRegister\nFile\nData\nMemory\nMemWrite\nRegWrite\nrd 5\nRegDataSrc\n\u25cf write enables are kind of the basis of \"things happening in a CPU\"\n\u25cf almost every instruction writes something somewhere!\n24\nGotta write it down\nadd t0, t1, t2\nbeq s0, 10, end jal func1\nsw s0, (t0)\nwrites to t0 writes to memory\nmight write to the PC writes to the PC and ra!\nif an instruction doesn't write anything, it's a no-op (nop).\n(if an instruction does not change anything, did it ever happen?)\nwhat changes when a conditional branch isn't taken?\n\u25cf we connected the datapath together; now for the control bits\n25\nThe control hardware\nInstruction\nMemory\naddress goes in\u2026\n\u2026instruction\ncomes out.\nPC\nimmediate\n(jump target)\n4\nPCSrc\n+\nMemWrite\nALUSrc\nALUOp\nrd\nRegWrite RegDataSrc\nrs\nrt\nimmediate\nPCSrc\nControl\ninstruction\ngoes in\u2026\n\u2026control signals\ncome out.\nsomehow.\nInstruction Decoding\n26\n\u25cf the first step is to split the encoded instruction up\n\u25cf but which instruction format is it? actually, it doesn't matter.\n27\nPull 'n' peel\n\"do everything at once, but\nuse only what you need.\"\n31 26 25 21 20 16 15 0\nopcode rs rt immediate\n31 26 25 21 20 16 15 11 10 6 5 0\nopcode rs rt rd shamt funct\n31 26 25 0\nopcode target\n31-26 opcode\n25-21\nrs\n20-16 rt\n15-11 rd\n10-6 shamt\n5-0 funct\n15-0 immediate\n25-0 target\n32\ninstruction\nR\nI\nJ\n\u25cf suppose the encoded instruction was addi s0, s0, -1.\n28\nNo, really, it's fine, don't worry about it\nop\nrs\nrt\nrd\nshamt\nfunct\nimm\ntarget\n32\n0x2210FFFF\naddi s0,s0,-1\n0x08\n0x10\n0x10\n0x1F\n0x1F\n0x3F\n0xFFFF\n0x210FFFF\n31 26 25 21 20 16 15 0\nopcode rs rt immediate\nput it through\nthe splitter and\u2026\n\u2026out come a\nbunch of values.\naddi is an I-type instruction.\nopcode, rs, rt, and immediate\nwill be used.\nthe rest are bogus and will be\nignored. see? it's fiiiiiine\n\u25cf the control is a boolean function that takes the instruction\nopcode as its input and outputs the control signals.\n\u25cf in other words, it's a big fat truth table.\n29\nMaking the control work\nopcode PCSrc RegDataSrc RegWrite ALUOp \u2026\n000000 0 00 0 000 \u2026\n000001 0 01 1 110 \u2026\n000010 0 00 1 010 \u2026\n000011 1 00 0 011 \u2026\n000100 1 11 1 000 \u2026\n000101 0 10 1 010 \u2026\n\u2026 \u2026 \u2026 \u2026 \u2026 \u2026\nThis is not the only way of\nmaking your control unit.\nyou will go insane.\nit's time-consuming,\nconfusing, hard to debug,\nand hard to change.\nThese are made up numbers. Please don't try to use them!\n\u25cf Here's a great use for a decoder: decoding. (huh.)\n30\nA more approachable approach\nopcode\n<r-type>\n<uhh random crap>\nj\njal\nbeq\nbne\nblez\nbgtz\naddi\naddiu\nslti\nsltiu\nexactly one of these will\nbe on at a time.\nnow it's just a matter of coming up with\nthe logic for each of the control signals.\nfor that, it's good to focus on one\ncontrol signal at a time.\n\u25cf let's say we want to come up with the MemWrite control signal\n\u25cf which MIPS instructions write to memory?\n31\n<the sound a seal makes>\nsw\nsh\nsb\nMemWrite pretty straightforward, huh?\nwhat about multi-bit control signals,\nlike your ALU operation?\nthere are a few approaches\u2026\n\u25cf in this approach, you use enormous MUXes to select constants.\n32\nThe brute-force approach: the MUXtipede\nopcode\nALUOp\nALUOp for opcode 0\nALUOp for opcode 1\nALUOp for opcode 2\nALUOp for opcode 3\nALUOp for opcode 4\nALUOp for opcode 5\nALUOp for opcode 6\nALUOp for opcode 7\nALUOp for opcode 8\nALUOp for opcode 9\nALUOp for opcode A\nALUOp for opcode B\nALUOpforopcodeCit\u2026 works, but it's hard to follow.\nit's hard to tell which constant\nis used for which instruction.\nit's also hard to add new\ninstructions.\nwe can make this a tiny\nbit MUCH MORE\nelegant!\n\u25cf a priority encoder is kind of the opposite of a decoder.\n\u25cf you give it several 1-bit inputs, and it tells you which one is 1.\n33\nPriority Encoders\nPri\n1\n0\n0\n0\n0 Pri\n0\n1\n0\n0\n1\nPri\n0\n1\n0\n0\n2 Pri\n0\n1\n0\n0\n3\nPri\n0\n0\n0\n0\nX\nif none of the inputs is 1,\nthen it gives you X\u2026\nto avoid this, put a constant\n1 as the first input.\n\u25cf let's say we have these instructions, and these ALU operations.\n\u25cf for each input, ask: which instructions need this ALU operation?\n34\nMulti-bit control signals\nadd\naddi\nsub\nsubi\nand\nor\n0: &\n1: |\n2: +\n3: - Pri ALUOp\n1\nsub\nsubi\nadd\naddi\nor\nALUOp 0 is the default,\nso and is handled.\nwhich instruction(s)\nneed OR (1)?\nwhat about + (2)?\nwhat about - (3)?\nthink of it like an\nupside-down if-else-if"
        },
        {
            "lecture": 19,
            "content": "The single-cycle machine\n\u25cf we\u2019ve been talking about a single-cycle machine and building one for project 3\n\u25cf this means each instruction takes one clock cycle to execute\n3\nadd t0, t1, t2 sb t0, 4(s0)\ncalculate the\naddress...\nstore sum in t0 store value\ndo the addition... in memory\nIn this example each instruction ends on the rising edge of the clock\nsince that's when the registers store their values\nThis is a diagram of a computer processor executing an instruction. There are several components involved. The instruction is read from the instruction memory, and the Program Counter (PC) is incremented. The instruction is then broken down into various parts, each of which is used to control the various parts of the processor.\n\nThe first part of the instruction (bits 31-26) is used to select a control signal.\n\nThe next part (bits 25-21) is used to read data from a register.\n\nThe next part (bits 20-16) is used to write data to a register.\n\nThe next part (bits 15-11) is used to select data from a multiplexer.\n\nThe next part (bits 15-0) is used to extend the sign of a number.\n\nThe next part (bits 5-0) is used to control the ALU (Arithmetic Logic Unit) operations.\n\nThe ALU is used to perform various mathematical and logical operations on the data. The ALU result is then used to update the registers.\n\nThis is a simplified explanation of how a computer processor executes an instruction. The actual process is more complex and involves many other components, but this gives you a basic understanding of how it works.\nHow fast can we clock it?\n\u25cf what's the thing that limits the clock speed?\no the critical path. in our case it happens to be...\no and here is the Achilles' heel of a single-cycle datapath:\n31\nMemory is\nSLOW.\nA.\nF.\nSingle-cycle CPU\nAny instruction executes during a single clock cycle\nLength of the clock cycle must accommodate the longest instruction\n\u25cf Faster instructions waste cycle time\n32\nClock cycle 0 1\nMem Reg Mem Reg\nMem Reg Reg\nlw t0,0(t1)\nadd t2,t2,t3\nIt's bad.\n\u25cf typical access times for modern DDR4 RAM is 12-15 ns\no that's our single-cycle CPU's critical path time\n\u25cf the inverse of that is... 66-83 MHz\no YEESH\n\u25cf the lw and sw instructions are holding us back\n\u25cf all the other instructions are gonna be WAY faster\nRemember the Critical Path?\n\u25cf the critical path is the path through a circuit that requires the longest series of\nsequential operations\no they depend on each other and can't be done in parallel!\nLet's break down how the diagram illustrates executing different instruction types, and then address real-world clocking issues:\n\n1. Executing an R-Type Instruction (e.g., add, sub, and, or)\n\nPurpose: R-type instructions perform arithmetic or logical operations on register values.\n\nFlow:\n\nFetch: The PC points to the R-type instruction in memory. The instruction is fetched and loaded into the Instruction Register (IR).\n\nDecode: The instruction is decoded. The opcode (bits 31-26) identifies it as R-type. The register fields (rs, rt, rd) indicate the source and destination registers.\n\nExecute: The ALU is controlled based on the ALU opcode field of the instruction. The ALU reads values from the specified source registers and performs the operation (add, sub, and, or).\n\nWrite Back: The ALU result is written back to the destination register (rd).\n\nPC Update: The PC is incremented to point to the next instruction.\n\nExample (add r1, r2, r3):\n* The instruction specifies to add the values in registers r2 and r3 and store the result in register r1.\n\n2. Executing an LW Instruction (Load Word)\n\nPurpose: LW loads a value from memory into a register.\n\nFlow:\n\nFetch and Decode: Same as R-type.\n\nAddress Calculation: The instruction's immediate field is combined with the contents of the register (rs) to calculate the memory address to read from.\n\nMemory Access: The calculated address is sent to the data memory. The data at that address is fetched.\n\nWrite Back: The fetched data is written to the register specified by the instruction (rt).\n\nPC Update: The PC is incremented.\n\nExample (lw r1, 16(r2):\n* This instruction loads the word at memory location (r2 + 16) into register r1.\n\n3. Executing a BEQ Instruction (Branch on Equal)\n\nPurpose: BEQ branches to a different address if two registers contain equal values.\n\nFlow:\n\nFetch and Decode: Same as R-type.\n\nCompare: The values of the two specified registers (rs and rt) are compared.\n\nBranch: If the registers are equal, the PC is updated with the value of the instruction's immediate field (shifted left by two bits). This effectively jumps to a different instruction in the program.\n\nPC Update: If the registers are not equal, the PC is incremented normally, continuing with the next instruction.\n\nExample (beq r1, r2, 100):\n* If the values in registers r1 and r2 are equal, the PC jumps to the instruction located 100 instructions ahead.\n\n4. Executing a Jump Instruction\n\nPurpose: Jump unconditionally to a new address.\n\nFlow:\n\nFetch and Decode: Same as R-type.\n\nAddress Calculation: The instruction's immediate field is used to calculate the new target address. This calculation often involves shifting the immediate field left by 2 bits.\n\nPC Update: The PC is set to the calculated target address.\n\nExample (j 100):\n* This instruction unconditionally jumps to the instruction located at address 100.\n\n5. Real-World Clocking Issues\n\nThe diagram is simplified. Real-world processors encounter timing and synchronization challenges:\n\nClock Cycle: Instructions are executed within clock cycles. These cycles must be precisely timed and synchronized across all processor components.\n\nPipeline Hazards: A pipeline is used to execute multiple instructions concurrently. This can lead to hazards like data dependencies (one instruction needs the result of another). These hazards need to be resolved, often with stalling or forwarding techniques.\n\nCache Misses: Memory access takes much longer than register access. If data needs to be fetched from main memory (cache miss), it delays the processor.\n\nMemory Latency: The time it takes to read from or write to memory can vary. This can lead to unpredictable execution times.\n\nHow the Diagram Relates\n\nThe diagram is a simplified model of a processor's execution pipeline, highlighting the control flow and data paths. It doesn't show the intricacies of clocking, pipeline hazards, or cache management, which are crucial in real-world processor implementations.\n\nKey Points:\n\nThe diagram demonstrates the basic steps of fetching, decoding, executing, and writing back results for instructions.\n\nReal-world processors use advanced techniques like pipelining and caching to improve performance and efficiency.\n\nClocking issues are complex and require careful design to ensure accurate and reliable operation."
        },
        {
            "lecture": 22,
            "content": "How can we make the CPU\nmore efficient? \u2026\n3\n\nDoing the laundry\nLuis (me), Artur, Stephen, and Ray have one load of clothes to\no Wash\no Dry\no Fold\nWhere we live, we can only do laundry Saturday from 9:00 to 18:00!\n4\nWasher takes 60 minutes\nDryer takes 60 minutes\nFolding takes 60 minutes\nSequential laundry\n\u25cf We have four loads of laundry to do (Luis, Artur, Stephen, and Ray)\n5\nFirst, I wash\nThen, I dry\nFinally, I fold\nIt took me 3:00, we\nstill have three\nloads remaining!\nYikes! It\u2019s 15:00, we still\nhave two loads to go\nIt\u2019s 18:00, and Ray\ncannot do his laundry!\n9:00 10:00 11:00 12:00 13:00 14:00 15:00 16:00 17:00\nHow can we solve this?\n\u25cf Buy more machines!!!\n\u25cf Or\u2026\n6\nPipelined laundry\n\u25cf We have four loads of laundry to do (Luis, Artur, Stephen, and Ray)\n7\nWe can start the\nnext load!\nThe washer is now\nfree!!\n9:00 10:00 11:00 12:00 13:00 14:00 15:00 16:00 17:00\nRinse and\nrepeat\nEveryone can do\ntheir laundry\nBut did the time it\ntakes to wash the\nclothes change?\nUpgrading the multi-cycle CPU\nLet\u2019s apply the same concept to a multi-cycle CPU!\nKeep the same clock\n\u25cf Reuse resources with \u2026\n8\nTime 0 1 2 3 4 5 6 7\nadd t2,t2,t3\nlw t0,0(t1) Mem Reg Mem Reg\nMem Reg Reg\nLighting up the silicon (animated)\nExecuting instructions in a pipeline\n9\nMemory\nF\nControl\nRegister\nFile\nD X\nMemory\nagain\nM\nW\nsub add sw\nUses\nmemory Uses decoder/registers Uses ALU Uses\nmemory\nPipeline vs Multi-cycle\n10\nPipelining doesn\u2019t help latency of a single instruction!\nDifferent tasks operating different resources\ncan execute simultaneously\nMore stages, more potential speedup (too many stages is not good!)\nIt helps throughput of the entire workload!\nTime 0 1 2 3 4 5 6 7\nadd t2,t2,t3\nlw t0,0(t1) Mem Reg Mem Reg\nMem Reg Reg\nSo how did we improve performance?\n\u25cf Did we make any individual instruction faster?\no No, the add still took 4 cycles\u2026 the lw took 5 cycles\n\u25cf But the whole thing finished faster. right?\n11\nYes, by overlapping the instructions,\nwe increased the throughput.\nIn any given clock cycle, we're\nnow doing more work.\nWith this we can get the CPI\ndown closer to 1.\nThe average CPI\n\u25cf It\u2019s the average number of Cycles Per Instruction\no For any program, we count the # of cycles\n\u00a7 and divide by the # of instructions\n12\nTime 0 1 2 3 4 5 6 7\nadd t0,t1,t2 Mem Reg Reg\nadd t3,t4,t5\nadd s0,s1,s2\nadd s3,s4,s5\nMem Reg Reg\nMem Reg Reg\nMem Reg Reg\nCPI = 7 \u00f7 4\n= 1.75\nWhat happens when we have an\ninfinite number of instructions?\nPipeline (real-world) issues\n13\nInstructions are co-dependent L\n\u25cf Sometimes, the next instruction cannot execute in the next cycle\no We call those pipeline hazards.\n\u25cf Hazards happen when for any reason an instruction is unable to advance\n(execute) in the pipeline\n\u25cf We\u2019ll look at three types of hazards\no Structural hazards\no Data hazards\no Control hazards\n14\nStructural hazards\nAttempting to use the same resource two different ways simultaneously. E.g.:\n\u25cf You get home soaking wet and need to dry your clothes while someone is\nusing the dryer\nIn a CPU with a single memory:\n\u25cf Can we fetch a new instruction while reading a word from memory?\no NOPe: structural hazard\n15\nTime 0 1 2 3 4 5 6 7\nStructural hazards\n\u25cf Two instructions using the same hardware at the same time\n16\nlw t0,0($0)\nlw t1,4($0)\nlw t2,8($0)\nlw t3,12($0)\nMem Reg Mem Reg\nMem Reg Mem Reg\nMem Reg Mem Reg\nMem Reg Mem Reg\nStructural hazards \u2013 What can I do???\n\u25cf Structural hazards arise from lack of resources\n\u25cf So\u2026 We can eliminate the hazard by adding more resources!\no Add a second memory?\n\u00a7 The Harvard architecture!\n\u25cf Another solution:\no Stall the instruction until the resource is available\n17\nTime 0 1 2 3 4 5 6 7\nlw t3,12($0) Mem Reg Mem Reg\nNOP NOP NOP NOP NOP\nTime 0 1 2 3 4 5 6 7\nStructural hazards \u2013 What can I do???\n\u25cf You may need more than one stall!\n18\nlw t0,0($0)\nlw t1,4($0)\nlw t2,8($0)\nlw t3,12($0)\nMem Reg Mem Reg\nMem Reg Mem Reg\nMem Reg Mem Reg\nMem Reg Mem Reg\nNOP NOP NOP NOP NOP\nNOP NOP NOP NOP NOP\nNOP NOP NOP NOP\nNOP NOP NOP NOP NOP\nData hazards\nAttempting to use an item before it is ready. E.g.:\n\u25cf Only one sock of a pair is found during folding\n\u25cf It\u2019s in the dryer! Folding has to wait!\nIn a CPU:\n\u25cf Instruction depends on result of prior instruction still in the pipeline\n19\nadd s0, t0, t1\nsub t2, t2, s0\ns0 must be produced before it can\nbe used\nData hazards \u2013 What can I do???\n\u25cf Are these common?\no Yup! You bet!\ni=i+1\narray[i]\n\u25cf Solution 1: Stall until value is written back to the register file\no Penalty is high with this solution.\n20\nTime 0 1 2 3 4 5 6 7\nadd s0,t0,t1\nsub t2,t2,s0\nMem Reg Reg\nNOP NOP Mem Reg Reg\nData hazards \u2013 What can I do???\n\u25cf Solution 2: What if we improve the register file?\n21\nTime 0 1 2 3 4 5 6 7\nadd s0,t0,t1\nsub t2,t2,s0\nMem Reg Reg\nNOP Mem Reg Reg\nRegister\nFile\nRead register during\nthe second half\nWrite to the register on\nthe falling edge\nR\nW\nData hazards \u2013 What can I do???\n\u25cf Solution 3: Can we forward the ALU output?\no Add path from ALU output to one of its inputs\n22\nTime 0 1 2 3 4 5 6 7\nadd s0,t0,t1\nsub t2,t2,s0\nMem Reg Reg\nMem Reg Reg\nThe value needed by the\nsub isn\u2019t read from the reg\nfile - it comes directly from\nthe result output from\ndoing the add operation\nForwarding: Passing the result from a\nlater stage to an earlier one\nControl hazards\nAttempting to make a decision before condition is evaluated\n\u25cf If the dirty clothes are not clean after washing!\n\u25cf Then I must wash them again\nIn a CPU:\n\u25cf Branches\n23\nblt s0, s1, DONE\n add t0, t1, t2\n or t0, t1, t2\nDONE:\n sub t0, t1, t2\nWhich path will the\nprogram take?\nWhich instruction do\nwe fetch next?\nControl hazards\nAttempting to make a decision before condition is evaluated\n\u25cf If the dirty clothes are not clean after washing!\n\u25cf Then I must wash them again\nIn a CPU:\n\u25cf Branches\n24\nif s0 < s1 goto DONE\n add t0, t1, t2\n or t0, t1, t2\nDONE:\n sub t0, t1, t2\nWhich path will the\nprogram take?\nWhich instruction do\nwe fetch next?\nTime 0 1 2 3 4 5 6 7\nControl hazards \u2013 What can I do???\n\u25cf We can stall\u2026 until the outcome is known!\n25\nblt s0,s1,DONE\nsub t0,t1,t2\n\u25cf This is a bit wasteful! We really don\u2019t like stalls! J\n\u25cf We want the pipeline always full and doing useful work!\nMem Reg\nNOP NOP Mem Reg Reg\nTime 0 1 2 3 4 5 6 7\nControl hazards \u2013 What can I do???\n\u25cf Sooo\u2026 we can predict that the branch is never taken! (na\u00efve)\n26\nblt s0,s1,DONE\nadd t0,t1,t2\n\u25cf We attempt to execute the next sequential instruction!\n\u25cf It is a gamble! that the branch will never be taken.\n\u25cf But if we are right, there is no stall!!! J\nMem Reg\nMem Reg Reg\nTime 0 1 2 3 4 5 6 7\nControl hazards \u2013 What if we are wrong?????!!!\n\u25cf Ok, what if we are wrong???!!\n27\nblt s0,s1,DONE\nadd t0,t1,t2\nor t0,t1,t2\nsub t0,t1,t2\n\u25cf Just abort (stall the remaining steps) to fix it! Nothing was actually changed!\n\u25cf Read the correct instruction!\nMem Reg\nMem\nMem Reg Reg\nReg NOP NOP\nMem NOP NOP NOP\nFun facts!\n\u25cf How often do you think a (less-na\u00efve) branch predictor is correct?\n28\nUsing 128 Bytes all these predictors\nhave an accuracy of >90%!!!\nMcFarling, Scott. Combining branch predictors. Vol. 49. Technical\nReport TN-36, Digital Western Research Laboratory, 1993.\nWhat to know more?\n\u25cf CS 1541 \u2013 Introduction to Computer Architecture\no Learn more about hazards.\no Learn more about branch predictors.\no Learn about memory hierarchies.\no And more\u2026\n29\nPerformance and\nThe Law of Diminishing Returns\n30\nDon't waste your time...\n\u25cf suppose you're trying to get better at time management\n\u25cf you got an app that lets you time how long you do stuff\n31\nWatching\nYoutube\nWorking\nMeals\nCommuting\nHygiene\nif you wanted to get\nmore free time by\nhalving the amount of\ntime it takes to do one\ntask, which task would\nyou choose?\nIf you cut Youtube by half...\n\u25cf look at all the extra free time you have!\n32\nWatching\nYoutube\nWorking\nMeals\nCommuting\nHygiene\nFree time!\nIf you cut commuting by half...\n\u25cf look at ... all the extra free time... you have.\n33\nWatching\nYoutube\nWorking\nMeals\nCommuting\nHygieneFree time!\nThe tale of two multipliers\n\u25cf The tale starts with a simple program\n\u25cf How many times does the loop execute?\n34\nli $1, 100\nL0:\nlw $2, A[i] ; pseudo-code to load A[i]\nlw $3, B[i] ; pseudo-code to load B[i]\nmult $3, $2\nmflo $4\nsw $4, C[i] ; pseudo-code to store C[i]\naddi $1, $1, -1\nbne $1, $0, L0\nRuns 100 times\nThe tale of two multipliers\n\u25cf You measure how long it takes to execute.\no It took 102010ns\n35\nli $1, 100\nL0:\nlw $2, A[i]\nlw $3, B[i]\nmult $3, $2\nmflo $4\nsw $4, C[i]\naddi $1, $1, -1\nbne $1, $0, L0\nThat\u2019s too long!\n10ns\n10ns\n10ns\n960ns\n10ns\n10ns\n10ns\n10ns\nI need to improve this,\nwhat should I do?\nLet me check what is\ngoing on here!\n\ufffd\ufffd\ufffd\ufffd = 1\u00d710\ufffd\ufffd +\n6\u00d7100\u00d710\ufffd\ufffd +\n1\u00d7100\u00d7960\ufffd\ufffd = 102010\ufffd\ufffd\n96000ns!!!\nThe tale of two multipliers\n\u25cf It seems this CPU implements a slow multiplier\no It needs to execute 3 distinct steps:\n(1) add, (2) shift left, and (3) shift right\no Multiplication takes 32-bit numbers\n\u00a7 The ALU and the adder are 64-bits!\no The 64-bit addition takes 10ns\no Shifts also take 10ns\no The multiplication takes 96 steps \u00e0 3\u00d732bits\n\u00a7 total = 96 steps\u00d710\ufffd\ufffd = 960\ufffd\ufffd\n36\nWhat if I used another\nmultiplier design?\nThe tale of two multipliers\n\u25cf I know, let\u2019s use a Fast multiplier design I have\n1. It combines some registers\n2. And we can make it do the 3 steps simultaneously\n3. And the ALU only needs\no Assuming a linear relationship between bits and adder speed:\n\u00a7 The 32-bit addition takes 5ns\no The multiplication takes 32 steps \u00e0 1(\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd)\u00d732bits\n\u00a7 total = 32 steps\u00d75\ufffd\ufffd = 160\ufffd\ufffd\n37\nCool! That\u2019s a lot\nfaster!!\nThe tale of two multipliers\n\u25cf Let\u2019s calculate how much faster it is:\no Let\u2019s calculate the speedup ratio:\n\u00a7 The factor by which the new version is faster than the old one\nspeedup =\nslow multiplier time\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\n=\n960\ufffd\ufffd\n160\ufffd\ufffd\n= 6\u00d7\n38\nBut will the program\nimprove that much?\nThe tale of two multipliers\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd =\nslow program\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n=\n102010\ufffd\ufffd\n22010\ufffd\ufffd\n= \ufffd. \ufffd\ufffd\u00d7\n39\nIt still an improvement!\nBut not 6x. Why?\n\ufffd\ufffd\ufffd\ufffd = 1\u00d710\ufffd\ufffd +\n6\u00d7100\u00d710\ufffd\ufffd +\n1\u00d7100\u00d7160\ufffd\ufffd = 22010\ufffd\ufffd\n\u25cf The multiplier is only used once!\nThe tale of two multipliers\n\u25cf What happens if we decrease the proportion of execution time?\n40\nSuppose 101 instructions: 100 non-multiply, 1 multiply\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd = 100\u00d710\ufffd\ufffd + 960\ufffd\ufffd = 1960\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd = 100\u00d710\ufffd\ufffd + 160\ufffd\ufffd = 1160\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd =\n1960\ufffd\ufffd\n1160\ufffd\ufffd\n= 1.7\u00d7\nSuppose 1001 instructions: 1000 non-multiply, 1 multiply\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd = 1000\u00d710\ufffd\ufffd + 960\ufffd\ufffd = 10960\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd = 1000\u00d710\ufffd\ufffd + 160\ufffd\ufffd = 10160\ufffd\ufffd\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd =\n10960\ufffd\ufffd\n10160\ufffd\ufffd\n= 1.08\u00d7\nDecreasing gains\n\u25cf 6\u00d7\u2192 4.63\u00d7\u2192 1.7\u00d7\u2192 1.08\u00d7\n\u25cf What happened?\no Proportion of time spent multiplying was not enough to have gains\n\u25cf Optimization is a balancing act.\no As you solve a bottleneck, a new one will appear.\no Improve things to a point, then there are diminishing returns!\n41\n5s 4s 3s\n2s 4s 3s\n2s 3s 3s\nWhat about pipelining?\n\u25cf How much faster (and why) is a pipelined implementation of MIPS?\n\u25cf As we saw last class, we compute the speedup for this:\nspeedup =\nslow time\n\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\n\u25cf And how do we compute \u201ctime\u201d?\nCPU time = \ufffd\u00d7 \ufffd\ufffd\ufffd\u00d7\ufffd seconds\n42\nAverage Instruction CPI\n\u25cf What is an \u201caverage instruction\u201d CPI?\no Remember how we calculated the average CPI of a program?\n\u25cf Given a program, how many cycles does an instruction typically take?\no It depends on the program!\no How many instructions, and what types?\n\u00a7 E.g.: all adds vs. all loads for multi-cycle implementation\n\u25cf The average instruction CPI is the average cycle count per instruction\n43\nInstruction Mix\n\u25cf Instruction mix: Is the % total instruction count (n) corresponding to each\ninstruction class\n\u25cf Program A: 100 adds, 100 subtracts, 50 loads, 25 stores, 50 branches, and 10\njumps. Total 335 instructions.\n\u25cf What is the mix?\n44\nArithmetic (100+100) / 335 = 0.597 = 59.7%\nLoad 50 / 335 = 0.149 = 14.9%\nStore 25/335 = 0.075 = 7.5%\nBranch 50/335 = 0.149 = 14.9%\nJump 10/335 = 0.03 = 3.0%\nCPI \u2013 Multi-cycle\n\u25cf Given this mix, what is the Average Cycles Per Instruction (CPI)?\no E.g., with a multi-cycle CPU.\n\u25cf We compute the weighted average\nCPI= \u03a3:;; <;:==>= \ufffd\ufffd\ufffd\ufffd\u00d7\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n45\nClass Frequency Cycles\nArithmetic 59.7% 4\nLoad 14.9% 5\nStore 7.5% 4\nBranch 14.9% 3\nJump 3.0% 3\nContribution\n2.388\n0.745\n0.3\n0.447\n0.09\nTotal 3.97 CPI\nCPU time\n\u25cf And now we can calculate the CPU time\no Assuming a cycle length of 2ns\nCPU time = 335\u00d73.97\u00d72\ufffd\ufffd\n= 2660\ufffd\ufffd\n46\nClass Frequency Cycles\nArithmetic 59.7% 4\nLoad 14.9% 5\nStore 7.5% 4\nBranch 14.9% 3\nJump 3.0% 3\nContribution\n2.388\n0.745\n0.3\n0.447\n0.09\nTotal 3.97 CPI\nWhat about in the pipeline implementation?\n\u25cf In the best case, what is the CPI?\no How many instructions are we starting every clock cycle?\n\u25cf What about the typical case, what is the CPI?\no We have to consider hazards.\no Say, 20% of branches are predicted correctly.\no 60% of loads do not conflict with other memory accesses.\n\u25cf Assume the same program and clock cycle.\n47\nInstruction Mix \u2013 Pipeline\n\u25cf Instruction mix: Treat the delayed load and branch instructions as a separate\nclass\n48\nClass Frequency Cycles\nArithmetic 59.7% 1\nLoad \u2013 no delay 0.6*14.9%=8.94% 1\nLoad \u2013 delay 5.96% 2\nStore 7.5% 1\nBranch predicted 0.2*14.9%=2.98% 1\nBranch not predicted 11.92% 3\nJump 3.0% 1\nCPI \u2013 Pipeline\n\u25cf We compute the weighted average\nCPI= \u03a3:;; <;:==>= \ufffd\ufffd\ufffd\ufffd\u00d7\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\n49\nClass Frequency Cycles\nArithmetic 59.7% 1\nLoad \u2013 no delay 0.6*14.9%=8.94% 1\nLoad \u2013 delay 5.96% 2\nStore 7.5% 1\nBranch predicted 0.2*14.9%=2.98% 1\nBranch not predicted 11.92% 3\nJump 3.0% 1\nContribution\n0.597\n0.0894\n0.1192\n.075\n.0298\n0.3576\n0.03\nTotal 1.30 CPI\nThe speedup\n\u25cf Compute CPU execution time of pipelined implementation\no Every value except CPI is the same as in the multi-cycle\n\u00a7 n \u2013 is a property of the program\nPipeline\tCPU\ttime\t=\t335\u00d71.30\u00d72\ufffd\ufffd\n= 871\ufffd\ufffd\nspeedup =\n2660\ufffd\ufffd\n871\ufffd\ufffd\n= 3.05\u00d7"
        },
        {
            "lecture": 21,
            "content": "Finite State Machines\n2\nWhat's an FSM?\n\u25cf A Finite State Machine is a machine with a finite number of states.\no :\u2019)\n\u25cf A Finite State Machine is a way of thinking about a process where:\no there is a series of inputs\no we need to produce a series of outputs\no the state stores some information\no the inputs can change the state and the outputs\n\u25cf FSMs come up all the time in programming and hardware design\n\u25cf They're great for controlling simple multiple-step procedures\n3\nA very simple example\n\u25cf what states can a ceiling fan be in?\no high, medium, low, and off\n\u25cf what are the input and output?\no the chain and the motor\n\u25cf when you pull the chain, it changes state\n4\noff high med low\npull pull pull\npull\nMissing some arrows\n\u25cf at any point in time, which of 2 choices can the input (chain) be?\no pulled or not-pulled\n\u25cf when you don't pull the chain, what happens?\n5\noff high med low\npull pull pull\npull\nno\npull\nno\npull\nno\npull\nno\npull\nthis is the state transition diagram\nThe state transition table - Table-a-fyin\u2019 it\n\u25cf we can represent this diagram with a truth table\n6\noff high med low\npull pull pull\nno pull pull\nno\npull\nno\npull\nno\npull\nS In Snext\noff\noff\nhigh\nhigh\nmed\nmed\nlow\nlow\nno pull\npull\nno pull\npull\nno pull\npull\nno pull\npull\noff\nhigh\nhigh\nmed\nmed\nlow\nlow\noff\nThe state transition table - Table-a-fyin\u2019 it\n\u25cf we can represent this diagram with a truth table\n\u25cf we have 4 states. how many bits\nare needed to represent 4 values?\n7\noff high med low\npull pull pull\nno pull pull\nno\npull\nno\npull\nno\npull\nS In Snext\n00 0 00\n00 1 01\n01 0 01\n01 1 10\n10 0 10\n10 1 11\n11 0 11\n11 1 00\nfor the state, let's say:\noff means 00\nhigh means 01\nmed means 10\nlow means 11\noff\noff\nhigh\nhigh\nmed\nmed\nlow\nlow\nno pull\npull\nno pull\npull\nno pull\npull\nno pull\npull\noff\nhigh\nhigh\nmed\nmed\nlow\nlow\noff\nThe state transition table - Table-a-fyin\u2019 it\n\u25cf we can represent this diagram with a truth table\n\u25cf we have 4 states. how many bits\nare needed to represent 4 values?\n8\noff high med low\npull pull pull\nno pull pull\nno\npull\nno\npull\nno\npull\nS In Snext\n00 0 00\n00 1 01\n01 0 01\n01 1 10\n10 0 10\n10 1 11\n11 0 11\n11 1 00\nfor the input, let's say:\n0 means not pulling\n1 means pulling\nno pull\npull\nno pull\npull\nno pull\npull\nno pull\npull\nThe state transition table - Table-a-fyin\u2019 it\n\u25cf we can represent this diagram with a truth table\n\u25cf we have 4 states. how many bits\nare needed to represent 4 values?\n9\noff high med low\n1 1 1\n0 1\n0 0 0\nS In Snext\n00 0 00\n00 1 01\n01 0 01\n01 1 10\n10 0 10\n10 1 11\n11 0 11\n11 1 00\nfor the input, let's say:\n0 means not pulling\n1 means pulling\n10\nIt\u2019s a UNIX system truth table, I know this!\n*it\u2019s a Silicon Graphics IRIX, which counts\u2026 kinda\nImage from Jurassic Park (1993), distributed by Universal Pictures\nTruth tables with multiple output bits\n\u25cf there's no tricky stuff here \u2013 each output bit is its own expression\n11\nS In Snext\n00 0 00\n00 1 01\n01 0 01\n01 1 10\n10 0 10\n10 1 11\n11 0 11\n11 1 00\nS1 S0 In Snext1\n0 0 0 0\n0 0 1 0\n0 1 0 0\n0 1 1 1\n1 0 0 1\n1 0 1 1\n1 1 0 1\n1 1 1 0\nS1 S0 In Snext0\n0 0 0 0\n0 0 1 1\n0 1 0 1\n0 1 1 0\n1 0 0 0\n1 0 1 1\n1 1 0 1\n1 1 1 0\nWhat about the outputs\n\u25cf our fan controller has to control the motor after all\n\u25cf we can make a table showing the output(s) for each state\n12\nState\noff\nhigh\nmed\nlow\nMotor power Output\n0% 00\n100% 11\n50% 10\n25% 01\nnote that the\ninput isn't\ninvolved at all\nthe outputs\nonly have to\ndepend on the\ncurrent state!\nAssume this is\nhow you\ncontrol the\nmotor\nRepresenting the output\n\u25cf We can represent the output in the state machine!\n13\noff\n[00]\nhigh\n[11]\nmed\n[10]\nlow\n[01]\n1 1 1\n0 1\n0 0 0\nS Output\n00 00\n01 11\n10 10\n11 01\nMaking a circuit out of it\n\u25cf This is a sequential circuit \u2013 the state changes over time\n\u25cf But the state transition and output tables are just combinational\n\u25cf Here's the general organization of any Moore FSM circuit:\n14\nD Q\nstate\nregister\ntransition\nlogic\ninputs\noutput\nlogic\noutputs\nstate feeds back into transition logic outputs based\non state\nHow to create a state machine?\n\u25cf Understand the problem\n\u25cf Represent all possible states and transitions\n\u25cf Encode the states\n\u25cf Implement the machine\n15\nUnderstanding the problem\nA problem:\n\u25cf You have an espresso machine\no Each espresso costs 15c <3\no The machine takes:\n\u00a7 5c - (N)ickels\n\u00a7 10c - (D)imes\no No change is given back!"
        },
        {
            "lecture": 20,
            "content": "Multicycle\n2\nMulticycle Design\n\u25cf Simply put: let instructions take more than one clock cycle to complete.\n3\nSingle-cycle\nMulticycle?\nPHOTO: https://www.straitstimes.com/asia/east-asia/china-scrambles-to-tame-rental-bike-chaos\nChop chop\n\u25cf Not all instructions take the same amount of time, so\u2026\n\u25cf Make different instructions take different amounts of time!\no And by that, we mean different numbers of clock cycles\n4\nj\nor\nlw\nj j\nor or or or\nlw lw lw lw lw lw lw lw lw lw lw lw l3 cycles\n4 cycles\n100 cycles\nThe instructions' steps\n\u25cf Why would some instructions take less time?\n\u25cf Recall the five phases of execution?\n\u25cf All instructions have IF, ID, EX, but only some write to memory/regs\no We\u2019re managing their complexity with respect to time.\n5\nbeq/j F D X\nadd/sub etc. F D X W\nlw F D X M M \u2026\u2026.. M M W\nMemory is slooooooow\nThe instructions' steps\n\u25cf Why would some instructions take less time?\n\u25cf Recall the five phases of execution?\n\u25cf All instructions have IF, ID, EX, but only some write to memory/regs\no We\u2019re managing their complexity with respect to time.\n6\nIF ID EX\nIF ID EX WB\nIF ID EX M WB\nbeq/j\nadd/sub etc.\nlw\n(let's just say lw is 5 cycles :)\nMulti-cycle CPU\nCalculate clock to accommodate a single phase.\n\u25cf Chop instructions and make the clock faster\n\u25cf Less time wasted by faster instructions! \u00e0 Reduces latency\n7\nTime 0 1 2 3 4 5 6 7 8\nlw t0,0(t1)\nadd t2,t2,t3\nMem Reg Mem Reg\nMem Reg Reg\nNot all stages are the same L\n8\nIn the multi-cycle design:\n Slowest stage limits the rate\nBalanced stages are desired\nTime 0 1 2 3 4\nlw t0,0(t1)\nMem Reg Mem Reg\nE.g. split the memory operation into multiple clock cycles\nMem Reg Mem Reg\nThe multicycle datapath from a bird's-eye view\n\u25cf Each phase of execution has its own functional unit\n\u25cf between phases, we insert registers to hold onto the data for the next phase.\n(Recall registers \u00e8 sequential logic)\n9\nInstruction\nMemory\nF\nControl\nRegister\nFile\nD X\nData\nMemory\nM\nW\nWatching an add (animated)\n\u25cf Let's watch an add instruction flow through the datapath!\n10\nInstruction\nMemory\nF\nControl\nRegister\nFile\nD X\nData\nMemory\nM\nW\nadd\nset all control\nsignals...\nClock! Clock!\nadd...\nClock!\nClock!\ndata flows back to registers...\nWatching a lw (animated)\n\u25cf Let's watch a lw instruction flow through the datapath!\n11\nInstruction\nMemory\nF\nControl\nRegister\nFile\nD X\nData\nMemory\nM\nW\nlw\nset all control\nsignals...\nClock! Clock!\nadd...\nClock! Clock!\ndata flows back to registers...\nload...\nCPI (and IPC)\n\u25cf CPI (Cycles Per Instruction) measures the average number of cycles it takes\nto complete one instruction\n\u25cf IPC (instructions per cycle) is its reciprocal\no multi-issue CPUs can execute multiple instructions in one clock cycle!\nWOAH 8O\n\u25cf So, what's the CPI for the single-cycle implementation?\no uh, 1.\no By, yanno, definition.\n\u25cf What about for a multicycle implementation?\no \u2026\u2026????? hmmm\n12\nSo what the heck has this bought us?\n\u25cf Let's say our clock cycle time decreased from 5ns to 1ns!\no that's from 200 MHz to 1 GHz! :D\n\u25cf ...buuut our CPI (cycles per instruction) increased a lot.\no with the single-cycle datapath, CPI was always 1.\no now the CPI is... well... uh... variable?\n13\nIF ID EX\nIF ID EX WB\nIF ID EX M WB\nbeq/j\nadd/sub etc.\nlw\nif instructions vary in length,\nhow do we calculate CPI?\nCalculating Average CPI\n\u25cf Every program is different, and every program has a different instruction\nmix \u2013 how many of each kind of instruction it uses\n\u25cf Let's say we have a program where 60% of the instructions are ALU, 20% are\nbranches, 15% are loads, and 5% are stores.\n14\nALU Branches Loads Stores\n% 60% 20% 15% 5%\nCycles 4 3 5 4\nCPI\n1. for each category, multiply the proportion\n(percentage) by the number of cycles for that\ncategory to get the per-category CPI\n2.4 0.6 0.75 0.2\n2. Now sum\nthe CPIs\n= 3.95\nthis is the Average\nCPI for THIS program.\ndifferent mixes give\ndifferent CPIs!\n+ + +\nThe performance equation\n\u25cf If we have n instructions, and each instruction takes CPI cycles, and each\ncycle takes t seconds, how long does it take to execute all the instructions?\n15\nTotal time = \ufffd instructions\u00d7\n\ufffd\ufffd\ufffd cycles\ninstruction\n\u00d7\n\ufffd seconds\ncycle\n= \ufffd\u00d7\ufffd\ufffd\ufffd\u00d7\ufffd seconds\nor in English, it's the product of the instruction count, the\nCPI, and the length of one clock cycle\nSo how much better is it?!??!?\n\u25cf Say we execute 500 mega (500 \u00d7 106) instructions\n\u25cf For the single-cycle datapath:\no CPI = 1\no cycle time = 5ns (5 x 10-9 s)\no total time = n \u00d7 CPI \u00d7 cycle time\n\u00a7 = (500 \u00d7 106) \u00d7 (1) \u00d7 (5 \u00d7 10-9)\n\u00a7 = 2.5 seconds.\n\u25cf For the multicycle datapath:\no CPI = 3.95 (much higher!) (again, this CPI is only for this program)\no cycle time = 1ns (much lower!)\no total time = (500 \u00d7 106) \u00d7 (3.95) \u00d7 (1 \u00d7 10-9)\no = 1.975 seconds!\n16\nHow does it look like?\n17\nMulticycle Datapath + Control (no control flow)\n\u25cf A potential example of a multicycle control for MIPS:\no Additional registers and multiplexers hold and then direct temporary data.\n18 Figure 5.26 in P&H 3e\nA single Shared Memory A single ALU\nMulticycle Datapath + Control (no control flow)\n\u25cf A potential example of a multicycle control for MIPS:\no Additional registers and multiplexers hold and then direct temporary data.\n19 Figure 5.26 in P&H 3e\nRegisters are added between\nfunctional units to store data\nThat needs to be used in the\nfollowing clock cycle\nMulticycle Datapath + Control (no control flow)\n\u25cf A potential example of a multicycle control for MIPS:\no Additional registers and multiplexers hold and then direct temporary data.\n20 Figure 5.26 in P&H 3e\nUsing a single ALU requires a\nchange in the hardware\ndesign.\nA MUX to connect either\nthe PC or the Register File\nA larger MUX to include PC\nincrement and adding\nthe branch offsets\nMulticycle Datapath + Control (with control flow)\n21\nNow we support\njump instructions J\nFigure 5.28 in P&H 3e\nMulticycle Datapath + Control (with control flow)\n22 Figure 5.28 in P&H 3e\nSignals\nSignal Effect\nMemRead Read from memory \u00e8 0: Don\u2019t read; 1: Read\nMemWrite Write to memory \u00e8 0: Don\u2019t write; 1: Write\nALUSelA Select input of ALU input A \u00e8 0: $pc ; 1: register A\nRegDst Select destination register \u00e8 0: $rt (I-Type); 1: $rd (R-Type)\nRegWrite Register-file write enable \u00e8 0: Don\u2019t write; 1: Write\nMemToReg Select data to write to the register-file\u00e8 0: ALU; 1: Memory\nIorD Select the source for the memory address to be accessed \u00e8 0: PC (instruction);\n1: ALU (lw/sw/lh/lhu/sh/lb/lbu/sb)\nIRWrite Instruction register write enable \u00e8 0: Don\u2019t write; 1: Write\nPCWrite PC unconditional write enable (jumps/PC=PC+4) \u00e8 0: No effect; 1: Jump\nPCWriteCond PC conditional write enable (branches) \u00e8 0: No effect; 1: Jump conditionally\n23\n(More) signals\nSignal Effect\nALUSelB 00 ALU input B comes from $rt\n01 ALU input B is the constant 4\n10 ALU input B comes from the Immediate field\n11 ALU input B comes from the Immediate field shifted left 2 (branch)\nALUOp 00 ALU does an addition\n01 ALU does an subtraction\n10 ALU behaviour depends on the function field (R-Type)\nPCSource 00 PC is updated with the result of the ALU (Fetch: PC+4)\n01 PC is updated with the result of the ALU (PC = PC + branch offset)\n10 PC is updated with the Jump target (jump)\n24\nFetch and decode\n25\nFetch Instruction\n26\n00\n01\n00\nIncrement PC\nRead instruction\nfrom memory\nDecode Instruction\n27\n00\n11\n00\nMaybe it\u2019s\na branch?\nALU adds PC (incremented in IF)\nto potential branch offset.\nJust in case!\nController does its thing\nR-Type\n28\nExecute Instruction\n29\n10\n00\n00\nadd s0, s1, s2\nALU adds\nregisters A and B\nWrite Back\n30\n00\n00\n00\nadd s0, s1, s2\nALU result is written\nback into the\nRegister File\nI-Type\nlw\n31\nExecute Instruction\n32\n00\n10\n00\nlw s0, 4(s1)\nALU adds registers A\nand Imm to calculate\neffective address\nMemory access\n33\n00\n00\n00\nlw s0, 4(s1)\nALU result is used\nas the address.\nMemory is read.\nWrite back\n34\n00\n00\n00\nlw s0, 4(s1)\nData read from memory\nis written into the\nRegister File\nI\n-Type\nbeq\n35\nExecute Instruction \u2013 Branch conclusion\n36\n01\n00\n01\nbeq s0, s1, label\nALU subtracts registers\nA and B if the result is\nzero, then branch\nJ-Type\njump\n37\nExecute Instruction \u2013 Jump\n38\n00\n00\n10\nj target\nJump\nMulticycle Control\n\u25cf How are control signals generated on each cycle?\no Single-cycle: Signals don\u2019t change during each instruction\n\u00a7 Combinational circuit\no Multi-cycle: Signals change during each instruction\n\u00a7 Different signals each clock cycle\nSequential circuit \u00e0 Needs to remember what it did before\n\u25cf What are the transitions between cycles?\no (i.e., what happens next?)\n\u25cf How to describe this behaviour?\no State machine!\n39\nFinite-State Machines\n40\nSingle-cycle\n41\nopcode\noutput\nlogic\nRegWrite\nMem2Reg\nALUSrc\n\u2026.\nTick-tock\n42\nD Q\nstate\nregister\ntransition\nlogic\nopcode\noutput\nlogic\nRegWrite\nIRWrite\nALUSrcA\n\u2026.\nMulticycle Control\n43\nFETCH\nDECODE\n/ REG.\nREAD\nEXEC.\nALU\nBRANCH\nCOMPL.\nJUMP\nCOMPL.\nCALC.\nADDR.\nREAD\nMEM\nWRITE\nMEM\nWRITE\nBACK\nALU\nWRITE\nBACK\nMEM\nFinite State Machine\nEach Cycle: Advance one state\nWhilst in a State:\n\u2022 Set datapath control\n\u2022 Make decision based on opcode\n\u2022 Control is different after Decode\nbranch jump\nload/store R-Type\nstore\nload\nMIPS has >100 instructions\nSome can take >20 clock cycles!!\nMaking the state machine a bit more complex J\nPerformance\n44\nThe layman's understanding\n\u25cf your ancient computer takes 30 seconds to open the browser\n\u25cf you get a new computer. it opens the browser in 3 seconds.\no which computer is faster?\n45\nyeah but this is computer science, not computer guessing.\nOld stuff!!\n\u25cf you wanna copy a CD as many times as you can in 12 minutes\n\u25cf both the PC and this... thing take 4 minutes to copy\n\u25cf which device will make more copies in 12 minutes? why?\no numbers usually mean we're getting more science-y, right?\n46\n\u25cf response time is the length of time from start to finish\n\u25cf throughput is the amount of work you can do in a span of time\n47\nResponse time and throughput\n30 seconds\n3s\nresponse time\n(time per task)\nthroughput\n(tasks per time)\n12 minutes\nthey're not quite\nreciprocals of each\nother; their\nrelationship is a\nlittle more complex\nResponse time can improve throughput!\n\u25cf you put a brand new 52X CD burner in your sweet Dell. it burns a CD in only\n2 minutes.\n48\n4min 4min 4min\n2min 2min 2min 2min 2min 2min\n\u25cf the response time for a single CD burn is improved, but this also\ncauses our throughput to double!\n\u25cf this is because the measurement period stayed the same (12min)\n4min\n4min\n4min\n4min\n4min\n4min\n4min\n4min\nThroughput can improve response time!\n\u25cf someone wants you to make them 20 copies ASAP\n\u25cf how long would it take with one CD duplicator?\n\u25cf how long would it take with two?\n49\nwith one:\n20min\nwith two:\n12min\n4min\n4min\n4min\n4min\n4min\n4min\n4min\n4min\n4min\n4min\n4min\n4min\n4min\n4min\n4min\n4min\n4min\n4min\n4min\n4min\nthis is because the\nworkload stayed the\nsame (20 copies)\nApplying it to a CPU\n\u25cf the CPU's job is to run instructions. so we could\u2026\no do each instruction faster (i.e. reduce latency)\no do more instructions at once (i.e. increase throughput)\n\u25cf for a long time, we did the former\u2026\no clock speeds increased by 2 orders of magnitude since ~1990\n\u00a7 I had a 33MHz! 80486 PC\n\u25cf but then we hit a wall.\no and that's when multi-core CPUs became common.\n50\nReducing latency\n\u25cf you put a new Pentium 4 in your sweet Dell. it executes a single instruction in\nonly 0.8 nanoseconds.\n51\n1.6ns 1.6ns 1.6ns\n.8ns .8ns .8ns .8ns .8ns .8ns\nif each instruction takes only\n0.8ns, that means 0.8ns between\nclock pulses. How fast is the\nclock running?\n1\n0.8\u00d710!\"\ufffd\n= 1.25\u00d710\"\ufffd\ufffd\n= 1.25 \ufffd\ufffd\ufffd\nReal-World Analysis\n52\nAnother example\n.data\nA: .word 10,20,30,40,50,60,70,80,90,100\nB: .word 0,0,0,0,0,0,0,0,0,0\n.text\nla $s0,A # address of A\nli $s1,10 # A[i] * 10\nli $s2,10 # iteration\nloop: lw $t0,0($s0) # read A[i]\nmul $t0,$t0,$s1 # $t0=A[i]*10\nsw $t0,40($s0) # update A[i]\naddi $s0,$s0,4 # next element\naddi $s2,$s2,-1 # dec iteration\nbne $s2,$0,loop # done?\nli $v0,10 # exit syscall\nsyscall # syscall\n53\nAnother example\n.data\nA: .word 10,20,30,40,50,60,70,80,90,100\nB: .word 0,0,0,0,0,0,0,0,0,0\n.text # instr. count\nla $s0,A # address of A 2\nli $s1,10 # A[i] * 10 1\nli $s2,10 # iteration 1\nloop: lw $t0,0($s0) # read A[i] 10\nmul $t0,$t0,$s1 # $t0=A[i]*10 10\nsw $t0,40($s0) # update A[i] 10\naddi $s0,$s0,4 # next element 10\naddi $s2,$s2,-1 # dec iteration 10\nbne $s2,$0,loop # done? 10\nli $v0,10 # exit syscall 1\nsyscall # syscall 1\n54\nAnother example\n\u25cf Let\u2019s analyze the program.\n\u25cf How much time with a Single-Cycle design?\n1. What\u2019s the clock length?\n\u00a7 Assume a clock speed of 100 MHz (cycle length is 1/100MHz, or 10ns)\n2. What\u2019s the cycles per instruction?\n\u00a7 CPI: 1 (single-cycle! yay!)\n\u25cf Thus this program executes in this much time:\no 66 instructions * 1 CPI * 10 ns = 660ns\n55\nAnother example\n\u25cf How much time with a Multicycle design?\n1. We need to know the clock length (what is the clock speed?)\n Let\u2019s just assume the ideal efficiency: divide the clock length by 5.\n\u00a7 (Because we said loads, the slowest, take 5 cycles while arithmetic takes 4)\n\u00a7 AKA multiply the clock speed by 5 to 500 MHz\n\u00a7 Either way, the clock length is 10ns / 5 = 2ns\n2. What\u2019s the CPI?\n\u00a7 We need to know how many of each type there are. Look at the program.\n\u00a7 Arithmetic: 36, Branches: 10, Loads: 10, Stores: 10\n\u00a7 There\u2019s a different # of cycles per each type (4, 3, 5, and 4 respectively)\n\u25cf Thus this program executes in this much time:\no 36*4*2ns + 10*3*2ns + 10*5*2ns + 10*4*2ns = 528ns\n\u25cf Multicycle, here, let\u2019s us improve our program execution\nfrom 660ns to 528ns (20% reduction!)\n56\nBut is this efficient?\n57\nR\ne\ng\ni\ns\nt\ne\nr\ns\nMulti-cycle lw (animated)\n\u25cf Let's watch a lw instruction flow through the datapath!\n58\nR\ne\ng\ni\ns\nt\ne\nr\ns\nR\ne\ng\ni\ns\nt\ne\nr\ns\nR\ne\ng\ni\ns\nt\ne\nr\ns\nInstruction\nMemory\nF\nControl\nRegister\nFile\nD X\nData\nMemory\nM\nW\nlw\nset all control\nsignals...\nClock! Clock!\nCalculate\neff addr...\nClock! Clock!\ndata flows back to registers...\nload...\nClock count: 3 Clock count: 5 Clock count: 0 Clock count: 1 Clock count: 2 Clock count: 4\ndoo-doo-doo doo-doo-doo-doo-doo\n\u25cf not bad! I guess?\nI mean, we increased the clock speed by a factor of 5...\nand we only got 20% reduction on execution time\nif our CPI were also close to 1, it'd be 10 times as fast as the single-cycle\nmachine...\n\u00a7 How do we increase throughput\u2026\n\u00a7 HMMMMMMMMMMMMMMMMMMMMMM\u2026"
        }
    ],
    "extra": [
        {
            "content": "MIPS <=> C correspondences\n\nIt's all mechanical.\n\nCompilers take high-level code like C and turn it into machine code. MIPS was designed to be easy for compilers to generate code for.\n\nYou can learn the same rules that compilers use to turn any high-level pseudocode into MIPS just by following some commonly-seen BRAIN ALGORITHMS.\n\nControl flow\n\nVariables\n\nData types\n\n1D Arrays\n\nFunction calls\n\nStructs\n\nVariables\n\nAssuming you have some global variables like this:\n\n.data \n    x: .word 10\n    y: .word 30\n    text: .byte 30\ncontent_copy\n\nC\nDescription\tC\tMIPS\tNotes\nGet value\tx\tlw t0, x\tThe type of load instruction must match the type of variable. Also, here you decide whether they're signed.\nSet value\tx = 10\tli t0, 10 <br> sw t0, x\tThe type of store instruction must match the variable type.\nRead-modify-write\tx++\tlw t0, x <br> addi t0, t0, 1 <br> sw t0, x\tCombine the above two.\nCopy variable\tx = y\tlw t0, y <br> sw t0, x\tSame idea.\nControl flow\nwhile(true) and do-while\n\nThe easiest kinds of loops.\n\nDescription\tC\tMIPS\tNotes\nInfinite loop\twhile(true) { <br> code <br> }\t_loop: <br> code <br> j _loop\tTo break, go to a label after the infinite loop.\ndo-while\tdo { <br> code <br> } while(i < 10);\t_loop: <br> code <br> blt t9, t0, _loop <br> j _loop_top\tLike an if at the end, but the condition is reversed. The condition is normal.\n\nThese two are similar, but you have to flip the conditions.\n\nif and while with conditions\nDescription\tC\tMIPS\tNotes\nsimple if\tif (t0 == 10) { <br> then code <br> }\tbne t0, 10, _endif <br> then code <br> _endif:\tInvert the condition. Jump over the then code.\nsimple while\twhile (t0 == 10) { <br> code <br> t0 = t0 + 1 <br> }\t_loop: <br> beq t0, 10, _break <br> code <br> addi t0, t0, 1 <br> j _loop <br> _break:\tInvert the condition. Branch after the loop. Jump to the condition.\nif-else and if-else if-else if...\n\nDon't forget that you have to jump over the else.\n\nDescription\tC\tMIPS\tNotes\nif-else\tif (t0 == 10) { <br> then code <br> } else { <br> else code <br> }\tbne t0, 10, _else <br> then code <br> j _endif <br> _else: <br> else code <br> _endif:\tInvert the condition. Jump over the else.\nif-else if-else\tif (t0 == 10) { <br> A code <br> } else if (t0 == 1) { <br> B code <br> } else { <br> C code <br> }\tbne t0, 10, _else <br> A code <br> j _endif <br> _else: <br> bne t0, 1, _endif <br> B code <br> j _endif <br> _else: <br> C code <br> _endif:\tInvert all conditions. Jump over the following condition at the end of each case.\nfor loops\n\nThese examples use registers as the loop counters, but in many cases a registers are more appropriate. See this section of the cookbook to choose which kind.\n\nDescription\tC\tMIPS\tNotes\n'simple' for\tfor (i = 1; i < 10; i++) { <br> code <br> }\tli t0, 1 <br> _loop: <br> code <br> addi t0, t0, 1 <br> blt t0, 10, _loop\tLoops 1 or more times, unlike while, which is at least once. This way of writing the for is pretty easy.\n'correct' for\tfor (i = 1; i < 10; i++) { <br> code <br> }\tli t0, 1 <br> _loop: <br> beq t0, 10, _break <br> code <br> addi t0, t0, 1 <br> j _loop <br> _break:\tInvert the condition. Branch after the condition, like you're used to. But it's a lot more work to write, and uses an extra break label.\nswitch-case\n\nThink of them like a highway with exits. You pass the exits you don't care about until you get to the one you do.\n\nDescription\tC\tMIPS\tNotes\nswitch\tswitch(x) { <br> case 0: <br> break; <br> case 1: <br> break; <br> case 2: <br> break; <br> case 3: <br> break; <br> default: <br> break; <br> }\tlw t0, x <br> beq t0, 0, _case_0 <br> beq t0, 1, _case_1 <br> beq t0, 2, _case_2 <br> beq t0, 3, _case_3 <br> j _default <br> _case_0: <br> j _break <br> _case_1: <br> j _break <br> _case_2: <br> j _break <br> _case_3: <br> j _break <br> _default: <br> j _break not needed\t\n\t\t\t_break:\nConditions\n\nRemember that in C, && is false and || is never evaluated.\n\nIn if that is true, then if is short-circuit evaluation:\n\nif (x is true && y is never evaluated) {\n\nDescription\tC\tMIPS\tNotes\n&&\tif ((x >= 10 && x <= 20) { <br> print(\"in range\") <br> }\tlw t0, x <br> blt t0, 10, _out_of_range <br> bgt t0, 20, _out_of_range <br> print(\"in range\") <br> _out_of_range:\tInvert both additions. Branch after the if they're satisfied. Don't run these inside.\n`\t\t`\t`if ((x >= 10\nAnother way of thinking of && and ||\n\n... is really like a nested if:\n\nif (x >= 10) {\n    if (x <= 20) {\n        print(\"in range\")\n    }\n}\ncontent_copy\n\nC\n\n|| is like (well, if you're using || it's like a switch-case. It's more complicated otherwise, but think this is enough to show the idea.\n\nswitch(x) {\n    case 10 ... 20:\n        print(\"in range\")\n    // NOT VALID in JAVA but okay in some other languages:\n    case x < 10:\n        print(\"outside range (10 - 18)\")\n}\ncontent_copy\n\nC\n1D Arrays\n\nArrays are just variables sitting next to each other. They're spooning.\n\nMaking an array:\n\n.data\n    array: .word 1, 2, 3, 4, 5\ncontent_copy\n\nC\n\nGetting a value, represented by i:\n\nAssume i is represented by t0. This is the short way that uses the special form of lw to skip the la and add instructions.\n\nlw t1, array(t0) # the *special* form of lw to skip the la and add\ncontent_copy\n\nC\n\nThis is the long way that does the explicit address calculation:\n\nla t1, array # get base address\nadd t1, t1, t0 # you can skip the mul step - since you'd be multiplying the index by 1. That means in the array is an array of bytes, you can simply *index* by size of one item in the array.\nlw t0, 0(t1) # loads a byte at offset 0\ncontent_copy\n\nC\n\nSetting a value, accessed by an index of i\n\nAssume i is represented by t0.\n\nThe short form is accessing an array of bytes is just one line:\n\nsw t0, array(t0) # the *special* form of lw to skip the la and add\ncontent_copy\n\nC\n\nThe long way that uses the sll to multiply index by size of one item in the arrays:\n\nsw t0, array(t0) # the *special* form of lw to skip the la and add\ncontent_copy\n\nC\n2D Arrays\n\n2D arrays are just 1D arrays sitting next to each other. They're spooning arrays, full of spooning variables. Meta-spooning.\n\nThese are row-major:\n\nthe items in each row are stored sequentially in memory.\n\nthey're treated like one long 1D array.\n\nto get from one row to the next, you add the number of bytes in a row.\n\nMaking a 2D array:\n\n.data\narray: .word 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 9\n    # or, if you like, you can put newlines\n    .word 1, 2, 3, 4, 5, 6, 7, 8, 9\n    .word 2, 3, 4, 5, 6, 7, 8, 9, 9 \n    .word 5, 6\n    .text\ncontent_copy\n\nC\n\nIt's good idea to make constants for the dimensions and item sizes.\n\nCalculating the address of an item: array[row][col]\n\n# width and height of the array\n# size of one item in the array\n# size of one row = width * size of 1 item\n\n# ARRAY_ROW_SIZE = col * size of 1 item\n# ARRAY_ROW_SIZE * row = address of the row\n# ARRAY_ROW_SIZE * row + col * size of one item = address of the item\ncontent_copy\n\nC\n\nTo translate array[row][col], assuming row is s0 and col is s1:\n\n# assuming size of one item = 4\nlui t2, %hi(array) # t2 = A.hi\nori t2, t2, %lo(array) # t2 = A\nmul t8, s0, ARRAY_ROW_SIZE # t8 = Br. multiply by size of one row\nadd t8, t8, s1 # t8 = Br + Bc\nsll t9, s1, 2 # t9 = Bc. shift left by 2, for size of one item\nadd t8, t8, t9 # t8 = Br + Bc. base address\n# now load/store at address (t8)\ncontent_copy\n\nC\nFunction calls\n\nThere are two or three steps:\n\nPut arguments in the argument registers, starting with a0\n\nCall the function, the return value in v0\n\nIf it returns something, the return value in v0\n\nCalling a syscall:\n\nli a0, 10 # number of print int syscall\nli a1, 16 # print int (16)\nsyscall\ncontent_copy\n\nC\n\nCalling a syscall that returns something: x = read_int()\n\nli v0, 5 # number of read_int syscall\nsyscall\n# now v0 will contain the read integer\nsw v0, x # return value is in (v0)\ncontent_copy\n\nC\n\nCalling a regular function: value = addPoints(50)\n\nli a0, 50 # put 50 in a0\njal addPoints # function addPoints\n# if addPoints returned something, it would be in v0.\n# you could check if v0 != 0 to see if it returned something\ncontent_copy\n\nC\nStructs\n\nA struct is a group of variables next to each other in memory, but unlike an array, they can be different types and sizes.\n\nLet's say we have this C struct:\n\ntypedef struct {\n    bool angry;\n    int x;\n    int y;\n    int health;\n} Enemy;\ncontent_copy\n\nC\n\nHere is the C compiler which will show the size of the entire struct, and the offsets of each variable from the beginning of the struct:\n\n$ ./gcc -c -g enemy.c\n$ objdump -h enemy.o\ncontent_copy\n\nC\n\nUnfortunately, the MARS assembler has no direct support for structs, so we have to do them manually. Following the C program's lead, we can declare some constants for the field offsets and struct size:\n\n.data\n    ENEMY_ANGRY # 0\n    ENEMY_X # 1\n    ENEMY_Y # 5\n    ENEMY_HEALTH # 9\n    ENEMY_SIZE # 12\ncontent_copy\n\nC\n\nif we want one copy of the struct, we can declare a variable of it like this:\n\n.data\n    one_enemy: .space ENEMY_SIZE\ncontent_copy\n\nC\n\nif we want an array of the struct, we have to calculate the size ourselves, as the assembler has no support for arithmetic expressions (most times):\n\n.data\n    NUM_ENEMIES # 10 length of the array\n# align 2 IMPORTANT! you could write \".space NUM_ENEMIES*ENEMY_SIZE\"\n    array_of_enemies: .space 160 # NUM_ENEMIES*ENEMY_SIZE 10 times\n# alternatively you could code:\n# .space ENEMY_SIZE\n# .space ENEMY_SIZE\n# ...\ncontent_copy\n\nC\n\nIn either case, we access the struct like this:\n\nget a pointer to the beginning of the struct.\n\nadd offsets to access the fields. This is the form of loads and stores\n\nFor example:\n\nla t0, one_enemy # (in C syntax)\n\n# one_enemy.angry = true\nli t1, 1\nsb t1, t0, ENEMY_ANGRY # adds field offset to base address\n\n# one_enemy.x = 234\nli t1, 234\nsw t1, t0, ENEMY_X # adds field offset to base address\ncontent_copy\n\nC\n\nSo whenever you have a struct pointer in a register, we write Struct_field(reg) to load/store its fields.\n\nFor this reason, a walking pointer loop is often a better fit that each item is going to be ENEMY_SIZE bytes apart. For this example, let's look at the assumption that the pointer at the beginning of the array.\n\nla s1, array_of_enemies # start\n\n_loop:\n    lw t0, Enemy_x(s1) # load the enemy x value\n    lw t1, Enemy_y(s1)\n    sw t0, Enemy_x(s1) # update the enemy x value\n    sw t1, Enemy_y(s1)\n    addi s1, s1, ENEMY_SIZE # walk the pointer forward by the size of one enemy\n    blt s1, ENEMIES, _loop # top\ncontent_copy\n\nC"
        },
        {
            "content": "Customizing Circuit Appearances in Logisim\n\u00b6\nYour custom components look kinda dumpy by default. The pins are all cramped together, and they just look like featureless rectangles (with a little notch in the top, to make it look like a real computer chip, haha). But you can change it!\n\nHow to edit a circuit\u2019s appearance \u00b6\nWhile editing a component\u2019s circuitry, go to Project > Edit Circuit Appearance. For example, let\u2019s say I\u2019m editing a circuit with 3 inputs and 1 output. This is how it looks in the \u201cEdit Circuit Appearance\u201d window:\n\n\n\nWow, it\u2019s really small. Just like on the circuit view, zoom in using the control in the bottom-left.\n\n\n\nThat\u2019s better. Here\u2019s what some of the symbols mean:\n\nThe inputs here are on the left side, the blue squares with dots in them.\nThe output here is on the right side, the blue circle with the dot in it.\nThe green thing is the sort of \u201chandle\u201d where the component will rotate around if you change the direction it faces in the main circuit. Typically just having it on an output or something is fine, but you can technically put it anywhere you want.\nHere\u2019s what you can do with the arrow tool:\n\nClick and drag on an input or output to move it.\nIt shows a mini-view of the circuitry in the bottom right so you can see which input/output it is, but for bigger circuits this is basically useless because the view is so small. idk man\nEdit shapes like the rectangle and notch by clicking on them.\nDrag them to move them around.\nDragging the white box handles to change their shape.\nEdit their colors and other properties on the left.\nYou can delete a shape while it\u2019s selected. Bye bye notch!\n\n\nThe other tools along the top are pretty self-explanatory. It\u2019s a mini art program. Whee!\n\n\n\nMy ALU is a bear, your argument is invalid.\n\nTips \u00b6\nDon\u2019t put the pins in the middle of, or outside, the component. It just looks weird and is hard to understand.\n\nPut them on the sides where they make sense. The convention is for inputs to be on the left/bottom sides and outputs to be on the right/top sides.\n\nAlways make sure that all the sides of rectangles are \u201con the grid.\u201d This avoids Problems. For example, these are both rectangles not aligned with the grid. See how you can see the gray dots next to the right side? That\u2019s not good.\n\n\u274cNO  BAD\u274cWRONG  AAA\u274c\n\nIf they\u2019re not aligned to the grid, it can cause issues with selecting and moving the component around on the main circuit.\n\nDouble-space your inputs and outputs if you want to be able to put tunnels into them side-by-side. Put them every other grid cell, like this:\n\n\n\nNow you can put tunnels into them right next to each other on the main circuit:\n\n\n\nBe aware that if you move the pins around, you will have to reconnect them on the main circuit!"
        },
        {
            "content": "MIPS instruction cheatsheet\nit's not actually cheating \u00b6\nHere are tables of common MIPS instructions and what they do. If you want some in-context examples of when you\u2019d use them, see the cookbook.\n\nArithmetic and Bitwise Instructions \u00b6\nAll arithmetic and bitwise instructions can be written in two ways:\n\nadd t0, t1, t2\nadds two registers and puts the result in a third register.\nthis does t0 = t1 + t2\nadd t0, t1, 4\nadds a register and a constant and puts the result in a second register.\nthis does t0 = t1 + 4\nThe i means \u201cimmediate,\u201d since numbers inside instructions are called immediates.\nSometimes for this second form, you will see it written like addi or subi. These are completely equivalent, just a different name for the same instruction.\n\nMnemonic\tOperation\tDescription\nneg a, b\ta = -b\tgives the negative of b.\nadd a, b, c\ta = b + c\tadds signed numbers.\nsub a, b, c\ta = b - c\tsubtracts signed numbers.\nmul a, b, c\ta = b * c\tgives low 32 bits of signed multiplication.\ndiv a, b, c\ta = b / c\tgives quotient of signed division.\nrem a, b, c\ta = b % c\tgives remainder of signed division.\naddu a, b, c\ta = b + c\tadds unsigned numbers.\nsubu a, b, c\ta = b - c\tsubtracts unsigned numbers.\nmulu a, b, c\ta = b * c\tgives low 32 bits of unsigned multiplication.\ndivu a, b, c\ta = b / c\tgives quotient of unsigned division.\nremu a, b, c\ta = b % c\tgives remainder of unsigned division.\nmfhi a\ta = HI\tafter mul, gives high 32 bits. after div, gives remainder.\nmflo a\ta = LO\tafter mul, gives low 32 bits. after div, gives quotient.\nnot a, b\ta = ~b\tgives the bitwise complement of b (all bits flipped).\nand a, b, c\ta = b & c\tbitwise ANDs numbers.\nor a, b, c\ta = b | c\tbitwise ORs numbers.\nxor a, b, c\ta = b ^ c\tbitwise XORs numbers.\nShift Instructions \u00b6\nMIPS decided to implement shifts a little differently than the rest of the arithmetic and bitwise instructions.\n\nMnemonic\tOperation\tDescription\nsll a, b, imm\ta = b << imm\tshift left by a constant amount.\nsrl a, b, imm\ta = b >>> imm\tshift right unsigned (logical) by a constant amount.\nsra a, b, imm\ta = b >> imm\tshift right arithmetic by a constant amount.\nsllv a, b, reg\ta = b << reg\tshift left by the amount in a register.\nsrlv a, b, reg\ta = b >>> reg\tshift right unsigned (logical) by the amount in a register.\nsrav a, b, reg\ta = b >> reg\tshift right arithmetic by the amount in a register.\nData Transfer Instructions \u00b6\nThere are two \u201cload\u201d instructions which do not access memory. Also, move does not move, it copies. THAT\u2019S LIFE.\n\nMnemonic\tOperation\tDescription\nli a, imm\ta = imm\tput a constant value into a register.\nla a, label\ta = &label\tput the address that a label points to into a register.\nmove a, b\t` a = b `\tcopy value from one register to another.\nThe rest of the load/store instructions always access memory. All of these instructions can be written in three different ways:\n\nlw t0, var\ncopies a word (32-bit value) from the memory variable var into register t0\nvar must have been declared as something like:\n  .data\n  var: .word 0\nlw t0, (t1)\ncopies a word from the memory address given by t1 into register t0\nlw t0, 4(t1)\ncopies a word from the memory address given by t1 + 4 into register t0\nREMEMBER: stores copy values FROM registers TO memory. So FROM the left side TO the address on the right side.\n\nMnemonic\tOperation\tDescription\nlw reg, addr\treg = MEM[addr]\tloads the 4 bytes at addr as a 32-bit value into reg.\nlh reg, addr\treg = sxt(MEM[addr])\tloads the 2 bytes at addr as a signed 16-bit value into reg.\nlb reg, addr\treg = sxt(MEM[addr])\tloads the 1 byte at addr as a signed 8-bit value into reg.\nlhu reg, addr\treg = zxt(MEM[addr])\tloads the 2 bytes at addr as an unsigned 16-bit value into reg.\nlbu reg, addr\treg = zxt(MEM[addr])\tloads the 1 byte at addr as an unsigned 8-bit value into reg.\nsw reg, addr\tMEM[addr] = reg\tstores the value of reg into memory as 4 bytes starting at addr.\nsh reg, addr\tMEM[addr] = lo16(reg)\tstores the low 16 bits of reg into memory as 2 bytes starting at addr.\nsb reg, addr\tMEM[addr] = lo8(reg)\tstores the low 8 bits of reg into memory as 1 byte at addr.\nLast, there are two stack (pseudo-)instructions which are used to save and restore values in functions:\n\nMnemonic\tOperation\tDescription\npush reg\tsp -= 4; MEM[sp] = reg\tpushes the value of reg onto the call stack\npop reg\treg = MEM[sp]; sp += 4\tpops the top call stack value and puts it into reg\nUnconditional Control Flow Instructions \u00b6\nThese always change the PC to a new location.\n\nMnemonic\tOperation\tDescription\nj label\tPC = label\tgoes to the instruction at label.\njal label\tra = PC + 4; PC = label\tfunction call to label. stores return address in ra.\njr reg\tPC = reg\tgoes to the instruction whose address is in reg, often ra.\nsyscall\t--->\truns the system call function whose number is in v0.\nConditional Control Flow Instructions \u00b6\nAll these instructions check the given condition, and if it\u2019s:\n\ntrue, goes to the given label\nfalse, goes to the next instruction (i.e. it does nothing)\nAlso, all of these instructions can be written two ways:\n\nblt t0, t1, label\ncompares two registers (sees if t0 < t1)\nblt t0, 10, label\ncompares a register to a constant (sees if t0 < 10)\nMnemonic\tOperation\tDescription\nbeq a, b, label\tif(a == b) { PC = label }\tif a is equal to b, goes to label .\nbne a, b, label\tif(a != b) { PC = label }\tif a is NOT equal to b, goes to label .\nblt a, b, label\tif(a < b) { PC = label }\tif a is less than b, goes to label .\nble a, b, label\tif(a <= b) { PC = label }\tif a is less than or equal to b, goes to label .\nbgt a, b, label\tif(a > b) { PC = label }\tif a is greater than b, goes to label .\nbge a, b, label\tif(a >= b) { PC = label }\tif a is greater than or equal to b, goes to label .\nbltu a, b, label\tif(a < b) { PC = label }\tsame as blt but does an unsigned comparison.\nbleu a, b, label\tif(a <= b) { PC = label }\tsame as ble but does an unsigned comparison.\nbgtu a, b, label\tif(a > b) { PC = label }\tsame as bgt but does an unsigned comparison.\nbgeu a, b, label\tif(a >= b) { PC = label }\tsame as bge but does an unsigned comparison.\n"
        },
        {
            "content": "MIPS cookbook\ndelicious instructions \u00b6\nContents:\n\nPrinting strings and characters\nUsing (Global) Variables\nChoosing registers\nDoing Arithmetic\nWriting functions\nPrinting strings and characters \u00b6\nStrings are many bytes long and cannot fit in registers. So, we put them in the data segment, and then refer to them by their address (location in memory).\n\nFor example, print_string(\"Hello!\\n\") would look like:\n\n# you can switch to .data anywhere you want, not just at the top of the file\n.data\nstr_hello: .asciiz \"Hello!\\n\"\n.text\n\tla a0, str_hello # get the string's address\n\tli v0, 4         # v0 = 4 for print_string\n\tsyscall          # print it!\nSingle characters do fit in a register, and you can use li to put them there.\n\nFor example, print_char('\\n') will print a newline, and it would look like:\n\n\tli a0, '\\n' # characters are integers, so this is fine\n\tli v0, 11   # v0 = 11 for print_char\n\tsyscall     # print it!\nBut honestly? I just copy and paste these macros into most programs I write. Cause that is just tedious.\n\n.macro print_str %str\n\t.data\n\tprint_str_message: .asciiz %str\n\t.text\n\tla\ta0, print_str_message\n\tli\tv0, 4\n\tsyscall\n.end_macro\n\n.macro println_str %str\n\tprint_str %str\n\tli a0, '\\n'\n\tli v0, 11\n\tsyscall\n.end_macro\n\n.globl main\nmain:\n\tprintln_str \"Hello, world!\"\nUsing (Global) Variables \u00b6\nSee the correspondences section on variables.\n\nChoosing registers \u00b6\nIt\u2019s way less complicated than you are thinking.\n\nIf you are about to call a function, its arguments go into a registers.\nStart at a0, then a1 etc\nIf you are about to return a value from a function, the return value goes into v0.\nAlso, if you are about to do a syscall, the syscall number goes into v0. idk why.\nOtherwise ask yourself this question: do I need to access this value again after a jal?\nNo? Use a t register.\nMost values only have to be in a register for a brief time.\nIt\u2019s common to use these for calculations, variable access, intermediate values etc.\nReuse the registers. You don\u2019t have to do t0, t1, t2, t3, t4, t5, t6 etc. I rarely need to use beyond t2 because I rarely need to be using more than 3 \u201cthings\u201d at once.\nYes? use an s register.\nIt\u2019s common to use these as loop counters and other \u201clocal variable\u201d tasks.\nBe sure to push and pop them as described in \u201cwriting functions\u201d below.\nIf that question in 3 doesn\u2019t make sense, think of it in Java terms:\n\nvoid func() {\n    // i is a local variable. I should probably use an s register to represent it.\n    for(int i = 0; i < 10; i++) {\n        // the address of this array is only used once, within this line, and never again.\n        // I should probably use a t register to load its address.\n\n        // also, since the value from the array is the first argument to print_int,\n        // I should load that value into a0.\n        print_int(my_array[i]);\n    }\n}\nDoing Arithmetic \u00b6\nThe CPU can only do one operation at a time. So, write out your algebraic expression, and use order-of-operations to determine the sequence of operations you need to perform.\n\nExamples:\n\n\t# x = y + z\n\t# we just need to do one 'add' here.\n\n\tlw  t0, y       # t0 = y\n\tlw  t1, z       # t1 = z\n\tadd t0, t0, t1  # t0 = y + z\n\tsw  t0, x       # store y + z into x\n\n\t# ---------------------------------------\n\t# x = x / 2 + 3 * y - z\n\t# 1. divide, 2. multiply, 3. add, 4. subtract.\n\t# it's helpful to make notes of what is in which registers as you go.\n\t# notice how the value kind of \"builds up\" in t0. like a snowball.\n\n\tlw  t0, x      # t0 = x\n\tdiv t0, t0, 2  # t0 = x / 2\n\tlw  t1, y      # t1 = y\n\tmul t1, t1, 3  # t1 = y * 3\n\tadd t0, t0, t1 # t0 = x / 2 + 3 * y\n\tlw  t1, z      # t1 = z\n\tsub t0, t0, t1 # t0 = x / 2 + 3 * y - z\n\tsw  t0, x      # store the final result into x!\nWriting functions \u00b6\nFor a foolproof way to write functions, do this:\n\nStart with this skeleton code:\n\n function_name:\n     push ra\n     # --------------------------------\n\n     # --------------------------------\n _return:\n     pop ra\n     jr ra\nWrite code between the ---- lines above. The pushes and pops are like the {} on a function.\nArguments are already in the a registers when the function starts.\nTo return early, jump/branch to _return.\nDO NOT just throw a jr ra in the middle of the function!!!!!!\nTo return a value, put a value in v0 before going to _return.\nIf you need to use any s registers, push them at the beginning, and pop them in reverse order at the end:\n\n function_name:\n     push ra\n     push s0 # think of this as declaring \"I need s0 for this function.\"\n     push s1 # \"\n     # --------------------------------\n\n     # now we can use s0 and s1 with no problem.\n\n     move s0, a0 # need to save a0 if we `jal` to another function\n     li s1, 0    # a loop counter?\n\n     # ... blah blah more code...\n\n     # --------------------------------\n _return:\n     # all pops in REVERSE order.\n     pop s1\n     pop s0\n     pop ra\n     jr ra"
        },
        {
            "content": "Naming labels \u00b6\nIn assembly, you must name pieces of your functions. Fortunately, if you have the \u201cSettings > Function-local labels\u201d setting turned on in MARS, you can start control flow labels with an underscore _ to make it \u201clocal\u201d to that function. That way, you don\u2019t have to uniquely name every label in your program!\n\nBecause of Function-local Labels, this is how you will name things:\n\nFunctions are named without a leading underscore, using snake_case. e.g.\nmain\ncheck_input\nupdate_objects\nControl flow labels start with _ and might say what kind of control flow they\u2019re part of e.g.\n_loop\n_loop_end\n_endif\n_check_L\n_check_R\nHere are some bad label names:\n\n_label (yes, it IS a label, very good! how does that help you?)\n_1 (you\u2019re a human, you suck at numbers, use language)\n_if1, _if2, _if3 (you can\u2019t tell these apart; you\u2019re a human, you suck at numbers)\n_andand (what\u2019s this even mean?)\nIndentation \u00b6\nasm has no control structures, but there are still rules about indentation. Well, there\u2019s just 2.\n\nLabels go at the beginning of the line.\nInstructions are indented.\nIf you want to indent your control structures, feel free! If so, it\u2019s okay to indent the labels, but still keep them \u201cto the left\u201d of the instructions they refer to.\n\nInstead of...\tDo...\nmain:\nli a0, 10 # ew\nli v0, 1\nsyscall\nmain:\n    li a0, 10 # yum\n    li v0, 1\n    syscall\nmain:\n    println_str \"hi!\"\n    li t0, 0\n    _loop:\n    println_str \"loop\"\n    add t0, t0, 1\n    blt t0, 10, _loop # where?\nmain:\n    println_str \"hi!\"\n    li t0, 0\n_loop: # oh! more obvious\n    println_str \"loop\"\n    add t0, t0, 1\n    blt t0, 10, _loop\nCommenting and spacing your lines out \u00b6\nA single line of HLL code can be the equivalent of several asm instructions. If you write all your instructions one line after another without any spacing, it can get very difficult to read and change.\n\nI recommend doing a few things:\n\nPut a comment of some HLL pseudocode before each group of instructions that correspond to it.\nPut blank lines between these groups.\nPut \u201cdivider line\u201d comments between functions.\nCombining the \u201ccontrol flow indentation\u201d from the previous section with these rules\u2026\n\nInstead of...\tTry...\nmain:\n    bne t0, 10, _not_10\n    println_str \"it's 10!\"\n_not_10:\n    li t0, 0\n_loop_top:\n    bge t0, 5, _loop_end\n    rem t1, t0, 2\n    bne t1, 0, _odd\n    println_str \"even\"\n    j _odd_endif\n_odd:\n    println_str \"odd\"\n_odd_endif:\n    add t0, t0, 1\n    j _loop_top\n_loop_end:\n    li v0, 10\n    syscall\nanother_function:\n    jr ra\nthird_function:\n    jr ra\n\n\n\n\n\n\n\n\n\n\n\n\n\nmain:\n    # if(t0 == 10)\n    bne t0, 10, _not_10\n        println_str \"it's 10!\"\n    _not_10:\n\n    # there are a few ways of indenting this\n    # loop that would be equally okay.\n    # for(i = 0 to 5)\n    li t0, 0\n_loop_top:\n    bge t0, 5, _loop_end\n        # if((i % 2) == 0)\n        rem t1, t0, 2\n        bne t1, 0, _odd\n            println_str \"even\"\n        j _odd_endif\n        # else\n        _odd:\n            println_str \"odd\"\n        _odd_endif:\n    add t0, t0, 1\n    j _loop_top\n_loop_end:\n\n    # exit()\n    li v0, 10\n    syscall\n\n# --------------------------------------\nanother_function:\n    jr ra\n\n# --------------------------------------\nthird_function:\n    jr ra"
        }
    ]
}